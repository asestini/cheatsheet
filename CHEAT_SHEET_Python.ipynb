{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CHEAT_SHEET_Python.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asestini/cheatsheet/blob/master/CHEAT_SHEET_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnkUEQZBvaYN",
        "colab_type": "text"
      },
      "source": [
        "# **1. LIBRARY / JUPYTER SETTINGS**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KJYjyxRFGfW",
        "colab_type": "text"
      },
      "source": [
        "> Basic Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Akx0Fz61z4KR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Basic Library\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm # For color purpose\n",
        "import math\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore') # To ignore warning messages (be carefull)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "895XU2j8FKpu",
        "colab_type": "text"
      },
      "source": [
        "> Machine Learning Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR_A-d2HHeXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Machine Learning Libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from sklearn.impute import KNNImputer\n",
        "from fancyimpute import KNN\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.tree import plot_tree\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import sklearn.naive_bayes as nb\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import BaggingClassifier as BC\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "! pip3 install xgboost\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import DBSCAN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMaTxCDzFPO1",
        "colab_type": "text"
      },
      "source": [
        "> Other useful Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy4DL6geyz6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Other Lbraries\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore') # To ignore warning messages (be carefull)\n",
        "\n",
        "# re for specific search within string\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY0CfK7AMTSw",
        "colab_type": "text"
      },
      "source": [
        "> Jupyter settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVc4-I6IMVTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove row / column display limitation\n",
        "# BEAR IN MIND : Try limit max rows or columns\n",
        "pd.options.display.max_rows = None # replace None by integer to set specific limitation\n",
        "pd.options.display.max_columns = None\n",
        "# or\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Vc6YHQk7a8z",
        "colab_type": "text"
      },
      "source": [
        "# **2. BASICS PYTHON**\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXZH_Lla-rLv",
        "colab_type": "text"
      },
      "source": [
        "## A. ASKING FOR HELP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqBIWgPq_v4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "help(str) # return the help for the STRING function\n",
        "str?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXwRZrzyxsP4",
        "colab_type": "text"
      },
      "source": [
        "## B. CALCULATIONS AND VARIABLES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzu_leJ37yPa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1e468182-8864-42bd-8abe-bb1a0d06e32c"
      },
      "source": [
        "# VARIABLE ASSIGNEMENT\n",
        "x = 9\n",
        "print(x)\n",
        "# return 9"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtNRZlUC8tci",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5205026e-c639-4218-a887-8c63cf675091"
      },
      "source": [
        "# CALCULATION (x = 9)\n",
        "x+2 # return 11 => SUM\n",
        "x-2 # return 7 => SUBSTRACTION\n",
        "x*2 # return 18 = > MULTIPLICATION\n",
        "x **2 # return 81 => SQUARED POWER\n",
        "x **(1/2) # return 3.0 => SQUARE ROOT\n",
        "x%2 # return 1 => REMAINDER (9 / 2 = 8 / 2 with remain 1)\n",
        "x/2 # 4.5 => DIVISION\n",
        "x//2 # 4 => FLOOR DVISION => discard the remainder\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICZYVW7FXMJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ADVANCED CALCULATION\n",
        "inputs @ weights # matrix product  \n",
        "np.exp(x) # exponential of x\n",
        "math.exp(x) # exponential of x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wk7A1Cff9BtR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9b825459-0666-4886-a539-16027a37bcfa"
      },
      "source": [
        "# Types (x = 9)\n",
        "str(x) # return '9' as a STRING\n",
        "int(x) # return 9 as an INTEGER\n",
        "float(x) # return 9.0 as a FLOAT\n",
        "bool(x) # return True => BOOLEAN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGkxzeezcBOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ID : to check the hash id of the object\n",
        "id(variable) # return the hash id of the object"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGSk_7fH_-5v",
        "colab_type": "text"
      },
      "source": [
        "## C. STRINGS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HziGqNaNA7Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_string = \"Text\"\n",
        "my_string # return 'Text'\n",
        "my_string*2 # return 'TextTest'\n",
        "my_string + \"Innit\" # return 'TextInnit'\n",
        "'t' in my_string # return True\n",
        "'a' in my_string # return False\n",
        "my_string.upper() # return 'TEXT' => the UPPER my_string\n",
        "my_string.lower() # return 'text' => the lower my_string\n",
        "my_string.find('t') # return 3 => CASE SENSITIVE\n",
        "my_string.rfind('t') # return 3 the hightest index of caracter to be find=> CASE SENSITIVE\n",
        "my_string.count('t') # return 1 => count the 't' value => THIS IS CASE SENSITIVE\n",
        "my_string.replace('e', 'i') # return 'Tixt' => replace ALL letters. THIS IS CASE SENSITIVE\n",
        "my_string.strip() # return 'Text' => remove by default whitespace \n",
        "my_string.strip('Tt') # return 'ex' => remove any char within ()  but CASE SENSITIVE)\n",
        "my_string.split('x') # return a list ['Te', 't'] => this is CASE SENSITIVE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3orGZIpN-4uc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Replace using dictionnary\n",
        "address = \"123 north anywhere street\"\n",
        "for word, replace_by in {\"NORTH\":\"N\", \"SOUTH\":\"S\" }.items():\n",
        "    address = address.replace(word.lower(), replace_by)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBnmbWIML_r9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove data / caracters\n",
        "str = 'Engineer123Discipline'\n",
        "\n",
        "# 1) use replace (see above)\n",
        "my_string.replace('e', '') # return 'Enginr123Disciplin' => This is CASE SENSITIVE\n",
        "\n",
        "#2) MY FAVORITE ONE : Translate => very useful for long list of caracters to remove\n",
        "str.translate({ord(i): None for i in '13'}) # return : 'Engineer2Discipline' => This is CASE SENSITIVE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdhDsZ8rBAv3",
        "colab_type": "text"
      },
      "source": [
        "## D. LISTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngRby21GBrxe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BASIC TASKS\n",
        "a = \"is\"\n",
        "b = \"nice\"\n",
        "my_list = ['my', 'list', a, b]\n",
        "my_list # return ['my', 'list', 'is', 'nice']\n",
        "my_list2 = [[4,5,6,7], [3,4,5,6]] # Can do list within list\n",
        "my_list3 = ['a', 1, 2, 'c'] # Can mix data type within same list\n",
        "my_list5 = [[1,2,3], [10,20]]\n",
        "\n",
        "# OPERATIONS ON LIST\n",
        "my_list2 + my_list5 # [[4, 5, 6, 7], [3, 4, 5, 6], [1, 2, 3], [10, 20]]\n",
        "my_list + my_list * 2 # ['my', 'list', 'is', 'nice', 'my', 'list', 'is', 'nice']\n",
        "\n",
        "# LIST METHODS\n",
        "my_list.index(a) # return 2 THE INDEX OF VARIABLE a WITHIN my_list\n",
        "my_list.count('y') # return 0 there is 'my' but NOT 'y'\n",
        "my_list.count('my') # return 1 there is 'my'\n",
        "my_list.append(['Test', 'hello']) # ['my', 'list', 'is', 'nice', ['Test', 'hello']] => append the whole ['Test', 'hello'] as a block\n",
        "my_list.extend(['Test', 'hello']) # ['my', 'list', 'is', 'nice', 'Test', 'hello'] => append piece by piece\n",
        "my_list.remove('my') # ['list', 'is', 'nice'] => remove the FIRST OCCURENCE OF the item 'my'=> if ['my', 'my']\n",
        "# => WARNING my_list.remove('y') won't work as do NOT remove the letter 'y' but the item 'y' => ['my'] but NOT ['y']\n",
        "del(my_list[0:1]) # remove the 1st item 'my' item ['list', 'is', 'nice']\n",
        "my_list2.clear() # return [] => Supprime TOUTES les valeurs dans la liste, MAIS PAS la liste qui sera vidée.  \n",
        "my_list5.sort() # Sort ascending by default => .sort(reverese = True) = sort descending  \n",
        "my_list.reverse() # reverse my_list => equal to .sort(reverse = True)\n",
        "my_list.pop(-1) # Cut to paste the last item in the list\n",
        "my_list.insert(0,'!') # Insert to the 1st index the [!] => if my_list = [1, 2, 3] => ['!', 1, 2, 3]\n",
        "my_string = \" \".join(my_list) # Join all list elements using the \" \" as separator to create a string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0unY4MugkQ7",
        "colab_type": "text"
      },
      "source": [
        "## E. SET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeOGgi5-g_og",
        "colab_type": "text"
      },
      "source": [
        "SET are \"kind of\" list with several differences:\n",
        "* you CANNOT get any duplicates \n",
        "* it is in '{}'\n",
        "* There is NO order => NO Slicicng"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M751Re0lNIML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize set\n",
        "my_set = set() # return empty set\n",
        "my_set = {1, 3} # return set\n",
        " \n",
        "my_set.add(2) # return {1, 2, 3} => add single element\n",
        "my_set.update([2, 3, 4]) # return {1, 2, 3, 4} => add multiple elements\n",
        "my_set.update([4, 5], {1, 6, 8}) # return {1, 2, 3, 4, 5, 6, 8} => add list and set\n",
        "\n",
        "my_set.discard(1) # return {3} => remove an element but if not exist NO error message\n",
        "my_set.remove(3) # return {3} => remove an element and if not exist = trigger error message\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZDDoB2Rgy3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Python set operations (union, intersection, difference and symmetric difference) \n",
        "A = {0, 2, 4, 6, 8}; \n",
        "B = {1, 2, 3, 4, 5}; \n",
        "  \n",
        "# union \n",
        "print(\"Union :\", A | B) # return ('Union :', set([0, 1, 2, 3, 4, 5, 6, 8]))\n",
        "  \n",
        "# intersection \n",
        "print(\"Intersection :\", A & B) # return ('Intersection :', set([2, 4]))\n",
        "  \n",
        "# difference \n",
        "print(\"Difference :\", A - B) # return ('Difference :', set([8, 0, 6]))\n",
        "  \n",
        "# symmetric difference \n",
        "print(\"Symmetric difference :\", A ^ B) # return ('Symmetric difference :', set([0, 1, 3, 5, 6, 8]))\n",
        "\n",
        "# (source : https://www.geeksforgeeks.org/python-set-operations-union-intersection-difference-symmetric-difference/)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aJoEjkfFMSn",
        "colab_type": "text"
      },
      "source": [
        "## F. DICTIONNARY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwOunHHrG8ja",
        "colab_type": "text"
      },
      "source": [
        "> {key : value}\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPh9xOmUFPuP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4421a5cf-8fbf-4ce6-9db1-169ed850075a"
      },
      "source": [
        "my_dict = {'key1': 'my 1st value', \n",
        "           'key2' : 'my 2nd value',\n",
        "           'key3' : 3\n",
        "           }\n",
        "my_dict[\"key1\"] # Return 'my 1st value'\n",
        "my_dict.get(\"key1\") # Return 'my 1st value' like my_dict[\"key1\"]\n",
        "my_dict.keys() # Return all keys within dictionary => ['key1', 'key2', 'key3']\n",
        "my_dict.values() # Return all values within dictionary => ['my 1st value', 'my 2nd value', 3]\n",
        "my_dict.items() # Return all key and values within dictionary => [('key1', 'my 1st value'), ('key2', 'my 2nd value'), ('key3', 3)]\n",
        "my_dict[\"key2\"] = 'I change the 2nd value' # Modify the value for \"key2\"\n",
        "del my_dict['key1'] # Delete the 'key1' item\n",
        "my_dict.pop(\"key1\") # Delete \"key1\"\n",
        "my_dict.clear() # Clear the whole dictionary\n",
        "my_dict2 = dict(color=\"C8\", linewidth=2) # return = {'color': 'C8', 'linewidth': 2}\n",
        "my_dict_inv = {v: k for k, v in my_dict_inv.items()} # Return inverse of the dictionnary (keys become values and values become keys)\n",
        "my_dict_inv = dict(zip(my_dict.values(), my_dict.keys()))\n",
        "my_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'key2': 'I change the 2nd value', 'key3': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psjR5WcnB9wn",
        "colab_type": "text"
      },
      "source": [
        "## G. SELECTING / SLICING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-8hLOIFA9q6",
        "colab_type": "text"
      },
      "source": [
        "> **Overview**\n",
        "\n",
        "**a**[*beg:end:step*]\n",
        "\n",
        "with *beg* = index **starting from 0** => can put negative value so start from the end => e.g. [-1] = last char\n",
        "\n",
        "with *end* = index **not** included\n",
        "\n",
        "with *step* = step to move from beg to end => step [0:4:2] would get index 0 => index 2 => NOT index 4 (not included)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne02E8HSD9RA",
        "colab_type": "text"
      },
      "source": [
        ">> **For strings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nk5Wcy1JDPnd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9fa111bf-ca09-4bcf-bf18-67d91da3f653"
      },
      "source": [
        "# For strings\n",
        "my_string = 'Text'\n",
        "my_string[0] # return 'T'\n",
        "my_string[-1] # return 't' => last char\n",
        "my_string[:2] # return 'Te' => from index 0 till index 2 NOT included\n",
        "my_string[::2] # return 'Tx' => index 0 and index 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tx'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BWePn5hEEUX",
        "colab_type": "text"
      },
      "source": [
        ">> **For Lists**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBNa8Sg0HQeu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "559e94e6-a2c1-489c-bbfc-261279361cc5"
      },
      "source": [
        "# For list\n",
        "my_list = [1, 2 ,3]\n",
        "my_list[0] # return 1\n",
        "my_list[0:2] # return [1, 2]\n",
        "my_list[-1] # return 3\n",
        "\n",
        "my_list2 = [[1, 2, 3, 4], ['a', 'b', 'c']]\n",
        "my_list2[1] # return ['a', 'b', 'c']\n",
        "my_list2[0][1] # return 2\n",
        "# Subsets\n",
        "my_list2[0][1:2] # return [2]\n",
        "#my_list2[0][1:3] # return [2, 3]\n",
        "# Advanced\n",
        "my_list3 = [[[1, 2, 3], [4, 5, 6]],['a', 'b', 'c']]\n",
        "my_list3[0][1][1:3] # return [5, 6]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 6]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2krOrj8Uk8m",
        "colab_type": "text"
      },
      "source": [
        ">> **For Dictionary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7YqlX_PUs58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For Dictionary you should use: \n",
        "# - the dictionary key\n",
        "# - loop using \"for:\"\n",
        "print({k:d[k] for k in l if k in d})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WshPfy2lTJtA",
        "colab_type": "text"
      },
      "source": [
        "## H. DATAFRAMES / SERIES - PANDAS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfnZXuoKt3bc",
        "colab_type": "text"
      },
      "source": [
        "> Manage file data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naOE44cMu4tk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LOAD DATA\n",
        "\n",
        "# Load data\n",
        "dataset = pd.read_csv('filename.csv', header=None, usecols=[3,6]) \n",
        "# 'header=None' => there is no header in columns | add the 'usecols' to say no header only for certain columns (4th to 6th)\n",
        "dataset = pd.read_csv(\"/content/drive/My Drive/Kaggle/train.csv\") # Example with data stored on google drive\n",
        "\n",
        "# Get data directly from url\n",
        "data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
        "dataset = pd.read_csv(data_url, header=None)\n",
        "\n",
        "# Download (export) to csv\n",
        "pd.to_csv('filename_exported.csv', index = False) # 'index = False' is not mandatory and remove index from export"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VY-aPeFXK7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TRANSFORM DATAFRAME / SERIES\n",
        "\n",
        "# Series\n",
        "d_series = pd.Series(data= dataset, name=series_or_column_name) # can add 'index= ds.index' with same length as dataset / 'dtype=...' to change dtype \n",
        "\n",
        "# DataFrame\n",
        "df = pd.DataFrame(data = dataset, columns=dataset.columns)\n",
        "\n",
        "# Series to Dataframe\n",
        "df = pd.DataFrame(data = pd.Series(dataset_series)).reset_index()\n",
        "\n",
        "# FLATTEN\n",
        "ds.flatten() # Transform to 0D vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpVYOBBQt_hd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MERGE DATA SET\n",
        "\n",
        "# Merge 2 datasets into 1\n",
        "dataset = df1.merge(df2, left_on='lkey', right_on='rkey',suffixes=('_left', '_right')) # suffixes is NOT mandatory to add extra suffixes\n",
        "\n",
        "# Concatenate\n",
        "dataset = pd.concat([dataset_1, dataset_2], join=\"inner\", axis=1) \n",
        "# 'inner' join to get only values shared among 2 datasets and 'axis=1' to add has new column (axis=0 by default => rows) \n",
        "\n",
        "# Join\n",
        "dataset = ds1.join(ds2) # can add 'on=key_column' to join on specific key otherwise will do on index level\n",
        "\n",
        "# Append\n",
        "dataset = dataset.append(ds2) # must set dataset = xx.append()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JzMVAjDr9Av",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RESET INDEX\n",
        "ds.reset_index(drop=True) # reset your index for the dataset => by default drop = False but = True avoid get old \"index values\" as a new column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pG3_Cu0Q_tfk",
        "colab_type": "text"
      },
      "source": [
        "> Modification in DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sv8-NzdbPd11",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DELETE Columns\n",
        "dataset.drop(['column_1', 'column_2'], axis=1)\n",
        "dataset.drop(columns=['column_1', 'column_2'])\n",
        "\n",
        "# DELETE Rows\n",
        "dataset.drop([0, 1]) # delete row in index 0 AND 1 => it is NOT ranging from 0 to 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eES8GbV43HR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DATA TYPE\n",
        "# Get the data type\n",
        "dataset.column_name.dtypes\n",
        "\n",
        "# Change Data Type\n",
        "dataset['column_name'].astype('int64') # modify to integer the value in column name\n",
        "# Main data type = 'object' / 'str' / 'int64' / 'float64'\n",
        "\n",
        "# Change Str to Float (ex : price with '$85.00' and sometimes '$1,000.00')\n",
        "# OPTION 1\n",
        "ds['price2'] = ds.price.apply(lambda x : x[1:])\n",
        "ds['price2'] = ds.price2.str.replace(',','').astype('float64')\n",
        "\n",
        "#OPTION 2\n",
        "ds['price2'] = X_clean.price.apply(lambda x: float(str(x).replace(\",\",\"\").replace(\"nan\",\"$0\")[1:])) # replace nan by \"$0\" because at the end we slice removing 1st index\n",
        "\n",
        "# OPTION 3 faster(10 to 15%)  than 1 and 2 but not the if type ... security\n",
        "ds['price2'] = ds.price.str.slice(1).str.replace(',','').astype('float64')\n",
        "\n",
        "\n",
        "# Map odd float to string\n",
        "dataset['column_name'].map(str) # 7.327584e+08 => 732758368.79972"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlCOGltqiiGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# COLUMNS\n",
        "\n",
        "# Reset index\n",
        "ds.set_index('month') # month column will replace the current index\n",
        "\n",
        "# Insert Column\n",
        "dataset.insert(loc_index, column_name_created, column_value) # DO NOT SET : 'dataset = dataset.insert ....' | Where \"loc_index\" = index of the column to insert (NOT replace) the new column\n",
        "\n",
        "# Re-order (move) column to the end\n",
        "cols_at_end = ['col_last']\n",
        "dataset = dataset[[c for c in dataset if c not in cols_at_end] \n",
        "        + [c for c in cols_at_end if c in dataset]]\n",
        "\n",
        "# Create new dataset with specific column\n",
        "new_dataset = old_dataset[['col_1', 'col_3']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-90b4ig1trh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RENAME\n",
        "# Columns\n",
        "df.rename(columns={\"A\": \"a\", \"B\": \"c\"}) # can rename 1 or several columns\n",
        "df.rename(str.lower, axis='columns')\n",
        "df.columns = ['col_name_1','col_name_2', 'col_name_3]\n",
        "\n",
        "\n",
        "# Rows\n",
        "df.rename(index={0: \"x\", 1: \"y\", 2: \"z\"})\n",
        "df.rename({1: 2, 2: 4}, axis='index')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpA0kHZge4YK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SLICING / SELECTION\n",
        "\n",
        "# Get all columns from Dataframes except column \"Price\" put in another variable using \"\".loc\"\n",
        "X = dataset.loc[:, dataset.columns != \"Price\"]\n",
        "y = dataset.loc[:, dataset.columns == \"Price\"] # Warning : Create a DataFrame\n",
        "y = dataset.iloc[:, -1:] # PLEASE NOTE  : Creates a 'Series'\n",
        "\n",
        "# Get specific columns\n",
        "dataset.loc[:, ['column_1', 'column_2', 'column_3']]\n",
        "\n",
        "# Mask to select\n",
        "mask = dataset['column_1'] == dataset['column_2']\n",
        "dataset[mask].head()\n",
        "# example:\n",
        "mask = (ds_2.y >=-0.01) & (ds_2.y <=0.01)\n",
        "ds_2[mask]\n",
        "\n",
        "\n",
        "# Select based on Data type\n",
        "X_num = X.select_dtypes(\"number\")\n",
        "X_cat = X.select_dtypes(exclude=\"number\")\n",
        "\n",
        "# Slicing within each \"cell\"\n",
        "ds.price = ds[\"price\"].str.slice(start, end, step)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvvrOuqJ73L-",
        "colab_type": "text"
      },
      "source": [
        "> Calculation in DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJwCjzNDX-a1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basic Calculation\n",
        "ds['column_1'].mean() # return mean\n",
        "ds['column_1'].median() # return median\n",
        "ds['column_1'].std() # return standard deviation\n",
        "ds['column_1'] = pd.qcut(ds['column_2'], q=4, labels=False) # Allow to split within same column in quartile, decile etc. | 'labels=False' to see the real result\n",
        "ds['column_1'] = pd.cut(ds['column_2'], 5, labels=False) # labels=False => can put list same lenght different cut (5 in ex) or False => digit from 0 to 4 in example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiBrT1FK77UV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GROUPBY => Consolidate by specific column to do calculation\n",
        "# basic functions\n",
        "dataset.groupby('column_name')\n",
        "dataset.groupby('column_name').max()\n",
        "\n",
        "# multi_columns\n",
        "dataset.groupby('column_1')['column_2', 'column_3'].sum()\n",
        "\n",
        "# Calculate value length in column\n",
        "dataset['column_length'] = dataset['column_name'].apply(len) # Warning => 'float' has no length =>  must '.map(str)' before calculating"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pVv4IsHLqnJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply a created function\n",
        "def your_function:\n",
        "  do_something\n",
        "\n",
        "dataset['column1'] =  dataset2['columnX'].apply(your_function)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvtLN90cAR8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unique Value\n",
        "ds['col_1'].unique() # return unique values\n",
        "np.unique(labels) # return unique values\n",
        "\n",
        "# Calculate count of unique value\n",
        "pd.Series(dataset.feature_column.unique()).value_counts() # Get the list of the unique values\n",
        "len(pd.Series(dataset.feature_column.unique())) # Get the count number of unique values\n",
        "np.unique(y_train, return_counts=True) # return_counts = True => displays the count per unique value\n",
        "\n",
        "# For loop to see unique value in Dataset\n",
        "for i in dataset.columns:\n",
        "  print(\"{} count unique value : {}\".format(\n",
        "      i, len(pd.Series(ds[i].unique()))\n",
        "  ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zbR5s20f1sS",
        "colab_type": "text"
      },
      "source": [
        "# **3. ADVANCED**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bq7w8ZjAgYk3",
        "colab_type": "text"
      },
      "source": [
        "## A. MAPPING DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNyEDLfmf6__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create dictionnary to map data\n",
        "mapping = {\n",
        "    0 : \"Unregistered\",\n",
        "    1 : \"Registered\",\n",
        "    2 : \"Super Registered\"\n",
        "    }\n",
        "_.apply(lambda x : mapping[x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f65Am1Zhg3SH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inverse this mapping dictionnary\n",
        "inv_mapping = {v: k for k, v in mapping.items()}\n",
        "_.apply(lambda x : inv_mapping[x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmFTltZsBSt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Complicated mappng with \"betwwen style\"\n",
        "for i,(min, max, value_to_put) in dataset_2.iterrows():\n",
        "        df1.loc[(dataset_1[\"value\"] >= min) & (dataset_1[\"value\"] < max),\"new_column_name\"] = value_to_put"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0SpMSpwNDg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply target_names to target value\n",
        "y = pd.Categorical.from_codes(wine.target, wine.target_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0z5bXECmMdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Quickly transform numerical field in 0 / 1 style target value\n",
        "dataset.iloc[:, -1] = (dataset.iloc[:, -1]>=0.75)*1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkU-xqtXLMFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply country mapping based on ip address using own function taking data from another dataset\n",
        "def transform_ip(arg) :\n",
        "  try :\n",
        "    return ds_ip.country[(ds_ip.lower_bound_ip_address <= arg) & (ds_ip.upper_bound_ip_address >= arg)].iloc[0]\n",
        "  except IndexError :\n",
        "    return \"Unknown country\"\n",
        "\n",
        "ds_fraud[\"country\"] = ds_fraud.ip_address.apply(transform_ip)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNinXut4r7oh",
        "colab_type": "text"
      },
      "source": [
        "## B. DUMMYFICATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP--1U9hr6l7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dummyfication of a column\n",
        "dataset = pd.get_dummies(dataset, columns = [\"Cabin_1\"], prefix =\"Cabin_1\", drop_first=True)\n",
        "# if only dataset and no columns => all object / str feature will be dummified\n",
        "# prefix is NOt mandatory and allow to add extra prefix (Python already provide one automatically)\n",
        "# drop_first=True => VERY IMPORTANT allow to avoid dummyfy all values withn columns and keep all of them (wrong because should always NOT keeping 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk7t-mG_lKyR",
        "colab_type": "text"
      },
      "source": [
        "## C. LOOP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZNafu9clTCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Enumarate\n",
        "# Allow to loop with index\n",
        "\n",
        "my_list = ['apple', 'banana', 'grapes', 'pear']\n",
        "for c, value in enumerate(my_list, 1):\n",
        "    print(c, value)\n",
        "# return\n",
        "# 1 apple\n",
        "# 2 banana\n",
        "# 3 grapes\n",
        "# 4 pear"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSPh54AiV4cI",
        "colab_type": "text"
      },
      "source": [
        "## D. DATE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fkY14SgmYBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transform str pandas to date\n",
        "ds['date'] = pd.to_datetime(ds.date, format='%Y-%m-%d') # format to specify the date format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2UtjUEHzvWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transform format date\n",
        "dataset['period'] = dataset.period.strftime(\"%d/%m/%Y\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZF_W9jGV7aF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transform date string into date number\n",
        "import datetime\n",
        "date_time_str = '2018-06-29 08:15:27.243860'\n",
        "date_time_obj = datetime.datetime.strptime(date_time_str, '%Y-%m-%d %H:%M:%S.%f')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWhJjQNoK6UI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate Delta in seconds using log10 scale\n",
        "ds['delta_sec'] = (ds.purchase_time - ds.signup_time).apply(lambda x : np.log10((x.days * 86400) + x.seconds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qveCUYQeOIOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create index date range 9 days\n",
        "index = pd.date_range('1/1/2000', periods=9, freq='T')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFOdSi8jVne_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reseample (transform) data time into other frequency (e.g. from second to day etc.)\n",
        "series.resample('3T').sum() # return time series in 3 groups summed\n",
        "\n",
        "series.resample('1d').sum() # "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLwZH5a7Mr9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Week Day number (0 = Monday)\n",
        "dataset.date.weekday()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAoeS3iP-vAB",
        "colab_type": "text"
      },
      "source": [
        "##E. RANDOM GENERATED DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T92r0iKU-1pr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# random.randint\n",
        "np.random.randint(min, max, size=None) # 'size' can be integer or None by default (create 1 report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpyGWfARXBZd",
        "colab_type": "text"
      },
      "source": [
        "##F. FILL THE GAP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PUw2HUiXGJt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PAD \n",
        "# To add at the beginnng and end of an array some values\n",
        "a = [1, 2, 3, 4, 5]\n",
        "\n",
        "np.pad(a, (2, 3), 'edge') # return array([1, 1, 1, ..., 5, 5, 5])\n",
        "np.pad(a, (2,), 'mean') # return array([3, 3, 1, 2, 3, 4, 5, 3, 3]) => works with 'median'\n",
        "np.pad(a, (2, 3), 'linear_ramp', end_values=(5, -4)) # return array([ 5,  3,  1,  2,  3,  4,  5,  2, -1, -4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP3WTao1QL-f",
        "colab_type": "text"
      },
      "source": [
        "##G. UNZIP / TAR FILES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3yd3cR0QQKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# UNZIP\n",
        "!unzip /content/train_photos.tgz.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unlSSB-NQO7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TAR FILES\n",
        "import tarfile\n",
        "file = tarfile.open(\"train_photos.tgz\", mode=\"r:gz\")\n",
        "file.extractall()\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv6fwZcZZKHF",
        "colab_type": "text"
      },
      "source": [
        "##H. EXPORT TO FILE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1ib9LtUZOII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Export to Txt file\n",
        "  text_file = open(\"./your_file.txt\", \"w\", encoding='utf8') # Open (or create if not existing) a file on the same current working directory called your_file | \"w\" for write mode\n",
        "  text_file.write(your_data) # to save \"your_data\" within the file\n",
        "  text_file.close() # Close the file (not mandatory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEJpvtE_hMQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Export to Excel\n",
        "data = data_to_save_to_excel\n",
        "xl = pd.ExcelWriter(path + filename)\n",
        "data.to_excel(xl)\n",
        "xl.save()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WNWlKxdatJ1",
        "colab_type": "text"
      },
      "source": [
        "##I. OS / DIRECTORY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_id5ScT6ax7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lirary\n",
        "import os\n",
        "\n",
        "# Basics\n",
        "os.mkdir('sample') # Create directory called \"sample\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBCh1XkJmvpa",
        "colab_type": "text"
      },
      "source": [
        "# **4. VISUALISATION**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f59RNunDriRI",
        "colab_type": "text"
      },
      "source": [
        "See https://colab.research.google.com/notebooks/charts.ipynb for many charts examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpsuDGAOm2Mh",
        "colab_type": "text"
      },
      "source": [
        "## A. SEABORN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBgY2v7Bnb1b",
        "colab_type": "text"
      },
      "source": [
        "> 1 feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXZCiwejm8Yy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DISTRIBUTION PLOT\n",
        "sns.distplot(dataset.feature1, kernel=False) # kernel = False will remove the kernel line => by default = True\n",
        "\n",
        "# CAT PLOT => Compare against the mean\n",
        "# Black line = confidance interval\n",
        "sns.catplot(x=\"feature1\", data=dataset, kind=\"bar\")\n",
        "\n",
        "# BOX PLOT # Easily check the outliers\n",
        "sns.catplot(y\"feature2\", data=dataset, kind=\"box\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqVAQFHBnd3i",
        "colab_type": "text"
      },
      "source": [
        "> 2 features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTMZ0knVnguC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RELATION PLOT\n",
        "sns.relplot(x=\"feature1\", y=\"feature2\", data=dataset)\n",
        "# can use the aspect parameter to increase size\n",
        "sns.relplot(x=\"feature1\", y=\"feature2\", data=dataset, aspect=5)\n",
        "# can add further features using hue, size, style\n",
        "sns.relplot(x=\"feature1\", y=\"feature2\", hue=\"feature3\", size=\"feature4\", style=\"feature5\", data=dataset)\n",
        "\n",
        "\n",
        "# LINE PLOT\n",
        "sns.relplot(x=\"feature1\", y=\"feature2\", data=dataset, kind=\"line\")\n",
        "\n",
        "# BAR PLOT => like CAT plot but compare against y value\n",
        "sns.barplot(x=\"feature1\", y=\"feature2\", data=dataset)\n",
        "\n",
        "# BOX PLOT # Easily check the outliers\n",
        "sns.catplot(x=\"feature1\", y\"feature2\", data=dataset, kind=\"box\")\n",
        "\n",
        "# HEAT MAP => generaly used for correlation matrix\n",
        "sns.heatmap(dataset.corr(), annot=True, fmt='d', center=0) # with 'fmt' not mandatory => to see integer / annot=True to display value / cmap='' to change color\n",
        "\n",
        "# LMPLOT\n",
        "sns.lmplot(x=\"feature1\", y=\"feature2\", data=dataset) # can play with the hue etc.\n",
        "sns.lmplot(x=\"feature1\", y=\"feature2\", data=dataset, logistic=True) # to see logistic.\n",
        "\n",
        "# SCATTER PLOT\n",
        "sns.scatterplot(x= \"feature1\", y= \"feature2\", hue=\"target_value\", data =  dataset)\n",
        "\n",
        "# VIOLON PLOT => like BOX plot to see outliers\n",
        "sns.violinplot(x=\"feature1\", y=\"feature2\", data=dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKGRDh84YQ3I",
        "colab_type": "text"
      },
      "source": [
        "> Every Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ntNgrZCYPdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PAIRPLOTS => it takes some time to be made\n",
        "sns.pairplots(dataset)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp3_LILem5Wq",
        "colab_type": "text"
      },
      "source": [
        "## B. MATPLOTLIB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFoOSgrOBOek",
        "colab_type": "text"
      },
      "source": [
        "We will use mainly the Object-Oriented Interface => ex: fig, ax = plt.subplots(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA3Ebd1bJ4wO",
        "colab_type": "text"
      },
      "source": [
        "I. General Tips"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byiAX2Oe4DSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DATA inputs : Recommended to input numpy data instead of pandas\n",
        "ds.values # => transform pdandas to numpy data\n",
        "\n",
        "# Can set your parameters in dictionnary and call them later on using **name of the dictionary\n",
        "style = dict(color=\"C8\", linewidth=2, linestyle=\"--\", marker=\"o\")\n",
        "plt.plot(x, y, **style) # if not using **style then create error because do NOT understand the dictionnary and do NOT transfomr it in parameters for the plot.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaSOfc3zFl0y",
        "colab_type": "text"
      },
      "source": [
        "II. Basic Setups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTKbITaPOZV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Figure is the overal component with subdivisions called 'subplots' or 'axes'\n",
        "plt.figure()  # create a plot figure (may contains multiple plots/charts)\n",
        "\n",
        "# Global figure style\n",
        "plt.style.use('classic')\n",
        "plt.style.use('bmh')\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.style.use('seaborn-colorblind')\n",
        "\n",
        "plt.style.available[:] # See all styles available\n",
        "\n",
        "# FIG SIZE SETTINGS\n",
        "fig.set_size_inches(15,15) # Set size all figures\n",
        "plt.subplots(figsize=(20, 5)) # other options for 1 plot\n",
        "\n",
        "  # C. SubPlot (aka axes)\n",
        "fig, ax = plt.subplots(2, 2) # Create subplots grids with 2 x 2 subplots within it\n",
        "fig, ax = plt.subplots(2, 3, sharex='col', sharey='row') # 2 Rows & 3 columns | Share x legend per column + share y legend per colonne => choose 'all' to share withn whole subplots\n",
        "# You call each ax through slicing\n",
        "ax[0, 1] to get the subplots in the 1st row (index 0) and 2nd column (index 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FmbpaAa54v7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "outputId": "11ee7625-6b49-4b35-921b-5a0e1315eea8"
      },
      "source": [
        "# 3. PLOT TYPES\n",
        "\n",
        "fig, ax = plt.subplots(4,3)\n",
        "fig.set_size_inches(15,10)\n",
        "\n",
        "ds = pd.DataFrame({\"C1\":[1,2,3,4], \"C2\":[9,8,7,6]})\n",
        "x = ds.iloc[:, 0]\n",
        "y = ds.iloc[:, 1]\n",
        "z = np.random.randn(150, 1)\n",
        "data1, data2 = np.random.randn(2,1000)\n",
        "\n",
        "\n",
        "#LINE PLOT\n",
        "ax[0,0].plot(x, y) # grid 0\n",
        "\n",
        "style = dict(color=\"C8\", linewidth=2, linestyle=\"--\", marker=\"o\")\n",
        "ax[0,1].plot(x, y + 1, **style) # grid 0\n",
        "\n",
        "#SCATTERPLOT : # = relplot with kind = 'scatter' (scatter = a point cloud)\n",
        "x = np.random.randint(0, 100, size = 20)\n",
        "y = np.random.randint(0, 50, size = 20)\n",
        "ax[0,2].scatter(x, y, marker=\"x\", color=\"C5\")\n",
        "\n",
        "# HISTOGRAMME\n",
        "ax[1,0].hist(z, bins=100, color=\"C1\") #Colors => C0 à C9 \n",
        "\n",
        "# KDEPLOT : kernel density estimation #noyau dur de vos données => CAN ADD SEARBORN PLOTS\n",
        "sns.kdeplot([1,2,3,4,5,6,7],[22,12,56,73,23,78,53], shade=True, shade_lowest=True, ax=ax[1,1])\n",
        "\n",
        "# PIE CHART\n",
        "ax[1,2].pie([2,3,1,5], labels=[\"Car\", \"Trucks\", \"Motorbikes\", \"Bikes\"], autopct=\"%1.0f%%\", explode=(0, 0.15, 0, 0))\n",
        "\n",
        "# BARPLOT\n",
        "ax[2,0].bar([\"Car\", \"Trucks\", \"Motorbikes\", \"Bikes\"], [2,3,1,5], color=\"C2\")\n",
        "\n",
        "\n",
        "# STACKED BAR : See 1 Categorial value based on several X num values\n",
        "ax[2,1].bar([\"Car\", \"Trucks\", \"Motorbikes\", \"Bikes\"], [2,3,1,5], color=\"C2\")\n",
        "ax[2,1].bar([\"Car\", \"Trucks\", \"Motorbikes\", \"Bikes\"], [6,7,8,9], bottom = [2,3,1,5])\n",
        "ax[2,1].bar([\"Car\", \"Trucks\", \"Motorbikes\", \"Bikes\"], [6,7,8,9], bottom = [8,10,9,14])\n",
        "\n",
        "ax[2,2].bar([\"Car\", \"Trucks\", \"Motorbikes\", \"Bikes\"], [2,3,1,5], color=\"C2\")\n",
        "ax[2,2].bar([\"Car\", \"Trucks\", \"Motorbikes\", \"Bikes\"], [6,7,8,9], color=\"C7\")\n",
        "ax[2,2].set_title(\"Car reparis\", fontsize = 15)\n",
        "\n",
        "# BOXPLOT\n",
        "ax[3,0].boxplot(data1, showmeans=True, meanline=True)\n",
        "\n",
        "\n",
        "# STACKED BAR INTELLIGENT\n",
        "names = [\"Car\", \"Motorbikes\", \"Scooter\"]\n",
        "values = [1,10,100]\n",
        "values2 = [7,3,10]\n",
        "\n",
        "# SEVERAL CHARTS SAME SUBPLOTS\n",
        "t = np.arange(0,2,0.01)\n",
        "s = np.sin(2*np.pi*t) #equation de la fonction sin\n",
        "u = 1 + np.log(2*t) #equation de la fonction log\n",
        "\n",
        "ax[3, 1].plot(t,s, linestyle='--')\n",
        "ax[3, 1].plot(t,u)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x720 with 12 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_EfmQARVFD2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "43afd06c-d672-4a3a-e764-8a2584616f18"
      },
      "source": [
        "#STACKED BAR => further details\n",
        "\n",
        "plt.figure()\n",
        "fig.set_size_inches(5,5)\n",
        "\n",
        "names = [\"Cars\", \"Motorbikes\", \"Bikes\"]\n",
        "values = [1,10,100]\n",
        "values2 = [7,3,10]\n",
        "\n",
        "plt.bar(names, values)\n",
        "plt.bar(names, values2, bottom=values)\n",
        "plt.title(\"This is a Title\")\n",
        "plt.legend([\"France\", \"OV\"], loc='best') # loc='best' to put legend best location \n",
        "plt.xlabel(\"X title\")\n",
        "plt.ylabel(\"Y title\")\n",
        "plt.text(names[0],2, values[0]) # set the size value of the text within each bar\n",
        "plt.text(names[0],10, values2[0])\n",
        "plt.text(names[1],20, values[1]+values2[1])\n",
        "plt.text(names[2],100, values[2]+values2[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(Bikes, 100, '110')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z27lVya1V9wM",
        "colab_type": "text"
      },
      "source": [
        "III. SPECIFIC UTLIZATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcJsT_jNEvv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize target value for each features\n",
        "f, ax = plt.subplots(8,1,figsize = (20,30)) #8 because 8 features and 1 because we want to see only 1 chart at a time\n",
        "for i,a in zip(X_train.columns,ax):\n",
        "  sns.pointplot(x=i, y=\"Outcome\", data=dataset, ax = a, join=False, ci=None) # Outcome is the column name of your target value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZsDVcP0V5Aj",
        "colab_type": "text"
      },
      "source": [
        "IV. EXPORT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adpeL1bNNrTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EXPORT\n",
        "fig.savefig('my_figure.png') # save file in working directory to png format\n",
        "# fileformat : 'jpg' / 'jpeg' / 'pdf' / 'tiff'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8U6nBQXWrCK",
        "colab_type": "text"
      },
      "source": [
        "> Color Type\n",
        "\n",
        "See : https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html for color schemes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-LW0Hm6Wzrb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import cm\n",
        "\n",
        "# 1 color\n",
        "cmap=\"gray\" # basic gray\n",
        "cmap=\"gray_r\" # return opposite / reverse of \"gray\"\n",
        "\n",
        "# 1 color (from white to color)\n",
        "\n",
        "cmap=\"Greys\" # White => Grey => Black\n",
        "cmap=\"Blues\" # White => Blue \n",
        "\n",
        "# 2 colors : color_1 => white => color_2\n",
        "cmap=\"PRGn\" # Purple => White => Green\n",
        "cmap=\"PiYG\" # Pink => White => Green\n",
        "cmap=\"bwr\" # Blue => White => Red\n",
        "\n",
        "# 3 colors : color_1 => color_2 => color_3\n",
        "cmap=\"RdYlBu\" # Red => Yellow => Blue\n",
        "cmap=\"YlOrRd\" # Yellow => Orange => Red\n",
        "\n",
        "# \"Funny\" ones\n",
        "cmap=\"spring\" #   Pink => Orange => Yellow\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLgFpBb8rTC-",
        "colab_type": "text"
      },
      "source": [
        "## C. IMAGES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ej8uUDvKr_Se",
        "colab_type": "text"
      },
      "source": [
        "> using sklearn dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Leh_xxp0rWGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import images from sklearn\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "faces = fetch_lfw_people(min_faces_per_person=60) # min_faces_per_person => to filter anyone with fewer than 60 images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtuhRUQSrnCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Dataframe\n",
        "dataset = pd.DataFrame(data=faces.data)\n",
        "# Dataset will get : \n",
        "# each row = 1 image\n",
        "# each column = pixel (index 0 = first pixel top left, 1 = 2nd pixel top left etc.)\n",
        "# each value = pixel intensity (in this case 0 to 255 => because grey image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPBypVlIsM1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display image\n",
        "plt.imshow(faces.images[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGDw0cj7sRCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display image with label name below\n",
        "i = 0\n",
        "plt.imshow(faces.images[i])\n",
        "plt.xlabel(faces.target_names[faces.target[i]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-Z9RsmFsb0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To show 15 first images\n",
        "fig, ax = plt.subplots(3, 5, figsize=(10, 10))\n",
        "for i, axi in enumerate(ax.flat):\n",
        "  axi.imshow(faces.images[i], cmap='bone')\n",
        "  axi.set(xticks=[], yticks=[], xlabel=faces.target_names[faces.target[i]])\n",
        "\n",
        "# To show 15 images from dataframe\n",
        "fig, ax = plt.subplots(3, 5, figsize=(10, 10))\n",
        "for i, axi in enumerate(ax.flat):\n",
        "  axi.imshow(ds[i].reshape[28, 28], cmap='bone')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIampn5Mdpic",
        "colab_type": "text"
      },
      "source": [
        "## D. ALTAIR - Interactive "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL0lSiYJdtmr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "5f063aa1-1d47-41c2-d37c-5bd24ffc8900"
      },
      "source": [
        "# PLEASE NOTE Rows limitation (5 000 max)!\n",
        "import altair as alt\n",
        "from vega_datasets import data\n",
        "cars = data.cars()\n",
        "\n",
        "alt.Chart(cars).mark_point().encode(\n",
        "    x='Horsepower',\n",
        "    y='Miles_per_Gallon',\n",
        "    color='Origin',\n",
        ").interactive()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "alt.Chart(...)"
            ],
            "text/html": [
              "\n",
              "<div id=\"altair-viz-2350f52a5a86446eb15fb4fc91319d7c\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-2350f52a5a86446eb15fb4fc91319d7c\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-2350f52a5a86446eb15fb4fc91319d7c\");\n",
              "    }\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function loadScript(lib) {\n",
              "      return new Promise(function(resolve, reject) {\n",
              "        var s = document.createElement('script');\n",
              "        s.src = paths[lib];\n",
              "        s.async = true;\n",
              "        s.onload = () => resolve(paths[lib]);\n",
              "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "      });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else if (typeof vegaEmbed === \"function\") {\n",
              "      displayChart(vegaEmbed);\n",
              "    } else {\n",
              "      loadScript(\"vega\")\n",
              "        .then(() => loadScript(\"vega-lite\"))\n",
              "        .then(() => loadScript(\"vega-embed\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-f02450ab61490a1363517a0190416235\"}, \"mark\": \"point\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Origin\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"Horsepower\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"Miles_per_Gallon\"}}, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-f02450ab61490a1363517a0190416235\": [{\"Name\": \"chevrolet chevelle malibu\", \"Miles_per_Gallon\": 18.0, \"Cylinders\": 8, \"Displacement\": 307.0, \"Horsepower\": 130.0, \"Weight_in_lbs\": 3504, \"Acceleration\": 12.0, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"buick skylark 320\", \"Miles_per_Gallon\": 15.0, \"Cylinders\": 8, \"Displacement\": 350.0, \"Horsepower\": 165.0, \"Weight_in_lbs\": 3693, \"Acceleration\": 11.5, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"plymouth satellite\", \"Miles_per_Gallon\": 18.0, \"Cylinders\": 8, \"Displacement\": 318.0, \"Horsepower\": 150.0, \"Weight_in_lbs\": 3436, \"Acceleration\": 11.0, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"amc rebel sst\", \"Miles_per_Gallon\": 16.0, \"Cylinders\": 8, \"Displacement\": 304.0, \"Horsepower\": 150.0, \"Weight_in_lbs\": 3433, \"Acceleration\": 12.0, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford torino\", \"Miles_per_Gallon\": 17.0, \"Cylinders\": 8, \"Displacement\": 302.0, \"Horsepower\": 140.0, \"Weight_in_lbs\": 3449, \"Acceleration\": 10.5, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford galaxie 500\", \"Miles_per_Gallon\": 15.0, \"Cylinders\": 8, \"Displacement\": 429.0, \"Horsepower\": 198.0, \"Weight_in_lbs\": 4341, \"Acceleration\": 10.0, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet impala\", \"Miles_per_Gallon\": 14.0, \"Cylinders\": 8, \"Displacement\": 454.0, \"Horsepower\": 220.0, \"Weight_in_lbs\": 4354, \"Acceleration\": 9.0, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"plymouth fury iii\", \"Miles_per_Gallon\": 14.0, \"Cylinders\": 8, \"Displacement\": 440.0, \"Horsepower\": 215.0, \"Weight_in_lbs\": 4312, \"Acceleration\": 8.5, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"pontiac catalina\", \"Miles_per_Gallon\": 14.0, \"Cylinders\": 8, \"Displacement\": 455.0, \"Horsepower\": 225.0, \"Weight_in_lbs\": 4425, \"Acceleration\": 10.0, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"amc ambassador dpl\", \"Miles_per_Gallon\": 15.0, \"Cylinders\": 8, \"Displacement\": 390.0, \"Horsepower\": 190.0, \"Weight_in_lbs\": 3850, \"Acceleration\": 8.5, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"citroen ds-21 pallas\", \"Miles_per_Gallon\": null, \"Cylinders\": 4, \"Displacement\": 133.0, \"Horsepower\": 115.0, \"Weight_in_lbs\": 3090, \"Acceleration\": 17.5, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"chevrolet chevelle concours (sw)\", \"Miles_per_Gallon\": null, \"Cylinders\": 8, \"Displacement\": 350.0, \"Horsepower\": 165.0, \"Weight_in_lbs\": 4142, \"Acceleration\": 11.5, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford torino (sw)\", \"Miles_per_Gallon\": null, \"Cylinders\": 8, \"Displacement\": 351.0, \"Horsepower\": 153.0, \"Weight_in_lbs\": 4034, \"Acceleration\": 11.0, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"plymouth satellite (sw)\", \"Miles_per_Gallon\": null, \"Cylinders\": 8, \"Displacement\": 383.0, \"Horsepower\": 175.0, \"Weight_in_lbs\": 4166, \"Acceleration\": 10.5, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"amc rebel sst (sw)\", \"Miles_per_Gallon\": null, \"Cylinders\": 8, \"Displacement\": 360.0, \"Horsepower\": 175.0, \"Weight_in_lbs\": 3850, \"Acceleration\": 11.0, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"dodge challenger se\", \"Miles_per_Gallon\": 15.0, \"Cylinders\": 8, \"Displacement\": 383.0, \"Horsepower\": 170.0, \"Weight_in_lbs\": 3563, \"Acceleration\": 10.0, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"plymouth 'cuda 340\", \"Miles_per_Gallon\": 14.0, \"Cylinders\": 8, \"Displacement\": 340.0, \"Horsepower\": 160.0, \"Weight_in_lbs\": 3609, \"Acceleration\": 8.0, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford mustang boss 302\", \"Miles_per_Gallon\": null, \"Cylinders\": 8, \"Displacement\": 302.0, \"Horsepower\": 140.0, \"Weight_in_lbs\": 3353, \"Acceleration\": 8.0, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet monte carlo\", \"Miles_per_Gallon\": 15.0, \"Cylinders\": 8, \"Displacement\": 400.0, \"Horsepower\": 150.0, \"Weight_in_lbs\": 3761, \"Acceleration\": 9.5, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"buick estate wagon (sw)\", \"Miles_per_Gallon\": 14.0, \"Cylinders\": 8, \"Displacement\": 455.0, \"Horsepower\": 225.0, \"Weight_in_lbs\": 3086, \"Acceleration\": 10.0, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"toyota corona mark ii\", \"Miles_per_Gallon\": 24.0, \"Cylinders\": 4, \"Displacement\": 113.0, \"Horsepower\": 95.0, \"Weight_in_lbs\": 2372, \"Acceleration\": 15.0, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"plymouth duster\", \"Miles_per_Gallon\": 22.0, \"Cylinders\": 6, \"Displacement\": 198.0, \"Horsepower\": 95.0, \"Weight_in_lbs\": 2833, \"Acceleration\": 15.5, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"amc hornet\", \"Miles_per_Gallon\": 18.0, \"Cylinders\": 6, \"Displacement\": 199.0, \"Horsepower\": 97.0, \"Weight_in_lbs\": 2774, \"Acceleration\": 15.5, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford maverick\", \"Miles_per_Gallon\": 21.0, \"Cylinders\": 6, \"Displacement\": 200.0, \"Horsepower\": 85.0, \"Weight_in_lbs\": 2587, \"Acceleration\": 16.0, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"datsun pl510\", \"Miles_per_Gallon\": 27.0, \"Cylinders\": 4, \"Displacement\": 97.0, \"Horsepower\": 88.0, \"Weight_in_lbs\": 2130, \"Acceleration\": 14.5, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"volkswagen 1131 deluxe sedan\", \"Miles_per_Gallon\": 26.0, \"Cylinders\": 4, \"Displacement\": 97.0, \"Horsepower\": 46.0, \"Weight_in_lbs\": 1835, \"Acceleration\": 20.5, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"peugeot 504\", \"Miles_per_Gallon\": 25.0, \"Cylinders\": 4, \"Displacement\": 110.0, \"Horsepower\": 87.0, \"Weight_in_lbs\": 2672, \"Acceleration\": 17.5, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"audi 100 ls\", \"Miles_per_Gallon\": 24.0, \"Cylinders\": 4, \"Displacement\": 107.0, \"Horsepower\": 90.0, \"Weight_in_lbs\": 2430, \"Acceleration\": 14.5, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"saab 99e\", \"Miles_per_Gallon\": 25.0, \"Cylinders\": 4, \"Displacement\": 104.0, \"Horsepower\": 95.0, \"Weight_in_lbs\": 2375, \"Acceleration\": 17.5, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"bmw 2002\", \"Miles_per_Gallon\": 26.0, \"Cylinders\": 4, \"Displacement\": 121.0, \"Horsepower\": 113.0, \"Weight_in_lbs\": 2234, \"Acceleration\": 12.5, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"amc gremlin\", \"Miles_per_Gallon\": 21.0, \"Cylinders\": 6, \"Displacement\": 199.0, \"Horsepower\": 90.0, \"Weight_in_lbs\": 2648, \"Acceleration\": 15.0, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford f250\", \"Miles_per_Gallon\": 10.0, \"Cylinders\": 8, \"Displacement\": 360.0, \"Horsepower\": 215.0, \"Weight_in_lbs\": 4615, \"Acceleration\": 14.0, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevy c20\", \"Miles_per_Gallon\": 10.0, \"Cylinders\": 8, \"Displacement\": 307.0, \"Horsepower\": 200.0, \"Weight_in_lbs\": 4376, \"Acceleration\": 15.0, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"dodge d200\", \"Miles_per_Gallon\": 11.0, \"Cylinders\": 8, \"Displacement\": 318.0, \"Horsepower\": 210.0, \"Weight_in_lbs\": 4382, \"Acceleration\": 13.5, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"hi 1200d\", \"Miles_per_Gallon\": 9.0, \"Cylinders\": 8, \"Displacement\": 304.0, \"Horsepower\": 193.0, \"Weight_in_lbs\": 4732, \"Acceleration\": 18.5, \"Year\": \"1970-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"datsun pl510\", \"Miles_per_Gallon\": 27.0, \"Cylinders\": 4, \"Displacement\": 97.0, \"Horsepower\": 88.0, \"Weight_in_lbs\": 2130, \"Acceleration\": 14.5, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"chevrolet vega 2300\", \"Miles_per_Gallon\": 28.0, \"Cylinders\": 4, \"Displacement\": 140.0, \"Horsepower\": 90.0, \"Weight_in_lbs\": 2264, \"Acceleration\": 15.5, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"toyota corona\", \"Miles_per_Gallon\": 25.0, \"Cylinders\": 4, \"Displacement\": 113.0, \"Horsepower\": 95.0, \"Weight_in_lbs\": 2228, \"Acceleration\": 14.0, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"ford pinto\", \"Miles_per_Gallon\": 25.0, \"Cylinders\": 4, \"Displacement\": 98.0, \"Horsepower\": null, \"Weight_in_lbs\": 2046, \"Acceleration\": 19.0, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"volkswagen super beetle 117\", \"Miles_per_Gallon\": null, \"Cylinders\": 4, \"Displacement\": 97.0, \"Horsepower\": 48.0, \"Weight_in_lbs\": 1978, \"Acceleration\": 20.0, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"amc gremlin\", \"Miles_per_Gallon\": 19.0, \"Cylinders\": 6, \"Displacement\": 232.0, \"Horsepower\": 100.0, \"Weight_in_lbs\": 2634, \"Acceleration\": 13.0, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"plymouth satellite custom\", \"Miles_per_Gallon\": 16.0, \"Cylinders\": 6, \"Displacement\": 225.0, \"Horsepower\": 105.0, \"Weight_in_lbs\": 3439, \"Acceleration\": 15.5, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet chevelle malibu\", \"Miles_per_Gallon\": 17.0, \"Cylinders\": 6, \"Displacement\": 250.0, \"Horsepower\": 100.0, \"Weight_in_lbs\": 3329, \"Acceleration\": 15.5, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford torino 500\", \"Miles_per_Gallon\": 19.0, \"Cylinders\": 6, \"Displacement\": 250.0, \"Horsepower\": 88.0, \"Weight_in_lbs\": 3302, \"Acceleration\": 15.5, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"amc matador\", \"Miles_per_Gallon\": 18.0, \"Cylinders\": 6, \"Displacement\": 232.0, \"Horsepower\": 100.0, \"Weight_in_lbs\": 3288, \"Acceleration\": 15.5, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet impala\", \"Miles_per_Gallon\": 14.0, \"Cylinders\": 8, \"Displacement\": 350.0, \"Horsepower\": 165.0, \"Weight_in_lbs\": 4209, \"Acceleration\": 12.0, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"pontiac catalina brougham\", \"Miles_per_Gallon\": 14.0, \"Cylinders\": 8, \"Displacement\": 400.0, \"Horsepower\": 175.0, \"Weight_in_lbs\": 4464, \"Acceleration\": 11.5, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford galaxie 500\", \"Miles_per_Gallon\": 14.0, \"Cylinders\": 8, \"Displacement\": 351.0, \"Horsepower\": 153.0, \"Weight_in_lbs\": 4154, \"Acceleration\": 13.5, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"plymouth fury iii\", \"Miles_per_Gallon\": 14.0, \"Cylinders\": 8, \"Displacement\": 318.0, \"Horsepower\": 150.0, \"Weight_in_lbs\": 4096, \"Acceleration\": 13.0, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"dodge monaco (sw)\", \"Miles_per_Gallon\": 12.0, \"Cylinders\": 8, \"Displacement\": 383.0, \"Horsepower\": 180.0, \"Weight_in_lbs\": 4955, \"Acceleration\": 11.5, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford country squire (sw)\", \"Miles_per_Gallon\": 13.0, \"Cylinders\": 8, \"Displacement\": 400.0, \"Horsepower\": 170.0, \"Weight_in_lbs\": 4746, \"Acceleration\": 12.0, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"pontiac safari (sw)\", \"Miles_per_Gallon\": 13.0, \"Cylinders\": 8, \"Displacement\": 400.0, \"Horsepower\": 175.0, \"Weight_in_lbs\": 5140, \"Acceleration\": 12.0, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"amc hornet sportabout (sw)\", \"Miles_per_Gallon\": 18.0, \"Cylinders\": 6, \"Displacement\": 258.0, \"Horsepower\": 110.0, \"Weight_in_lbs\": 2962, \"Acceleration\": 13.5, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet vega (sw)\", \"Miles_per_Gallon\": 22.0, \"Cylinders\": 4, \"Displacement\": 140.0, \"Horsepower\": 72.0, \"Weight_in_lbs\": 2408, \"Acceleration\": 19.0, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"pontiac firebird\", \"Miles_per_Gallon\": 19.0, \"Cylinders\": 6, \"Displacement\": 250.0, \"Horsepower\": 100.0, \"Weight_in_lbs\": 3282, \"Acceleration\": 15.0, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford mustang\", \"Miles_per_Gallon\": 18.0, \"Cylinders\": 6, \"Displacement\": 250.0, \"Horsepower\": 88.0, \"Weight_in_lbs\": 3139, \"Acceleration\": 14.5, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"mercury capri 2000\", \"Miles_per_Gallon\": 23.0, \"Cylinders\": 4, \"Displacement\": 122.0, \"Horsepower\": 86.0, \"Weight_in_lbs\": 2220, \"Acceleration\": 14.0, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"opel 1900\", \"Miles_per_Gallon\": 28.0, \"Cylinders\": 4, \"Displacement\": 116.0, \"Horsepower\": 90.0, \"Weight_in_lbs\": 2123, \"Acceleration\": 14.0, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"peugeot 304\", \"Miles_per_Gallon\": 30.0, \"Cylinders\": 4, \"Displacement\": 79.0, \"Horsepower\": 70.0, \"Weight_in_lbs\": 2074, \"Acceleration\": 19.5, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"fiat 124b\", \"Miles_per_Gallon\": 30.0, \"Cylinders\": 4, \"Displacement\": 88.0, \"Horsepower\": 76.0, \"Weight_in_lbs\": 2065, \"Acceleration\": 14.5, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"toyota corolla 1200\", \"Miles_per_Gallon\": 31.0, \"Cylinders\": 4, \"Displacement\": 71.0, \"Horsepower\": 65.0, \"Weight_in_lbs\": 1773, \"Acceleration\": 19.0, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"datsun 1200\", \"Miles_per_Gallon\": 35.0, \"Cylinders\": 4, \"Displacement\": 72.0, \"Horsepower\": 69.0, \"Weight_in_lbs\": 1613, \"Acceleration\": 18.0, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"volkswagen model 111\", \"Miles_per_Gallon\": 27.0, \"Cylinders\": 4, \"Displacement\": 97.0, \"Horsepower\": 60.0, \"Weight_in_lbs\": 1834, \"Acceleration\": 19.0, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"plymouth cricket\", \"Miles_per_Gallon\": 26.0, \"Cylinders\": 4, \"Displacement\": 91.0, \"Horsepower\": 70.0, \"Weight_in_lbs\": 1955, \"Acceleration\": 20.5, \"Year\": \"1971-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"toyota corona hardtop\", \"Miles_per_Gallon\": 24.0, \"Cylinders\": 4, \"Displacement\": 113.0, \"Horsepower\": 95.0, \"Weight_in_lbs\": 2278, \"Acceleration\": 15.5, \"Year\": \"1972-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"dodge colt hardtop\", \"Miles_per_Gallon\": 25.0, \"Cylinders\": 4, \"Displacement\": 97.5, \"Horsepower\": 80.0, \"Weight_in_lbs\": 2126, \"Acceleration\": 17.0, \"Year\": \"1972-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"volkswagen type 3\", \"Miles_per_Gallon\": 23.0, \"Cylinders\": 4, \"Displacement\": 97.0, \"Horsepower\": 54.0, \"Weight_in_lbs\": 2254, \"Acceleration\": 23.5, \"Year\": \"1972-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"chevrolet vega\", \"Miles_per_Gallon\": 20.0, \"Cylinders\": 4, \"Displacement\": 140.0, \"Horsepower\": 90.0, \"Weight_in_lbs\": 2408, \"Acceleration\": 19.5, \"Year\": \"1972-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford pinto runabout\", \"Miles_per_Gallon\": 21.0, \"Cylinders\": 4, \"Displacement\": 122.0, \"Horsepower\": 86.0, \"Weight_in_lbs\": 2226, \"Acceleration\": 16.5, \"Year\": \"1972-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet impala\", \"Miles_per_Gallon\": 13.0, \"Cylinders\": 8, \"Displacement\": 350.0, \"Horsepower\": 165.0, \"Weight_in_lbs\": 4274, \"Acceleration\": 12.0, \"Year\": \"1972-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"pontiac catalina\", \"Miles_per_Gallon\": 14.0, \"Cylinders\": 8, \"Displacement\": 400.0, \"Horsepower\": 175.0, \"Weight_in_lbs\": 4385, \"Acceleration\": 12.0, \"Year\": \"1972-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"plymouth fury iii\", \"Miles_per_Gallon\": 15.0, \"Cylinders\": 8, \"Displacement\": 318.0, \"Horsepower\": 150.0, \"Weight_in_lbs\": 4135, \"Acceleration\": 13.5, \"Year\": \"1972-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford galaxie 500\", \"Miles_per_Gallon\": 14.0, \"Cylinders\": 8, \"Displacement\": 351.0, \"Horsepower\": 153.0, \"Weight_in_lbs\": 4129, \"Acceleration\": 13.0, \"Year\": \"1972-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"amc ambassador sst\", \"Miles_per_Gallon\": 17.0, \"Cylinders\": 8, \"Displacement\": 304.0, \"Horsepower\": 150.0, \"Weight_in_lbs\": 3672, \"Acceleration\": 11.5, \"Year\": \"1972-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"mercury marquis\", \"Miles_per_Gallon\": 11.0, \"Cylinders\": 8, \"Displacement\": 429.0, \"Horsepower\": 208.0, \"Weight_in_lbs\": 4633, \"Acceleration\": 11.0, \"Year\": \"1972-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"buick lesabre custom\", \"Miles_per_Gallon\": 13.0, \"Cylinders\": 8, \"Displacement\": 350.0, \"Horsepower\": 155.0, \"Weight_in_lbs\": 4502, \"Acceleration\": 13.5, \"Year\": \"1972-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"oldsmobile delta 88 royale\", \"Miles_per_Gallon\": 12.0, \"Cylinders\": 8, \"Displacement\": 350.0, \"Horsepower\": 160.0, \"Weight_in_lbs\": 4456, \"Acceleration\": 13.5, \"Year\": \"1972-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chrysler newport royal\", \"Miles_per_Gallon\": 13.0, \"Cylinders\": 8, \"Displacement\": 400.0, \"Horsepower\": 190.0, \"Weight_in_lbs\": 4422, \"Acceleration\": 12.5, \"Year\": \"1972-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"mazda rx2 coupe\", \"Miles_per_Gallon\": 19.0, \"Cylinders\": 3, \"Displacement\": 70.0, \"Horsepower\": 97.0, \"Weight_in_lbs\": 2330, \"Acceleration\": 13.5, \"Year\": \"1972-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"amc matador (sw)\", \"Miles_per_Gallon\": 15.0, \"Cylinders\": 8, \"Displacement\": 304.0, \"Horsepower\": 150.0, \"Weight_in_lbs\": 3892, \"Acceleration\": 12.5, \"Year\": \"1972-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet chevelle concours (sw)\", \"Miles_per_Gallon\": 13.0, \"Cylinders\": 8, \"Displacement\": 307.0, \"Horsepower\": 130.0, \"Weight_in_lbs\": 4098, \"Acceleration\": 14.0, \"Year\": \"1972-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford gran torino (sw)\", \"Miles_per_Gallon\": 13.0, \"Cylinders\": 8, \"Displacement\": 302.0, \"Horsepower\": 140.0, \"Weight_in_lbs\": 4294, \"Acceleration\": 16.0, \"Year\": \"1972-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"plymouth satellite custom (sw)\", \"Miles_per_Gallon\": 14.0, \"Cylinders\": 8, \"Displacement\": 318.0, \"Horsepower\": 150.0, \"Weight_in_lbs\": 4077, \"Acceleration\": 14.0, \"Year\": \"1972-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"volvo 145e (sw)\", \"Miles_per_Gallon\": 18.0, \"Cylinders\": 4, \"Displacement\": 121.0, \"Horsepower\": 112.0, \"Weight_in_lbs\": 2933, \"Acceleration\": 14.5, \"Year\": \"1972-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"volkswagen 411 (sw)\", \"Miles_per_Gallon\": 22.0, \"Cylinders\": 4, \"Displacement\": 121.0, \"Horsepower\": 76.0, \"Weight_in_lbs\": 2511, \"Acceleration\": 18.0, \"Year\": \"1972-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"peugeot 504 (sw)\", \"Miles_per_Gallon\": 21.0, \"Cylinders\": 4, \"Displacement\": 120.0, \"Horsepower\": 87.0, \"Weight_in_lbs\": 2979, \"Acceleration\": 19.5, \"Year\": \"1972-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"renault 12 (sw)\", \"Miles_per_Gallon\": 26.0, \"Cylinders\": 4, \"Displacement\": 96.0, \"Horsepower\": 69.0, \"Weight_in_lbs\": 2189, \"Acceleration\": 18.0, \"Year\": \"1972-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"ford pinto (sw)\", \"Miles_per_Gallon\": 22.0, \"Cylinders\": 4, \"Displacement\": 122.0, \"Horsepower\": 86.0, \"Weight_in_lbs\": 2395, \"Acceleration\": 16.0, \"Year\": \"1972-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"datsun 510 (sw)\", \"Miles_per_Gallon\": 28.0, \"Cylinders\": 4, \"Displacement\": 97.0, \"Horsepower\": 92.0, \"Weight_in_lbs\": 2288, \"Acceleration\": 17.0, \"Year\": \"1972-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"toyouta corona mark ii (sw)\", \"Miles_per_Gallon\": 23.0, \"Cylinders\": 4, \"Displacement\": 120.0, \"Horsepower\": 97.0, \"Weight_in_lbs\": 2506, \"Acceleration\": 14.5, \"Year\": \"1972-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"dodge colt (sw)\", \"Miles_per_Gallon\": 28.0, \"Cylinders\": 4, \"Displacement\": 98.0, \"Horsepower\": 80.0, \"Weight_in_lbs\": 2164, \"Acceleration\": 15.0, \"Year\": \"1972-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"toyota corolla 1600 (sw)\", \"Miles_per_Gallon\": 27.0, \"Cylinders\": 4, \"Displacement\": 97.0, \"Horsepower\": 88.0, \"Weight_in_lbs\": 2100, \"Acceleration\": 16.5, \"Year\": \"1972-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"buick century 350\", \"Miles_per_Gallon\": 13.0, \"Cylinders\": 8, \"Displacement\": 350.0, \"Horsepower\": 175.0, \"Weight_in_lbs\": 4100, \"Acceleration\": 13.0, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"amc matador\", \"Miles_per_Gallon\": 14.0, \"Cylinders\": 8, \"Displacement\": 304.0, \"Horsepower\": 150.0, \"Weight_in_lbs\": 3672, \"Acceleration\": 11.5, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet malibu\", \"Miles_per_Gallon\": 13.0, \"Cylinders\": 8, \"Displacement\": 350.0, \"Horsepower\": 145.0, \"Weight_in_lbs\": 3988, \"Acceleration\": 13.0, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford gran torino\", \"Miles_per_Gallon\": 14.0, \"Cylinders\": 8, \"Displacement\": 302.0, \"Horsepower\": 137.0, \"Weight_in_lbs\": 4042, \"Acceleration\": 14.5, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"dodge coronet custom\", \"Miles_per_Gallon\": 15.0, \"Cylinders\": 8, \"Displacement\": 318.0, \"Horsepower\": 150.0, \"Weight_in_lbs\": 3777, \"Acceleration\": 12.5, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"mercury marquis brougham\", \"Miles_per_Gallon\": 12.0, \"Cylinders\": 8, \"Displacement\": 429.0, \"Horsepower\": 198.0, \"Weight_in_lbs\": 4952, \"Acceleration\": 11.5, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet caprice classic\", \"Miles_per_Gallon\": 13.0, \"Cylinders\": 8, \"Displacement\": 400.0, \"Horsepower\": 150.0, \"Weight_in_lbs\": 4464, \"Acceleration\": 12.0, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford ltd\", \"Miles_per_Gallon\": 13.0, \"Cylinders\": 8, \"Displacement\": 351.0, \"Horsepower\": 158.0, \"Weight_in_lbs\": 4363, \"Acceleration\": 13.0, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"plymouth fury gran sedan\", \"Miles_per_Gallon\": 14.0, \"Cylinders\": 8, \"Displacement\": 318.0, \"Horsepower\": 150.0, \"Weight_in_lbs\": 4237, \"Acceleration\": 14.5, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chrysler new yorker brougham\", \"Miles_per_Gallon\": 13.0, \"Cylinders\": 8, \"Displacement\": 440.0, \"Horsepower\": 215.0, \"Weight_in_lbs\": 4735, \"Acceleration\": 11.0, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"buick electra 225 custom\", \"Miles_per_Gallon\": 12.0, \"Cylinders\": 8, \"Displacement\": 455.0, \"Horsepower\": 225.0, \"Weight_in_lbs\": 4951, \"Acceleration\": 11.0, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"amc ambassador brougham\", \"Miles_per_Gallon\": 13.0, \"Cylinders\": 8, \"Displacement\": 360.0, \"Horsepower\": 175.0, \"Weight_in_lbs\": 3821, \"Acceleration\": 11.0, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"plymouth valiant\", \"Miles_per_Gallon\": 18.0, \"Cylinders\": 6, \"Displacement\": 225.0, \"Horsepower\": 105.0, \"Weight_in_lbs\": 3121, \"Acceleration\": 16.5, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet nova custom\", \"Miles_per_Gallon\": 16.0, \"Cylinders\": 6, \"Displacement\": 250.0, \"Horsepower\": 100.0, \"Weight_in_lbs\": 3278, \"Acceleration\": 18.0, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"amc hornet\", \"Miles_per_Gallon\": 18.0, \"Cylinders\": 6, \"Displacement\": 232.0, \"Horsepower\": 100.0, \"Weight_in_lbs\": 2945, \"Acceleration\": 16.0, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford maverick\", \"Miles_per_Gallon\": 18.0, \"Cylinders\": 6, \"Displacement\": 250.0, \"Horsepower\": 88.0, \"Weight_in_lbs\": 3021, \"Acceleration\": 16.5, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"plymouth duster\", \"Miles_per_Gallon\": 23.0, \"Cylinders\": 6, \"Displacement\": 198.0, \"Horsepower\": 95.0, \"Weight_in_lbs\": 2904, \"Acceleration\": 16.0, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"volkswagen super beetle\", \"Miles_per_Gallon\": 26.0, \"Cylinders\": 4, \"Displacement\": 97.0, \"Horsepower\": 46.0, \"Weight_in_lbs\": 1950, \"Acceleration\": 21.0, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"chevrolet impala\", \"Miles_per_Gallon\": 11.0, \"Cylinders\": 8, \"Displacement\": 400.0, \"Horsepower\": 150.0, \"Weight_in_lbs\": 4997, \"Acceleration\": 14.0, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford country\", \"Miles_per_Gallon\": 12.0, \"Cylinders\": 8, \"Displacement\": 400.0, \"Horsepower\": 167.0, \"Weight_in_lbs\": 4906, \"Acceleration\": 12.5, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"plymouth custom suburb\", \"Miles_per_Gallon\": 13.0, \"Cylinders\": 8, \"Displacement\": 360.0, \"Horsepower\": 170.0, \"Weight_in_lbs\": 4654, \"Acceleration\": 13.0, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"oldsmobile vista cruiser\", \"Miles_per_Gallon\": 12.0, \"Cylinders\": 8, \"Displacement\": 350.0, \"Horsepower\": 180.0, \"Weight_in_lbs\": 4499, \"Acceleration\": 12.5, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"amc gremlin\", \"Miles_per_Gallon\": 18.0, \"Cylinders\": 6, \"Displacement\": 232.0, \"Horsepower\": 100.0, \"Weight_in_lbs\": 2789, \"Acceleration\": 15.0, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"toyota carina\", \"Miles_per_Gallon\": 20.0, \"Cylinders\": 4, \"Displacement\": 97.0, \"Horsepower\": 88.0, \"Weight_in_lbs\": 2279, \"Acceleration\": 19.0, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"chevrolet vega\", \"Miles_per_Gallon\": 21.0, \"Cylinders\": 4, \"Displacement\": 140.0, \"Horsepower\": 72.0, \"Weight_in_lbs\": 2401, \"Acceleration\": 19.5, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"datsun 610\", \"Miles_per_Gallon\": 22.0, \"Cylinders\": 4, \"Displacement\": 108.0, \"Horsepower\": 94.0, \"Weight_in_lbs\": 2379, \"Acceleration\": 16.5, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"maxda rx3\", \"Miles_per_Gallon\": 18.0, \"Cylinders\": 3, \"Displacement\": 70.0, \"Horsepower\": 90.0, \"Weight_in_lbs\": 2124, \"Acceleration\": 13.5, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"ford pinto\", \"Miles_per_Gallon\": 19.0, \"Cylinders\": 4, \"Displacement\": 122.0, \"Horsepower\": 85.0, \"Weight_in_lbs\": 2310, \"Acceleration\": 18.5, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"mercury capri v6\", \"Miles_per_Gallon\": 21.0, \"Cylinders\": 6, \"Displacement\": 155.0, \"Horsepower\": 107.0, \"Weight_in_lbs\": 2472, \"Acceleration\": 14.0, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"fiat 124 sport coupe\", \"Miles_per_Gallon\": 26.0, \"Cylinders\": 4, \"Displacement\": 98.0, \"Horsepower\": 90.0, \"Weight_in_lbs\": 2265, \"Acceleration\": 15.5, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"chevrolet monte carlo s\", \"Miles_per_Gallon\": 15.0, \"Cylinders\": 8, \"Displacement\": 350.0, \"Horsepower\": 145.0, \"Weight_in_lbs\": 4082, \"Acceleration\": 13.0, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"pontiac grand prix\", \"Miles_per_Gallon\": 16.0, \"Cylinders\": 8, \"Displacement\": 400.0, \"Horsepower\": 230.0, \"Weight_in_lbs\": 4278, \"Acceleration\": 9.5, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"fiat 128\", \"Miles_per_Gallon\": 29.0, \"Cylinders\": 4, \"Displacement\": 68.0, \"Horsepower\": 49.0, \"Weight_in_lbs\": 1867, \"Acceleration\": 19.5, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"opel manta\", \"Miles_per_Gallon\": 24.0, \"Cylinders\": 4, \"Displacement\": 116.0, \"Horsepower\": 75.0, \"Weight_in_lbs\": 2158, \"Acceleration\": 15.5, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"audi 100ls\", \"Miles_per_Gallon\": 20.0, \"Cylinders\": 4, \"Displacement\": 114.0, \"Horsepower\": 91.0, \"Weight_in_lbs\": 2582, \"Acceleration\": 14.0, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"volvo 144ea\", \"Miles_per_Gallon\": 19.0, \"Cylinders\": 4, \"Displacement\": 121.0, \"Horsepower\": 112.0, \"Weight_in_lbs\": 2868, \"Acceleration\": 15.5, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"dodge dart custom\", \"Miles_per_Gallon\": 15.0, \"Cylinders\": 8, \"Displacement\": 318.0, \"Horsepower\": 150.0, \"Weight_in_lbs\": 3399, \"Acceleration\": 11.0, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"saab 99le\", \"Miles_per_Gallon\": 24.0, \"Cylinders\": 4, \"Displacement\": 121.0, \"Horsepower\": 110.0, \"Weight_in_lbs\": 2660, \"Acceleration\": 14.0, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"toyota mark ii\", \"Miles_per_Gallon\": 20.0, \"Cylinders\": 6, \"Displacement\": 156.0, \"Horsepower\": 122.0, \"Weight_in_lbs\": 2807, \"Acceleration\": 13.5, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"oldsmobile omega\", \"Miles_per_Gallon\": 11.0, \"Cylinders\": 8, \"Displacement\": 350.0, \"Horsepower\": 180.0, \"Weight_in_lbs\": 3664, \"Acceleration\": 11.0, \"Year\": \"1973-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"plymouth duster\", \"Miles_per_Gallon\": 20.0, \"Cylinders\": 6, \"Displacement\": 198.0, \"Horsepower\": 95.0, \"Weight_in_lbs\": 3102, \"Acceleration\": 16.5, \"Year\": \"1974-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford maverick\", \"Miles_per_Gallon\": 21.0, \"Cylinders\": 6, \"Displacement\": 200.0, \"Horsepower\": null, \"Weight_in_lbs\": 2875, \"Acceleration\": 17.0, \"Year\": \"1974-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"amc hornet\", \"Miles_per_Gallon\": 19.0, \"Cylinders\": 6, \"Displacement\": 232.0, \"Horsepower\": 100.0, \"Weight_in_lbs\": 2901, \"Acceleration\": 16.0, \"Year\": \"1974-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet nova\", \"Miles_per_Gallon\": 15.0, \"Cylinders\": 6, \"Displacement\": 250.0, \"Horsepower\": 100.0, \"Weight_in_lbs\": 3336, \"Acceleration\": 17.0, \"Year\": \"1974-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"datsun b210\", \"Miles_per_Gallon\": 31.0, \"Cylinders\": 4, \"Displacement\": 79.0, \"Horsepower\": 67.0, \"Weight_in_lbs\": 1950, \"Acceleration\": 19.0, \"Year\": \"1974-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"ford pinto\", \"Miles_per_Gallon\": 26.0, \"Cylinders\": 4, \"Displacement\": 122.0, \"Horsepower\": 80.0, \"Weight_in_lbs\": 2451, \"Acceleration\": 16.5, \"Year\": \"1974-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"toyota corolla 1200\", \"Miles_per_Gallon\": 32.0, \"Cylinders\": 4, \"Displacement\": 71.0, \"Horsepower\": 65.0, \"Weight_in_lbs\": 1836, \"Acceleration\": 21.0, \"Year\": \"1974-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"chevrolet vega\", \"Miles_per_Gallon\": 25.0, \"Cylinders\": 4, \"Displacement\": 140.0, \"Horsepower\": 75.0, \"Weight_in_lbs\": 2542, \"Acceleration\": 17.0, \"Year\": \"1974-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet chevelle malibu classic\", \"Miles_per_Gallon\": 16.0, \"Cylinders\": 6, \"Displacement\": 250.0, \"Horsepower\": 100.0, \"Weight_in_lbs\": 3781, \"Acceleration\": 17.0, \"Year\": \"1974-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"amc matador\", \"Miles_per_Gallon\": 16.0, \"Cylinders\": 6, \"Displacement\": 258.0, \"Horsepower\": 110.0, \"Weight_in_lbs\": 3632, \"Acceleration\": 18.0, \"Year\": \"1974-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"plymouth satellite sebring\", \"Miles_per_Gallon\": 18.0, \"Cylinders\": 6, \"Displacement\": 225.0, \"Horsepower\": 105.0, \"Weight_in_lbs\": 3613, \"Acceleration\": 16.5, \"Year\": \"1974-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford gran torino\", \"Miles_per_Gallon\": 16.0, \"Cylinders\": 8, \"Displacement\": 302.0, \"Horsepower\": 140.0, \"Weight_in_lbs\": 4141, \"Acceleration\": 14.0, \"Year\": \"1974-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"buick century luxus (sw)\", \"Miles_per_Gallon\": 13.0, \"Cylinders\": 8, \"Displacement\": 350.0, \"Horsepower\": 150.0, \"Weight_in_lbs\": 4699, \"Acceleration\": 14.5, \"Year\": \"1974-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"dodge coronet custom (sw)\", \"Miles_per_Gallon\": 14.0, \"Cylinders\": 8, \"Displacement\": 318.0, \"Horsepower\": 150.0, \"Weight_in_lbs\": 4457, \"Acceleration\": 13.5, \"Year\": \"1974-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford gran torino (sw)\", \"Miles_per_Gallon\": 14.0, \"Cylinders\": 8, \"Displacement\": 302.0, \"Horsepower\": 140.0, \"Weight_in_lbs\": 4638, \"Acceleration\": 16.0, \"Year\": \"1974-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"amc matador (sw)\", \"Miles_per_Gallon\": 14.0, \"Cylinders\": 8, \"Displacement\": 304.0, \"Horsepower\": 150.0, \"Weight_in_lbs\": 4257, \"Acceleration\": 15.5, \"Year\": \"1974-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"audi fox\", \"Miles_per_Gallon\": 29.0, \"Cylinders\": 4, \"Displacement\": 98.0, \"Horsepower\": 83.0, \"Weight_in_lbs\": 2219, \"Acceleration\": 16.5, \"Year\": \"1974-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"volkswagen dasher\", \"Miles_per_Gallon\": 26.0, \"Cylinders\": 4, \"Displacement\": 79.0, \"Horsepower\": 67.0, \"Weight_in_lbs\": 1963, \"Acceleration\": 15.5, \"Year\": \"1974-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"opel manta\", \"Miles_per_Gallon\": 26.0, \"Cylinders\": 4, \"Displacement\": 97.0, \"Horsepower\": 78.0, \"Weight_in_lbs\": 2300, \"Acceleration\": 14.5, \"Year\": \"1974-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"toyota corona\", \"Miles_per_Gallon\": 31.0, \"Cylinders\": 4, \"Displacement\": 76.0, \"Horsepower\": 52.0, \"Weight_in_lbs\": 1649, \"Acceleration\": 16.5, \"Year\": \"1974-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"datsun 710\", \"Miles_per_Gallon\": 32.0, \"Cylinders\": 4, \"Displacement\": 83.0, \"Horsepower\": 61.0, \"Weight_in_lbs\": 2003, \"Acceleration\": 19.0, \"Year\": \"1974-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"dodge colt\", \"Miles_per_Gallon\": 28.0, \"Cylinders\": 4, \"Displacement\": 90.0, \"Horsepower\": 75.0, \"Weight_in_lbs\": 2125, \"Acceleration\": 14.5, \"Year\": \"1974-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"fiat 128\", \"Miles_per_Gallon\": 24.0, \"Cylinders\": 4, \"Displacement\": 90.0, \"Horsepower\": 75.0, \"Weight_in_lbs\": 2108, \"Acceleration\": 15.5, \"Year\": \"1974-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"fiat 124 tc\", \"Miles_per_Gallon\": 26.0, \"Cylinders\": 4, \"Displacement\": 116.0, \"Horsepower\": 75.0, \"Weight_in_lbs\": 2246, \"Acceleration\": 14.0, \"Year\": \"1974-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"honda civic\", \"Miles_per_Gallon\": 24.0, \"Cylinders\": 4, \"Displacement\": 120.0, \"Horsepower\": 97.0, \"Weight_in_lbs\": 2489, \"Acceleration\": 15.0, \"Year\": \"1974-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"subaru\", \"Miles_per_Gallon\": 26.0, \"Cylinders\": 4, \"Displacement\": 108.0, \"Horsepower\": 93.0, \"Weight_in_lbs\": 2391, \"Acceleration\": 15.5, \"Year\": \"1974-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"fiat x1.9\", \"Miles_per_Gallon\": 31.0, \"Cylinders\": 4, \"Displacement\": 79.0, \"Horsepower\": 67.0, \"Weight_in_lbs\": 2000, \"Acceleration\": 16.0, \"Year\": \"1974-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"plymouth valiant custom\", \"Miles_per_Gallon\": 19.0, \"Cylinders\": 6, \"Displacement\": 225.0, \"Horsepower\": 95.0, \"Weight_in_lbs\": 3264, \"Acceleration\": 16.0, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet nova\", \"Miles_per_Gallon\": 18.0, \"Cylinders\": 6, \"Displacement\": 250.0, \"Horsepower\": 105.0, \"Weight_in_lbs\": 3459, \"Acceleration\": 16.0, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"mercury monarch\", \"Miles_per_Gallon\": 15.0, \"Cylinders\": 6, \"Displacement\": 250.0, \"Horsepower\": 72.0, \"Weight_in_lbs\": 3432, \"Acceleration\": 21.0, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford maverick\", \"Miles_per_Gallon\": 15.0, \"Cylinders\": 6, \"Displacement\": 250.0, \"Horsepower\": 72.0, \"Weight_in_lbs\": 3158, \"Acceleration\": 19.5, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"pontiac catalina\", \"Miles_per_Gallon\": 16.0, \"Cylinders\": 8, \"Displacement\": 400.0, \"Horsepower\": 170.0, \"Weight_in_lbs\": 4668, \"Acceleration\": 11.5, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet bel air\", \"Miles_per_Gallon\": 15.0, \"Cylinders\": 8, \"Displacement\": 350.0, \"Horsepower\": 145.0, \"Weight_in_lbs\": 4440, \"Acceleration\": 14.0, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"plymouth grand fury\", \"Miles_per_Gallon\": 16.0, \"Cylinders\": 8, \"Displacement\": 318.0, \"Horsepower\": 150.0, \"Weight_in_lbs\": 4498, \"Acceleration\": 14.5, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford ltd\", \"Miles_per_Gallon\": 14.0, \"Cylinders\": 8, \"Displacement\": 351.0, \"Horsepower\": 148.0, \"Weight_in_lbs\": 4657, \"Acceleration\": 13.5, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"buick century\", \"Miles_per_Gallon\": 17.0, \"Cylinders\": 6, \"Displacement\": 231.0, \"Horsepower\": 110.0, \"Weight_in_lbs\": 3907, \"Acceleration\": 21.0, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevroelt chevelle malibu\", \"Miles_per_Gallon\": 16.0, \"Cylinders\": 6, \"Displacement\": 250.0, \"Horsepower\": 105.0, \"Weight_in_lbs\": 3897, \"Acceleration\": 18.5, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"amc matador\", \"Miles_per_Gallon\": 15.0, \"Cylinders\": 6, \"Displacement\": 258.0, \"Horsepower\": 110.0, \"Weight_in_lbs\": 3730, \"Acceleration\": 19.0, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"plymouth fury\", \"Miles_per_Gallon\": 18.0, \"Cylinders\": 6, \"Displacement\": 225.0, \"Horsepower\": 95.0, \"Weight_in_lbs\": 3785, \"Acceleration\": 19.0, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"buick skyhawk\", \"Miles_per_Gallon\": 21.0, \"Cylinders\": 6, \"Displacement\": 231.0, \"Horsepower\": 110.0, \"Weight_in_lbs\": 3039, \"Acceleration\": 15.0, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet monza 2+2\", \"Miles_per_Gallon\": 20.0, \"Cylinders\": 8, \"Displacement\": 262.0, \"Horsepower\": 110.0, \"Weight_in_lbs\": 3221, \"Acceleration\": 13.5, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford mustang ii\", \"Miles_per_Gallon\": 13.0, \"Cylinders\": 8, \"Displacement\": 302.0, \"Horsepower\": 129.0, \"Weight_in_lbs\": 3169, \"Acceleration\": 12.0, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"toyota corolla\", \"Miles_per_Gallon\": 29.0, \"Cylinders\": 4, \"Displacement\": 97.0, \"Horsepower\": 75.0, \"Weight_in_lbs\": 2171, \"Acceleration\": 16.0, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"ford pinto\", \"Miles_per_Gallon\": 23.0, \"Cylinders\": 4, \"Displacement\": 140.0, \"Horsepower\": 83.0, \"Weight_in_lbs\": 2639, \"Acceleration\": 17.0, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"amc gremlin\", \"Miles_per_Gallon\": 20.0, \"Cylinders\": 6, \"Displacement\": 232.0, \"Horsepower\": 100.0, \"Weight_in_lbs\": 2914, \"Acceleration\": 16.0, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"pontiac astro\", \"Miles_per_Gallon\": 23.0, \"Cylinders\": 4, \"Displacement\": 140.0, \"Horsepower\": 78.0, \"Weight_in_lbs\": 2592, \"Acceleration\": 18.5, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"toyota corona\", \"Miles_per_Gallon\": 24.0, \"Cylinders\": 4, \"Displacement\": 134.0, \"Horsepower\": 96.0, \"Weight_in_lbs\": 2702, \"Acceleration\": 13.5, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"volkswagen dasher\", \"Miles_per_Gallon\": 25.0, \"Cylinders\": 4, \"Displacement\": 90.0, \"Horsepower\": 71.0, \"Weight_in_lbs\": 2223, \"Acceleration\": 16.5, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"datsun 710\", \"Miles_per_Gallon\": 24.0, \"Cylinders\": 4, \"Displacement\": 119.0, \"Horsepower\": 97.0, \"Weight_in_lbs\": 2545, \"Acceleration\": 17.0, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"ford pinto\", \"Miles_per_Gallon\": 18.0, \"Cylinders\": 6, \"Displacement\": 171.0, \"Horsepower\": 97.0, \"Weight_in_lbs\": 2984, \"Acceleration\": 14.5, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"volkswagen rabbit\", \"Miles_per_Gallon\": 29.0, \"Cylinders\": 4, \"Displacement\": 90.0, \"Horsepower\": 70.0, \"Weight_in_lbs\": 1937, \"Acceleration\": 14.0, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"amc pacer\", \"Miles_per_Gallon\": 19.0, \"Cylinders\": 6, \"Displacement\": 232.0, \"Horsepower\": 90.0, \"Weight_in_lbs\": 3211, \"Acceleration\": 17.0, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"audi 100ls\", \"Miles_per_Gallon\": 23.0, \"Cylinders\": 4, \"Displacement\": 115.0, \"Horsepower\": 95.0, \"Weight_in_lbs\": 2694, \"Acceleration\": 15.0, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"peugeot 504\", \"Miles_per_Gallon\": 23.0, \"Cylinders\": 4, \"Displacement\": 120.0, \"Horsepower\": 88.0, \"Weight_in_lbs\": 2957, \"Acceleration\": 17.0, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"volvo 244dl\", \"Miles_per_Gallon\": 22.0, \"Cylinders\": 4, \"Displacement\": 121.0, \"Horsepower\": 98.0, \"Weight_in_lbs\": 2945, \"Acceleration\": 14.5, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"saab 99le\", \"Miles_per_Gallon\": 25.0, \"Cylinders\": 4, \"Displacement\": 121.0, \"Horsepower\": 115.0, \"Weight_in_lbs\": 2671, \"Acceleration\": 13.5, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"honda civic cvcc\", \"Miles_per_Gallon\": 33.0, \"Cylinders\": 4, \"Displacement\": 91.0, \"Horsepower\": 53.0, \"Weight_in_lbs\": 1795, \"Acceleration\": 17.5, \"Year\": \"1975-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"fiat 131\", \"Miles_per_Gallon\": 28.0, \"Cylinders\": 4, \"Displacement\": 107.0, \"Horsepower\": 86.0, \"Weight_in_lbs\": 2464, \"Acceleration\": 15.5, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"opel 1900\", \"Miles_per_Gallon\": 25.0, \"Cylinders\": 4, \"Displacement\": 116.0, \"Horsepower\": 81.0, \"Weight_in_lbs\": 2220, \"Acceleration\": 16.9, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"capri ii\", \"Miles_per_Gallon\": 25.0, \"Cylinders\": 4, \"Displacement\": 140.0, \"Horsepower\": 92.0, \"Weight_in_lbs\": 2572, \"Acceleration\": 14.9, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"dodge colt\", \"Miles_per_Gallon\": 26.0, \"Cylinders\": 4, \"Displacement\": 98.0, \"Horsepower\": 79.0, \"Weight_in_lbs\": 2255, \"Acceleration\": 17.7, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"renault 12tl\", \"Miles_per_Gallon\": 27.0, \"Cylinders\": 4, \"Displacement\": 101.0, \"Horsepower\": 83.0, \"Weight_in_lbs\": 2202, \"Acceleration\": 15.3, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"chevrolet chevelle malibu classic\", \"Miles_per_Gallon\": 17.5, \"Cylinders\": 8, \"Displacement\": 305.0, \"Horsepower\": 140.0, \"Weight_in_lbs\": 4215, \"Acceleration\": 13.0, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"dodge coronet brougham\", \"Miles_per_Gallon\": 16.0, \"Cylinders\": 8, \"Displacement\": 318.0, \"Horsepower\": 150.0, \"Weight_in_lbs\": 4190, \"Acceleration\": 13.0, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"amc matador\", \"Miles_per_Gallon\": 15.5, \"Cylinders\": 8, \"Displacement\": 304.0, \"Horsepower\": 120.0, \"Weight_in_lbs\": 3962, \"Acceleration\": 13.9, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford gran torino\", \"Miles_per_Gallon\": 14.5, \"Cylinders\": 8, \"Displacement\": 351.0, \"Horsepower\": 152.0, \"Weight_in_lbs\": 4215, \"Acceleration\": 12.8, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"plymouth valiant\", \"Miles_per_Gallon\": 22.0, \"Cylinders\": 6, \"Displacement\": 225.0, \"Horsepower\": 100.0, \"Weight_in_lbs\": 3233, \"Acceleration\": 15.4, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet nova\", \"Miles_per_Gallon\": 22.0, \"Cylinders\": 6, \"Displacement\": 250.0, \"Horsepower\": 105.0, \"Weight_in_lbs\": 3353, \"Acceleration\": 14.5, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford maverick\", \"Miles_per_Gallon\": 24.0, \"Cylinders\": 6, \"Displacement\": 200.0, \"Horsepower\": 81.0, \"Weight_in_lbs\": 3012, \"Acceleration\": 17.6, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"amc hornet\", \"Miles_per_Gallon\": 22.5, \"Cylinders\": 6, \"Displacement\": 232.0, \"Horsepower\": 90.0, \"Weight_in_lbs\": 3085, \"Acceleration\": 17.6, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet chevette\", \"Miles_per_Gallon\": 29.0, \"Cylinders\": 4, \"Displacement\": 85.0, \"Horsepower\": 52.0, \"Weight_in_lbs\": 2035, \"Acceleration\": 22.2, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet woody\", \"Miles_per_Gallon\": 24.5, \"Cylinders\": 4, \"Displacement\": 98.0, \"Horsepower\": 60.0, \"Weight_in_lbs\": 2164, \"Acceleration\": 22.1, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"vw rabbit\", \"Miles_per_Gallon\": 29.0, \"Cylinders\": 4, \"Displacement\": 90.0, \"Horsepower\": 70.0, \"Weight_in_lbs\": 1937, \"Acceleration\": 14.2, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"honda civic\", \"Miles_per_Gallon\": 33.0, \"Cylinders\": 4, \"Displacement\": 91.0, \"Horsepower\": 53.0, \"Weight_in_lbs\": 1795, \"Acceleration\": 17.4, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"dodge aspen se\", \"Miles_per_Gallon\": 20.0, \"Cylinders\": 6, \"Displacement\": 225.0, \"Horsepower\": 100.0, \"Weight_in_lbs\": 3651, \"Acceleration\": 17.7, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford granada ghia\", \"Miles_per_Gallon\": 18.0, \"Cylinders\": 6, \"Displacement\": 250.0, \"Horsepower\": 78.0, \"Weight_in_lbs\": 3574, \"Acceleration\": 21.0, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"pontiac ventura sj\", \"Miles_per_Gallon\": 18.5, \"Cylinders\": 6, \"Displacement\": 250.0, \"Horsepower\": 110.0, \"Weight_in_lbs\": 3645, \"Acceleration\": 16.2, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"amc pacer d/l\", \"Miles_per_Gallon\": 17.5, \"Cylinders\": 6, \"Displacement\": 258.0, \"Horsepower\": 95.0, \"Weight_in_lbs\": 3193, \"Acceleration\": 17.8, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"volkswagen rabbit\", \"Miles_per_Gallon\": 29.5, \"Cylinders\": 4, \"Displacement\": 97.0, \"Horsepower\": 71.0, \"Weight_in_lbs\": 1825, \"Acceleration\": 12.2, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"datsun b-210\", \"Miles_per_Gallon\": 32.0, \"Cylinders\": 4, \"Displacement\": 85.0, \"Horsepower\": 70.0, \"Weight_in_lbs\": 1990, \"Acceleration\": 17.0, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"toyota corolla\", \"Miles_per_Gallon\": 28.0, \"Cylinders\": 4, \"Displacement\": 97.0, \"Horsepower\": 75.0, \"Weight_in_lbs\": 2155, \"Acceleration\": 16.4, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"ford pinto\", \"Miles_per_Gallon\": 26.5, \"Cylinders\": 4, \"Displacement\": 140.0, \"Horsepower\": 72.0, \"Weight_in_lbs\": 2565, \"Acceleration\": 13.6, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"volvo 245\", \"Miles_per_Gallon\": 20.0, \"Cylinders\": 4, \"Displacement\": 130.0, \"Horsepower\": 102.0, \"Weight_in_lbs\": 3150, \"Acceleration\": 15.7, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"plymouth volare premier v8\", \"Miles_per_Gallon\": 13.0, \"Cylinders\": 8, \"Displacement\": 318.0, \"Horsepower\": 150.0, \"Weight_in_lbs\": 3940, \"Acceleration\": 13.2, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"peugeot 504\", \"Miles_per_Gallon\": 19.0, \"Cylinders\": 4, \"Displacement\": 120.0, \"Horsepower\": 88.0, \"Weight_in_lbs\": 3270, \"Acceleration\": 21.9, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"toyota mark ii\", \"Miles_per_Gallon\": 19.0, \"Cylinders\": 6, \"Displacement\": 156.0, \"Horsepower\": 108.0, \"Weight_in_lbs\": 2930, \"Acceleration\": 15.5, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"mercedes-benz 280s\", \"Miles_per_Gallon\": 16.5, \"Cylinders\": 6, \"Displacement\": 168.0, \"Horsepower\": 120.0, \"Weight_in_lbs\": 3820, \"Acceleration\": 16.7, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"cadillac seville\", \"Miles_per_Gallon\": 16.5, \"Cylinders\": 8, \"Displacement\": 350.0, \"Horsepower\": 180.0, \"Weight_in_lbs\": 4380, \"Acceleration\": 12.1, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevy c10\", \"Miles_per_Gallon\": 13.0, \"Cylinders\": 8, \"Displacement\": 350.0, \"Horsepower\": 145.0, \"Weight_in_lbs\": 4055, \"Acceleration\": 12.0, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford f108\", \"Miles_per_Gallon\": 13.0, \"Cylinders\": 8, \"Displacement\": 302.0, \"Horsepower\": 130.0, \"Weight_in_lbs\": 3870, \"Acceleration\": 15.0, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"dodge d100\", \"Miles_per_Gallon\": 13.0, \"Cylinders\": 8, \"Displacement\": 318.0, \"Horsepower\": 150.0, \"Weight_in_lbs\": 3755, \"Acceleration\": 14.0, \"Year\": \"1976-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"honda Accelerationord cvcc\", \"Miles_per_Gallon\": 31.5, \"Cylinders\": 4, \"Displacement\": 98.0, \"Horsepower\": 68.0, \"Weight_in_lbs\": 2045, \"Acceleration\": 18.5, \"Year\": \"1977-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"buick opel isuzu deluxe\", \"Miles_per_Gallon\": 30.0, \"Cylinders\": 4, \"Displacement\": 111.0, \"Horsepower\": 80.0, \"Weight_in_lbs\": 2155, \"Acceleration\": 14.8, \"Year\": \"1977-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"renault 5 gtl\", \"Miles_per_Gallon\": 36.0, \"Cylinders\": 4, \"Displacement\": 79.0, \"Horsepower\": 58.0, \"Weight_in_lbs\": 1825, \"Acceleration\": 18.6, \"Year\": \"1977-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"plymouth arrow gs\", \"Miles_per_Gallon\": 25.5, \"Cylinders\": 4, \"Displacement\": 122.0, \"Horsepower\": 96.0, \"Weight_in_lbs\": 2300, \"Acceleration\": 15.5, \"Year\": \"1977-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"datsun f-10 hatchback\", \"Miles_per_Gallon\": 33.5, \"Cylinders\": 4, \"Displacement\": 85.0, \"Horsepower\": 70.0, \"Weight_in_lbs\": 1945, \"Acceleration\": 16.8, \"Year\": \"1977-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"chevrolet caprice classic\", \"Miles_per_Gallon\": 17.5, \"Cylinders\": 8, \"Displacement\": 305.0, \"Horsepower\": 145.0, \"Weight_in_lbs\": 3880, \"Acceleration\": 12.5, \"Year\": \"1977-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"oldsmobile cutlass supreme\", \"Miles_per_Gallon\": 17.0, \"Cylinders\": 8, \"Displacement\": 260.0, \"Horsepower\": 110.0, \"Weight_in_lbs\": 4060, \"Acceleration\": 19.0, \"Year\": \"1977-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"dodge monaco brougham\", \"Miles_per_Gallon\": 15.5, \"Cylinders\": 8, \"Displacement\": 318.0, \"Horsepower\": 145.0, \"Weight_in_lbs\": 4140, \"Acceleration\": 13.7, \"Year\": \"1977-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"mercury cougar brougham\", \"Miles_per_Gallon\": 15.0, \"Cylinders\": 8, \"Displacement\": 302.0, \"Horsepower\": 130.0, \"Weight_in_lbs\": 4295, \"Acceleration\": 14.9, \"Year\": \"1977-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet concours\", \"Miles_per_Gallon\": 17.5, \"Cylinders\": 6, \"Displacement\": 250.0, \"Horsepower\": 110.0, \"Weight_in_lbs\": 3520, \"Acceleration\": 16.4, \"Year\": \"1977-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"buick skylark\", \"Miles_per_Gallon\": 20.5, \"Cylinders\": 6, \"Displacement\": 231.0, \"Horsepower\": 105.0, \"Weight_in_lbs\": 3425, \"Acceleration\": 16.9, \"Year\": \"1977-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"plymouth volare custom\", \"Miles_per_Gallon\": 19.0, \"Cylinders\": 6, \"Displacement\": 225.0, \"Horsepower\": 100.0, \"Weight_in_lbs\": 3630, \"Acceleration\": 17.7, \"Year\": \"1977-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford granada\", \"Miles_per_Gallon\": 18.5, \"Cylinders\": 6, \"Displacement\": 250.0, \"Horsepower\": 98.0, \"Weight_in_lbs\": 3525, \"Acceleration\": 19.0, \"Year\": \"1977-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"pontiac grand prix lj\", \"Miles_per_Gallon\": 16.0, \"Cylinders\": 8, \"Displacement\": 400.0, \"Horsepower\": 180.0, \"Weight_in_lbs\": 4220, \"Acceleration\": 11.1, \"Year\": \"1977-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet monte carlo landau\", \"Miles_per_Gallon\": 15.5, \"Cylinders\": 8, \"Displacement\": 350.0, \"Horsepower\": 170.0, \"Weight_in_lbs\": 4165, \"Acceleration\": 11.4, \"Year\": \"1977-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chrysler cordoba\", \"Miles_per_Gallon\": 15.5, \"Cylinders\": 8, \"Displacement\": 400.0, \"Horsepower\": 190.0, \"Weight_in_lbs\": 4325, \"Acceleration\": 12.2, \"Year\": \"1977-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford thunderbird\", \"Miles_per_Gallon\": 16.0, \"Cylinders\": 8, \"Displacement\": 351.0, \"Horsepower\": 149.0, \"Weight_in_lbs\": 4335, \"Acceleration\": 14.5, \"Year\": \"1977-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"volkswagen rabbit custom\", \"Miles_per_Gallon\": 29.0, \"Cylinders\": 4, \"Displacement\": 97.0, \"Horsepower\": 78.0, \"Weight_in_lbs\": 1940, \"Acceleration\": 14.5, \"Year\": \"1977-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"pontiac sunbird coupe\", \"Miles_per_Gallon\": 24.5, \"Cylinders\": 4, \"Displacement\": 151.0, \"Horsepower\": 88.0, \"Weight_in_lbs\": 2740, \"Acceleration\": 16.0, \"Year\": \"1977-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"toyota corolla liftback\", \"Miles_per_Gallon\": 26.0, \"Cylinders\": 4, \"Displacement\": 97.0, \"Horsepower\": 75.0, \"Weight_in_lbs\": 2265, \"Acceleration\": 18.2, \"Year\": \"1977-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"ford mustang ii 2+2\", \"Miles_per_Gallon\": 25.5, \"Cylinders\": 4, \"Displacement\": 140.0, \"Horsepower\": 89.0, \"Weight_in_lbs\": 2755, \"Acceleration\": 15.8, \"Year\": \"1977-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet chevette\", \"Miles_per_Gallon\": 30.5, \"Cylinders\": 4, \"Displacement\": 98.0, \"Horsepower\": 63.0, \"Weight_in_lbs\": 2051, \"Acceleration\": 17.0, \"Year\": \"1977-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"dodge colt m/m\", \"Miles_per_Gallon\": 33.5, \"Cylinders\": 4, \"Displacement\": 98.0, \"Horsepower\": 83.0, \"Weight_in_lbs\": 2075, \"Acceleration\": 15.9, \"Year\": \"1977-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"subaru dl\", \"Miles_per_Gallon\": 30.0, \"Cylinders\": 4, \"Displacement\": 97.0, \"Horsepower\": 67.0, \"Weight_in_lbs\": 1985, \"Acceleration\": 16.4, \"Year\": \"1977-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"volkswagen dasher\", \"Miles_per_Gallon\": 30.5, \"Cylinders\": 4, \"Displacement\": 97.0, \"Horsepower\": 78.0, \"Weight_in_lbs\": 2190, \"Acceleration\": 14.1, \"Year\": \"1977-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"datsun 810\", \"Miles_per_Gallon\": 22.0, \"Cylinders\": 6, \"Displacement\": 146.0, \"Horsepower\": 97.0, \"Weight_in_lbs\": 2815, \"Acceleration\": 14.5, \"Year\": \"1977-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"bmw 320i\", \"Miles_per_Gallon\": 21.5, \"Cylinders\": 4, \"Displacement\": 121.0, \"Horsepower\": 110.0, \"Weight_in_lbs\": 2600, \"Acceleration\": 12.8, \"Year\": \"1977-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"mazda rx-4\", \"Miles_per_Gallon\": 21.5, \"Cylinders\": 3, \"Displacement\": 80.0, \"Horsepower\": 110.0, \"Weight_in_lbs\": 2720, \"Acceleration\": 13.5, \"Year\": \"1977-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"volkswagen rabbit custom diesel\", \"Miles_per_Gallon\": 43.1, \"Cylinders\": 4, \"Displacement\": 90.0, \"Horsepower\": 48.0, \"Weight_in_lbs\": 1985, \"Acceleration\": 21.5, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"ford fiesta\", \"Miles_per_Gallon\": 36.1, \"Cylinders\": 4, \"Displacement\": 98.0, \"Horsepower\": 66.0, \"Weight_in_lbs\": 1800, \"Acceleration\": 14.4, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"mazda glc deluxe\", \"Miles_per_Gallon\": 32.8, \"Cylinders\": 4, \"Displacement\": 78.0, \"Horsepower\": 52.0, \"Weight_in_lbs\": 1985, \"Acceleration\": 19.4, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"datsun b210 gx\", \"Miles_per_Gallon\": 39.4, \"Cylinders\": 4, \"Displacement\": 85.0, \"Horsepower\": 70.0, \"Weight_in_lbs\": 2070, \"Acceleration\": 18.6, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"honda civic cvcc\", \"Miles_per_Gallon\": 36.1, \"Cylinders\": 4, \"Displacement\": 91.0, \"Horsepower\": 60.0, \"Weight_in_lbs\": 1800, \"Acceleration\": 16.4, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"oldsmobile cutlass salon brougham\", \"Miles_per_Gallon\": 19.9, \"Cylinders\": 8, \"Displacement\": 260.0, \"Horsepower\": 110.0, \"Weight_in_lbs\": 3365, \"Acceleration\": 15.5, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"dodge diplomat\", \"Miles_per_Gallon\": 19.4, \"Cylinders\": 8, \"Displacement\": 318.0, \"Horsepower\": 140.0, \"Weight_in_lbs\": 3735, \"Acceleration\": 13.2, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"mercury monarch ghia\", \"Miles_per_Gallon\": 20.2, \"Cylinders\": 8, \"Displacement\": 302.0, \"Horsepower\": 139.0, \"Weight_in_lbs\": 3570, \"Acceleration\": 12.8, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"pontiac phoenix lj\", \"Miles_per_Gallon\": 19.2, \"Cylinders\": 6, \"Displacement\": 231.0, \"Horsepower\": 105.0, \"Weight_in_lbs\": 3535, \"Acceleration\": 19.2, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet malibu\", \"Miles_per_Gallon\": 20.5, \"Cylinders\": 6, \"Displacement\": 200.0, \"Horsepower\": 95.0, \"Weight_in_lbs\": 3155, \"Acceleration\": 18.2, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford fairmont (auto)\", \"Miles_per_Gallon\": 20.2, \"Cylinders\": 6, \"Displacement\": 200.0, \"Horsepower\": 85.0, \"Weight_in_lbs\": 2965, \"Acceleration\": 15.8, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford fairmont (man)\", \"Miles_per_Gallon\": 25.1, \"Cylinders\": 4, \"Displacement\": 140.0, \"Horsepower\": 88.0, \"Weight_in_lbs\": 2720, \"Acceleration\": 15.4, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"plymouth volare\", \"Miles_per_Gallon\": 20.5, \"Cylinders\": 6, \"Displacement\": 225.0, \"Horsepower\": 100.0, \"Weight_in_lbs\": 3430, \"Acceleration\": 17.2, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"amc concord\", \"Miles_per_Gallon\": 19.4, \"Cylinders\": 6, \"Displacement\": 232.0, \"Horsepower\": 90.0, \"Weight_in_lbs\": 3210, \"Acceleration\": 17.2, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"buick century special\", \"Miles_per_Gallon\": 20.6, \"Cylinders\": 6, \"Displacement\": 231.0, \"Horsepower\": 105.0, \"Weight_in_lbs\": 3380, \"Acceleration\": 15.8, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"mercury zephyr\", \"Miles_per_Gallon\": 20.8, \"Cylinders\": 6, \"Displacement\": 200.0, \"Horsepower\": 85.0, \"Weight_in_lbs\": 3070, \"Acceleration\": 16.7, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"dodge aspen\", \"Miles_per_Gallon\": 18.6, \"Cylinders\": 6, \"Displacement\": 225.0, \"Horsepower\": 110.0, \"Weight_in_lbs\": 3620, \"Acceleration\": 18.7, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"amc concord d/l\", \"Miles_per_Gallon\": 18.1, \"Cylinders\": 6, \"Displacement\": 258.0, \"Horsepower\": 120.0, \"Weight_in_lbs\": 3410, \"Acceleration\": 15.1, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet monte carlo landau\", \"Miles_per_Gallon\": 19.2, \"Cylinders\": 8, \"Displacement\": 305.0, \"Horsepower\": 145.0, \"Weight_in_lbs\": 3425, \"Acceleration\": 13.2, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"buick regal sport coupe (turbo)\", \"Miles_per_Gallon\": 17.7, \"Cylinders\": 6, \"Displacement\": 231.0, \"Horsepower\": 165.0, \"Weight_in_lbs\": 3445, \"Acceleration\": 13.4, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford futura\", \"Miles_per_Gallon\": 18.1, \"Cylinders\": 8, \"Displacement\": 302.0, \"Horsepower\": 139.0, \"Weight_in_lbs\": 3205, \"Acceleration\": 11.2, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"dodge magnum xe\", \"Miles_per_Gallon\": 17.5, \"Cylinders\": 8, \"Displacement\": 318.0, \"Horsepower\": 140.0, \"Weight_in_lbs\": 4080, \"Acceleration\": 13.7, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet chevette\", \"Miles_per_Gallon\": 30.0, \"Cylinders\": 4, \"Displacement\": 98.0, \"Horsepower\": 68.0, \"Weight_in_lbs\": 2155, \"Acceleration\": 16.5, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"toyota corona\", \"Miles_per_Gallon\": 27.5, \"Cylinders\": 4, \"Displacement\": 134.0, \"Horsepower\": 95.0, \"Weight_in_lbs\": 2560, \"Acceleration\": 14.2, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"datsun 510\", \"Miles_per_Gallon\": 27.2, \"Cylinders\": 4, \"Displacement\": 119.0, \"Horsepower\": 97.0, \"Weight_in_lbs\": 2300, \"Acceleration\": 14.7, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"dodge omni\", \"Miles_per_Gallon\": 30.9, \"Cylinders\": 4, \"Displacement\": 105.0, \"Horsepower\": 75.0, \"Weight_in_lbs\": 2230, \"Acceleration\": 14.5, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"toyota celica gt liftback\", \"Miles_per_Gallon\": 21.1, \"Cylinders\": 4, \"Displacement\": 134.0, \"Horsepower\": 95.0, \"Weight_in_lbs\": 2515, \"Acceleration\": 14.8, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"plymouth sapporo\", \"Miles_per_Gallon\": 23.2, \"Cylinders\": 4, \"Displacement\": 156.0, \"Horsepower\": 105.0, \"Weight_in_lbs\": 2745, \"Acceleration\": 16.7, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"oldsmobile starfire sx\", \"Miles_per_Gallon\": 23.8, \"Cylinders\": 4, \"Displacement\": 151.0, \"Horsepower\": 85.0, \"Weight_in_lbs\": 2855, \"Acceleration\": 17.6, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"datsun 200-sx\", \"Miles_per_Gallon\": 23.9, \"Cylinders\": 4, \"Displacement\": 119.0, \"Horsepower\": 97.0, \"Weight_in_lbs\": 2405, \"Acceleration\": 14.9, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"audi 5000\", \"Miles_per_Gallon\": 20.3, \"Cylinders\": 5, \"Displacement\": 131.0, \"Horsepower\": 103.0, \"Weight_in_lbs\": 2830, \"Acceleration\": 15.9, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"volvo 264gl\", \"Miles_per_Gallon\": 17.0, \"Cylinders\": 6, \"Displacement\": 163.0, \"Horsepower\": 125.0, \"Weight_in_lbs\": 3140, \"Acceleration\": 13.6, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"saab 99gle\", \"Miles_per_Gallon\": 21.6, \"Cylinders\": 4, \"Displacement\": 121.0, \"Horsepower\": 115.0, \"Weight_in_lbs\": 2795, \"Acceleration\": 15.7, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"peugeot 604sl\", \"Miles_per_Gallon\": 16.2, \"Cylinders\": 6, \"Displacement\": 163.0, \"Horsepower\": 133.0, \"Weight_in_lbs\": 3410, \"Acceleration\": 15.8, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"volkswagen scirocco\", \"Miles_per_Gallon\": 31.5, \"Cylinders\": 4, \"Displacement\": 89.0, \"Horsepower\": 71.0, \"Weight_in_lbs\": 1990, \"Acceleration\": 14.9, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"honda Accelerationord lx\", \"Miles_per_Gallon\": 29.5, \"Cylinders\": 4, \"Displacement\": 98.0, \"Horsepower\": 68.0, \"Weight_in_lbs\": 2135, \"Acceleration\": 16.6, \"Year\": \"1978-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"pontiac lemans v6\", \"Miles_per_Gallon\": 21.5, \"Cylinders\": 6, \"Displacement\": 231.0, \"Horsepower\": 115.0, \"Weight_in_lbs\": 3245, \"Acceleration\": 15.4, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"mercury zephyr 6\", \"Miles_per_Gallon\": 19.8, \"Cylinders\": 6, \"Displacement\": 200.0, \"Horsepower\": 85.0, \"Weight_in_lbs\": 2990, \"Acceleration\": 18.2, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford fairmont 4\", \"Miles_per_Gallon\": 22.3, \"Cylinders\": 4, \"Displacement\": 140.0, \"Horsepower\": 88.0, \"Weight_in_lbs\": 2890, \"Acceleration\": 17.3, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"amc concord dl 6\", \"Miles_per_Gallon\": 20.2, \"Cylinders\": 6, \"Displacement\": 232.0, \"Horsepower\": 90.0, \"Weight_in_lbs\": 3265, \"Acceleration\": 18.2, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"dodge aspen 6\", \"Miles_per_Gallon\": 20.6, \"Cylinders\": 6, \"Displacement\": 225.0, \"Horsepower\": 110.0, \"Weight_in_lbs\": 3360, \"Acceleration\": 16.6, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet caprice classic\", \"Miles_per_Gallon\": 17.0, \"Cylinders\": 8, \"Displacement\": 305.0, \"Horsepower\": 130.0, \"Weight_in_lbs\": 3840, \"Acceleration\": 15.4, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford ltd landau\", \"Miles_per_Gallon\": 17.6, \"Cylinders\": 8, \"Displacement\": 302.0, \"Horsepower\": 129.0, \"Weight_in_lbs\": 3725, \"Acceleration\": 13.4, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"mercury grand marquis\", \"Miles_per_Gallon\": 16.5, \"Cylinders\": 8, \"Displacement\": 351.0, \"Horsepower\": 138.0, \"Weight_in_lbs\": 3955, \"Acceleration\": 13.2, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"dodge st. regis\", \"Miles_per_Gallon\": 18.2, \"Cylinders\": 8, \"Displacement\": 318.0, \"Horsepower\": 135.0, \"Weight_in_lbs\": 3830, \"Acceleration\": 15.2, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"buick estate wagon (sw)\", \"Miles_per_Gallon\": 16.9, \"Cylinders\": 8, \"Displacement\": 350.0, \"Horsepower\": 155.0, \"Weight_in_lbs\": 4360, \"Acceleration\": 14.9, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford country squire (sw)\", \"Miles_per_Gallon\": 15.5, \"Cylinders\": 8, \"Displacement\": 351.0, \"Horsepower\": 142.0, \"Weight_in_lbs\": 4054, \"Acceleration\": 14.3, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet malibu classic (sw)\", \"Miles_per_Gallon\": 19.2, \"Cylinders\": 8, \"Displacement\": 267.0, \"Horsepower\": 125.0, \"Weight_in_lbs\": 3605, \"Acceleration\": 15.0, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chrysler lebaron town @ country (sw)\", \"Miles_per_Gallon\": 18.5, \"Cylinders\": 8, \"Displacement\": 360.0, \"Horsepower\": 150.0, \"Weight_in_lbs\": 3940, \"Acceleration\": 13.0, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"vw rabbit custom\", \"Miles_per_Gallon\": 31.9, \"Cylinders\": 4, \"Displacement\": 89.0, \"Horsepower\": 71.0, \"Weight_in_lbs\": 1925, \"Acceleration\": 14.0, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"maxda glc deluxe\", \"Miles_per_Gallon\": 34.1, \"Cylinders\": 4, \"Displacement\": 86.0, \"Horsepower\": 65.0, \"Weight_in_lbs\": 1975, \"Acceleration\": 15.2, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"dodge colt hatchback custom\", \"Miles_per_Gallon\": 35.7, \"Cylinders\": 4, \"Displacement\": 98.0, \"Horsepower\": 80.0, \"Weight_in_lbs\": 1915, \"Acceleration\": 14.4, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"amc spirit dl\", \"Miles_per_Gallon\": 27.4, \"Cylinders\": 4, \"Displacement\": 121.0, \"Horsepower\": 80.0, \"Weight_in_lbs\": 2670, \"Acceleration\": 15.0, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"mercedes benz 300d\", \"Miles_per_Gallon\": 25.4, \"Cylinders\": 5, \"Displacement\": 183.0, \"Horsepower\": 77.0, \"Weight_in_lbs\": 3530, \"Acceleration\": 20.1, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"cadillac eldorado\", \"Miles_per_Gallon\": 23.0, \"Cylinders\": 8, \"Displacement\": 350.0, \"Horsepower\": 125.0, \"Weight_in_lbs\": 3900, \"Acceleration\": 17.4, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"peugeot 504\", \"Miles_per_Gallon\": 27.2, \"Cylinders\": 4, \"Displacement\": 141.0, \"Horsepower\": 71.0, \"Weight_in_lbs\": 3190, \"Acceleration\": 24.8, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"oldsmobile cutlass salon brougham\", \"Miles_per_Gallon\": 23.9, \"Cylinders\": 8, \"Displacement\": 260.0, \"Horsepower\": 90.0, \"Weight_in_lbs\": 3420, \"Acceleration\": 22.2, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"plymouth horizon\", \"Miles_per_Gallon\": 34.2, \"Cylinders\": 4, \"Displacement\": 105.0, \"Horsepower\": 70.0, \"Weight_in_lbs\": 2200, \"Acceleration\": 13.2, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"plymouth horizon tc3\", \"Miles_per_Gallon\": 34.5, \"Cylinders\": 4, \"Displacement\": 105.0, \"Horsepower\": 70.0, \"Weight_in_lbs\": 2150, \"Acceleration\": 14.9, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"datsun 210\", \"Miles_per_Gallon\": 31.8, \"Cylinders\": 4, \"Displacement\": 85.0, \"Horsepower\": 65.0, \"Weight_in_lbs\": 2020, \"Acceleration\": 19.2, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"fiat strada custom\", \"Miles_per_Gallon\": 37.3, \"Cylinders\": 4, \"Displacement\": 91.0, \"Horsepower\": 69.0, \"Weight_in_lbs\": 2130, \"Acceleration\": 14.7, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"buick skylark limited\", \"Miles_per_Gallon\": 28.4, \"Cylinders\": 4, \"Displacement\": 151.0, \"Horsepower\": 90.0, \"Weight_in_lbs\": 2670, \"Acceleration\": 16.0, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet citation\", \"Miles_per_Gallon\": 28.8, \"Cylinders\": 6, \"Displacement\": 173.0, \"Horsepower\": 115.0, \"Weight_in_lbs\": 2595, \"Acceleration\": 11.3, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"oldsmobile omega brougham\", \"Miles_per_Gallon\": 26.8, \"Cylinders\": 6, \"Displacement\": 173.0, \"Horsepower\": 115.0, \"Weight_in_lbs\": 2700, \"Acceleration\": 12.9, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"pontiac phoenix\", \"Miles_per_Gallon\": 33.5, \"Cylinders\": 4, \"Displacement\": 151.0, \"Horsepower\": 90.0, \"Weight_in_lbs\": 2556, \"Acceleration\": 13.2, \"Year\": \"1979-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"vw rabbit\", \"Miles_per_Gallon\": 41.5, \"Cylinders\": 4, \"Displacement\": 98.0, \"Horsepower\": 76.0, \"Weight_in_lbs\": 2144, \"Acceleration\": 14.7, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"toyota corolla tercel\", \"Miles_per_Gallon\": 38.1, \"Cylinders\": 4, \"Displacement\": 89.0, \"Horsepower\": 60.0, \"Weight_in_lbs\": 1968, \"Acceleration\": 18.8, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"chevrolet chevette\", \"Miles_per_Gallon\": 32.1, \"Cylinders\": 4, \"Displacement\": 98.0, \"Horsepower\": 70.0, \"Weight_in_lbs\": 2120, \"Acceleration\": 15.5, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"datsun 310\", \"Miles_per_Gallon\": 37.2, \"Cylinders\": 4, \"Displacement\": 86.0, \"Horsepower\": 65.0, \"Weight_in_lbs\": 2019, \"Acceleration\": 16.4, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"chevrolet citation\", \"Miles_per_Gallon\": 28.0, \"Cylinders\": 4, \"Displacement\": 151.0, \"Horsepower\": 90.0, \"Weight_in_lbs\": 2678, \"Acceleration\": 16.5, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford fairmont\", \"Miles_per_Gallon\": 26.4, \"Cylinders\": 4, \"Displacement\": 140.0, \"Horsepower\": 88.0, \"Weight_in_lbs\": 2870, \"Acceleration\": 18.1, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"amc concord\", \"Miles_per_Gallon\": 24.3, \"Cylinders\": 4, \"Displacement\": 151.0, \"Horsepower\": 90.0, \"Weight_in_lbs\": 3003, \"Acceleration\": 20.1, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"dodge aspen\", \"Miles_per_Gallon\": 19.1, \"Cylinders\": 6, \"Displacement\": 225.0, \"Horsepower\": 90.0, \"Weight_in_lbs\": 3381, \"Acceleration\": 18.7, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"audi 4000\", \"Miles_per_Gallon\": 34.3, \"Cylinders\": 4, \"Displacement\": 97.0, \"Horsepower\": 78.0, \"Weight_in_lbs\": 2188, \"Acceleration\": 15.8, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"toyota corona liftback\", \"Miles_per_Gallon\": 29.8, \"Cylinders\": 4, \"Displacement\": 134.0, \"Horsepower\": 90.0, \"Weight_in_lbs\": 2711, \"Acceleration\": 15.5, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"mazda 626\", \"Miles_per_Gallon\": 31.3, \"Cylinders\": 4, \"Displacement\": 120.0, \"Horsepower\": 75.0, \"Weight_in_lbs\": 2542, \"Acceleration\": 17.5, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"datsun 510 hatchback\", \"Miles_per_Gallon\": 37.0, \"Cylinders\": 4, \"Displacement\": 119.0, \"Horsepower\": 92.0, \"Weight_in_lbs\": 2434, \"Acceleration\": 15.0, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"toyota corolla\", \"Miles_per_Gallon\": 32.2, \"Cylinders\": 4, \"Displacement\": 108.0, \"Horsepower\": 75.0, \"Weight_in_lbs\": 2265, \"Acceleration\": 15.2, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"mazda glc\", \"Miles_per_Gallon\": 46.6, \"Cylinders\": 4, \"Displacement\": 86.0, \"Horsepower\": 65.0, \"Weight_in_lbs\": 2110, \"Acceleration\": 17.9, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"dodge colt\", \"Miles_per_Gallon\": 27.9, \"Cylinders\": 4, \"Displacement\": 156.0, \"Horsepower\": 105.0, \"Weight_in_lbs\": 2800, \"Acceleration\": 14.4, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"datsun 210\", \"Miles_per_Gallon\": 40.8, \"Cylinders\": 4, \"Displacement\": 85.0, \"Horsepower\": 65.0, \"Weight_in_lbs\": 2110, \"Acceleration\": 19.2, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"vw rabbit c (diesel)\", \"Miles_per_Gallon\": 44.3, \"Cylinders\": 4, \"Displacement\": 90.0, \"Horsepower\": 48.0, \"Weight_in_lbs\": 2085, \"Acceleration\": 21.7, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"vw dasher (diesel)\", \"Miles_per_Gallon\": 43.4, \"Cylinders\": 4, \"Displacement\": 90.0, \"Horsepower\": 48.0, \"Weight_in_lbs\": 2335, \"Acceleration\": 23.7, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"audi 5000s (diesel)\", \"Miles_per_Gallon\": 36.4, \"Cylinders\": 5, \"Displacement\": 121.0, \"Horsepower\": 67.0, \"Weight_in_lbs\": 2950, \"Acceleration\": 19.9, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"mercedes-benz 240d\", \"Miles_per_Gallon\": 30.0, \"Cylinders\": 4, \"Displacement\": 146.0, \"Horsepower\": 67.0, \"Weight_in_lbs\": 3250, \"Acceleration\": 21.8, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"honda civic 1500 gl\", \"Miles_per_Gallon\": 44.6, \"Cylinders\": 4, \"Displacement\": 91.0, \"Horsepower\": 67.0, \"Weight_in_lbs\": 1850, \"Acceleration\": 13.8, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"renault lecar deluxe\", \"Miles_per_Gallon\": 40.9, \"Cylinders\": 4, \"Displacement\": 85.0, \"Horsepower\": null, \"Weight_in_lbs\": 1835, \"Acceleration\": 17.3, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"subaru dl\", \"Miles_per_Gallon\": 33.8, \"Cylinders\": 4, \"Displacement\": 97.0, \"Horsepower\": 67.0, \"Weight_in_lbs\": 2145, \"Acceleration\": 18.0, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"vokswagen rabbit\", \"Miles_per_Gallon\": 29.8, \"Cylinders\": 4, \"Displacement\": 89.0, \"Horsepower\": 62.0, \"Weight_in_lbs\": 1845, \"Acceleration\": 15.3, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"datsun 280-zx\", \"Miles_per_Gallon\": 32.7, \"Cylinders\": 6, \"Displacement\": 168.0, \"Horsepower\": 132.0, \"Weight_in_lbs\": 2910, \"Acceleration\": 11.4, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"mazda rx-7 gs\", \"Miles_per_Gallon\": 23.7, \"Cylinders\": 3, \"Displacement\": 70.0, \"Horsepower\": 100.0, \"Weight_in_lbs\": 2420, \"Acceleration\": 12.5, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"triumph tr7 coupe\", \"Miles_per_Gallon\": 35.0, \"Cylinders\": 4, \"Displacement\": 122.0, \"Horsepower\": 88.0, \"Weight_in_lbs\": 2500, \"Acceleration\": 15.1, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"ford mustang cobra\", \"Miles_per_Gallon\": 23.6, \"Cylinders\": 4, \"Displacement\": 140.0, \"Horsepower\": null, \"Weight_in_lbs\": 2905, \"Acceleration\": 14.3, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"honda Accelerationord\", \"Miles_per_Gallon\": 32.4, \"Cylinders\": 4, \"Displacement\": 107.0, \"Horsepower\": 72.0, \"Weight_in_lbs\": 2290, \"Acceleration\": 17.0, \"Year\": \"1980-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"plymouth reliant\", \"Miles_per_Gallon\": 27.2, \"Cylinders\": 4, \"Displacement\": 135.0, \"Horsepower\": 84.0, \"Weight_in_lbs\": 2490, \"Acceleration\": 15.7, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"buick skylark\", \"Miles_per_Gallon\": 26.6, \"Cylinders\": 4, \"Displacement\": 151.0, \"Horsepower\": 84.0, \"Weight_in_lbs\": 2635, \"Acceleration\": 16.4, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"dodge aries wagon (sw)\", \"Miles_per_Gallon\": 25.8, \"Cylinders\": 4, \"Displacement\": 156.0, \"Horsepower\": 92.0, \"Weight_in_lbs\": 2620, \"Acceleration\": 14.4, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet citation\", \"Miles_per_Gallon\": 23.5, \"Cylinders\": 6, \"Displacement\": 173.0, \"Horsepower\": 110.0, \"Weight_in_lbs\": 2725, \"Acceleration\": 12.6, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"plymouth reliant\", \"Miles_per_Gallon\": 30.0, \"Cylinders\": 4, \"Displacement\": 135.0, \"Horsepower\": 84.0, \"Weight_in_lbs\": 2385, \"Acceleration\": 12.9, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"toyota starlet\", \"Miles_per_Gallon\": 39.1, \"Cylinders\": 4, \"Displacement\": 79.0, \"Horsepower\": 58.0, \"Weight_in_lbs\": 1755, \"Acceleration\": 16.9, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"plymouth champ\", \"Miles_per_Gallon\": 39.0, \"Cylinders\": 4, \"Displacement\": 86.0, \"Horsepower\": 64.0, \"Weight_in_lbs\": 1875, \"Acceleration\": 16.4, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"honda civic 1300\", \"Miles_per_Gallon\": 35.1, \"Cylinders\": 4, \"Displacement\": 81.0, \"Horsepower\": 60.0, \"Weight_in_lbs\": 1760, \"Acceleration\": 16.1, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"subaru\", \"Miles_per_Gallon\": 32.3, \"Cylinders\": 4, \"Displacement\": 97.0, \"Horsepower\": 67.0, \"Weight_in_lbs\": 2065, \"Acceleration\": 17.8, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"datsun 210\", \"Miles_per_Gallon\": 37.0, \"Cylinders\": 4, \"Displacement\": 85.0, \"Horsepower\": 65.0, \"Weight_in_lbs\": 1975, \"Acceleration\": 19.4, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"toyota tercel\", \"Miles_per_Gallon\": 37.7, \"Cylinders\": 4, \"Displacement\": 89.0, \"Horsepower\": 62.0, \"Weight_in_lbs\": 2050, \"Acceleration\": 17.3, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"mazda glc 4\", \"Miles_per_Gallon\": 34.1, \"Cylinders\": 4, \"Displacement\": 91.0, \"Horsepower\": 68.0, \"Weight_in_lbs\": 1985, \"Acceleration\": 16.0, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"plymouth horizon 4\", \"Miles_per_Gallon\": 34.7, \"Cylinders\": 4, \"Displacement\": 105.0, \"Horsepower\": 63.0, \"Weight_in_lbs\": 2215, \"Acceleration\": 14.9, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford escort 4w\", \"Miles_per_Gallon\": 34.4, \"Cylinders\": 4, \"Displacement\": 98.0, \"Horsepower\": 65.0, \"Weight_in_lbs\": 2045, \"Acceleration\": 16.2, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford escort 2h\", \"Miles_per_Gallon\": 29.9, \"Cylinders\": 4, \"Displacement\": 98.0, \"Horsepower\": 65.0, \"Weight_in_lbs\": 2380, \"Acceleration\": 20.7, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"volkswagen jetta\", \"Miles_per_Gallon\": 33.0, \"Cylinders\": 4, \"Displacement\": 105.0, \"Horsepower\": 74.0, \"Weight_in_lbs\": 2190, \"Acceleration\": 14.2, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"renault 18i\", \"Miles_per_Gallon\": 34.5, \"Cylinders\": 4, \"Displacement\": 100.0, \"Horsepower\": null, \"Weight_in_lbs\": 2320, \"Acceleration\": 15.8, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"honda prelude\", \"Miles_per_Gallon\": 33.7, \"Cylinders\": 4, \"Displacement\": 107.0, \"Horsepower\": 75.0, \"Weight_in_lbs\": 2210, \"Acceleration\": 14.4, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"toyota corolla\", \"Miles_per_Gallon\": 32.4, \"Cylinders\": 4, \"Displacement\": 108.0, \"Horsepower\": 75.0, \"Weight_in_lbs\": 2350, \"Acceleration\": 16.8, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"datsun 200sx\", \"Miles_per_Gallon\": 32.9, \"Cylinders\": 4, \"Displacement\": 119.0, \"Horsepower\": 100.0, \"Weight_in_lbs\": 2615, \"Acceleration\": 14.8, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"mazda 626\", \"Miles_per_Gallon\": 31.6, \"Cylinders\": 4, \"Displacement\": 120.0, \"Horsepower\": 74.0, \"Weight_in_lbs\": 2635, \"Acceleration\": 18.3, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"peugeot 505s turbo diesel\", \"Miles_per_Gallon\": 28.1, \"Cylinders\": 4, \"Displacement\": 141.0, \"Horsepower\": 80.0, \"Weight_in_lbs\": 3230, \"Acceleration\": 20.4, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"saab 900s\", \"Miles_per_Gallon\": null, \"Cylinders\": 4, \"Displacement\": 121.0, \"Horsepower\": 110.0, \"Weight_in_lbs\": 2800, \"Acceleration\": 15.4, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"volvo diesel\", \"Miles_per_Gallon\": 30.7, \"Cylinders\": 6, \"Displacement\": 145.0, \"Horsepower\": 76.0, \"Weight_in_lbs\": 3160, \"Acceleration\": 19.6, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"toyota cressida\", \"Miles_per_Gallon\": 25.4, \"Cylinders\": 6, \"Displacement\": 168.0, \"Horsepower\": 116.0, \"Weight_in_lbs\": 2900, \"Acceleration\": 12.6, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"datsun 810 maxima\", \"Miles_per_Gallon\": 24.2, \"Cylinders\": 6, \"Displacement\": 146.0, \"Horsepower\": 120.0, \"Weight_in_lbs\": 2930, \"Acceleration\": 13.8, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"buick century\", \"Miles_per_Gallon\": 22.4, \"Cylinders\": 6, \"Displacement\": 231.0, \"Horsepower\": 110.0, \"Weight_in_lbs\": 3415, \"Acceleration\": 15.8, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"oldsmobile cutlass ls\", \"Miles_per_Gallon\": 26.6, \"Cylinders\": 8, \"Displacement\": 350.0, \"Horsepower\": 105.0, \"Weight_in_lbs\": 3725, \"Acceleration\": 19.0, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford granada gl\", \"Miles_per_Gallon\": 20.2, \"Cylinders\": 6, \"Displacement\": 200.0, \"Horsepower\": 88.0, \"Weight_in_lbs\": 3060, \"Acceleration\": 17.1, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chrysler lebaron salon\", \"Miles_per_Gallon\": 17.6, \"Cylinders\": 6, \"Displacement\": 225.0, \"Horsepower\": 85.0, \"Weight_in_lbs\": 3465, \"Acceleration\": 16.6, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet cavalier\", \"Miles_per_Gallon\": 28.0, \"Cylinders\": 4, \"Displacement\": 112.0, \"Horsepower\": 88.0, \"Weight_in_lbs\": 2605, \"Acceleration\": 19.6, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet cavalier wagon\", \"Miles_per_Gallon\": 27.0, \"Cylinders\": 4, \"Displacement\": 112.0, \"Horsepower\": 88.0, \"Weight_in_lbs\": 2640, \"Acceleration\": 18.6, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet cavalier 2-door\", \"Miles_per_Gallon\": 34.0, \"Cylinders\": 4, \"Displacement\": 112.0, \"Horsepower\": 88.0, \"Weight_in_lbs\": 2395, \"Acceleration\": 18.0, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"pontiac j2000 se hatchback\", \"Miles_per_Gallon\": 31.0, \"Cylinders\": 4, \"Displacement\": 112.0, \"Horsepower\": 85.0, \"Weight_in_lbs\": 2575, \"Acceleration\": 16.2, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"dodge aries se\", \"Miles_per_Gallon\": 29.0, \"Cylinders\": 4, \"Displacement\": 135.0, \"Horsepower\": 84.0, \"Weight_in_lbs\": 2525, \"Acceleration\": 16.0, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"pontiac phoenix\", \"Miles_per_Gallon\": 27.0, \"Cylinders\": 4, \"Displacement\": 151.0, \"Horsepower\": 90.0, \"Weight_in_lbs\": 2735, \"Acceleration\": 18.0, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford fairmont futura\", \"Miles_per_Gallon\": 24.0, \"Cylinders\": 4, \"Displacement\": 140.0, \"Horsepower\": 92.0, \"Weight_in_lbs\": 2865, \"Acceleration\": 16.4, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"amc concord dl\", \"Miles_per_Gallon\": 23.0, \"Cylinders\": 4, \"Displacement\": 151.0, \"Horsepower\": null, \"Weight_in_lbs\": 3035, \"Acceleration\": 20.5, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"volkswagen rabbit l\", \"Miles_per_Gallon\": 36.0, \"Cylinders\": 4, \"Displacement\": 105.0, \"Horsepower\": 74.0, \"Weight_in_lbs\": 1980, \"Acceleration\": 15.3, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"mazda glc custom l\", \"Miles_per_Gallon\": 37.0, \"Cylinders\": 4, \"Displacement\": 91.0, \"Horsepower\": 68.0, \"Weight_in_lbs\": 2025, \"Acceleration\": 18.2, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"mazda glc custom\", \"Miles_per_Gallon\": 31.0, \"Cylinders\": 4, \"Displacement\": 91.0, \"Horsepower\": 68.0, \"Weight_in_lbs\": 1970, \"Acceleration\": 17.6, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"plymouth horizon miser\", \"Miles_per_Gallon\": 38.0, \"Cylinders\": 4, \"Displacement\": 105.0, \"Horsepower\": 63.0, \"Weight_in_lbs\": 2125, \"Acceleration\": 14.7, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"mercury lynx l\", \"Miles_per_Gallon\": 36.0, \"Cylinders\": 4, \"Displacement\": 98.0, \"Horsepower\": 70.0, \"Weight_in_lbs\": 2125, \"Acceleration\": 17.3, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"nissan stanza xe\", \"Miles_per_Gallon\": 36.0, \"Cylinders\": 4, \"Displacement\": 120.0, \"Horsepower\": 88.0, \"Weight_in_lbs\": 2160, \"Acceleration\": 14.5, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"honda Accelerationord\", \"Miles_per_Gallon\": 36.0, \"Cylinders\": 4, \"Displacement\": 107.0, \"Horsepower\": 75.0, \"Weight_in_lbs\": 2205, \"Acceleration\": 14.5, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"toyota corolla\", \"Miles_per_Gallon\": 34.0, \"Cylinders\": 4, \"Displacement\": 108.0, \"Horsepower\": 70.0, \"Weight_in_lbs\": 2245, \"Acceleration\": 16.9, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"honda civic\", \"Miles_per_Gallon\": 38.0, \"Cylinders\": 4, \"Displacement\": 91.0, \"Horsepower\": 67.0, \"Weight_in_lbs\": 1965, \"Acceleration\": 15.0, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"honda civic (auto)\", \"Miles_per_Gallon\": 32.0, \"Cylinders\": 4, \"Displacement\": 91.0, \"Horsepower\": 67.0, \"Weight_in_lbs\": 1965, \"Acceleration\": 15.7, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"datsun 310 gx\", \"Miles_per_Gallon\": 38.0, \"Cylinders\": 4, \"Displacement\": 91.0, \"Horsepower\": 67.0, \"Weight_in_lbs\": 1995, \"Acceleration\": 16.2, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"buick century limited\", \"Miles_per_Gallon\": 25.0, \"Cylinders\": 6, \"Displacement\": 181.0, \"Horsepower\": 110.0, \"Weight_in_lbs\": 2945, \"Acceleration\": 16.4, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"oldsmobile cutlass ciera (diesel)\", \"Miles_per_Gallon\": 38.0, \"Cylinders\": 6, \"Displacement\": 262.0, \"Horsepower\": 85.0, \"Weight_in_lbs\": 3015, \"Acceleration\": 17.0, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chrysler lebaron medallion\", \"Miles_per_Gallon\": 26.0, \"Cylinders\": 4, \"Displacement\": 156.0, \"Horsepower\": 92.0, \"Weight_in_lbs\": 2585, \"Acceleration\": 14.5, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford granada l\", \"Miles_per_Gallon\": 22.0, \"Cylinders\": 6, \"Displacement\": 232.0, \"Horsepower\": 112.0, \"Weight_in_lbs\": 2835, \"Acceleration\": 14.7, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"toyota celica gt\", \"Miles_per_Gallon\": 32.0, \"Cylinders\": 4, \"Displacement\": 144.0, \"Horsepower\": 96.0, \"Weight_in_lbs\": 2665, \"Acceleration\": 13.9, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"Japan\"}, {\"Name\": \"dodge charger 2.2\", \"Miles_per_Gallon\": 36.0, \"Cylinders\": 4, \"Displacement\": 135.0, \"Horsepower\": 84.0, \"Weight_in_lbs\": 2370, \"Acceleration\": 13.0, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevrolet camaro\", \"Miles_per_Gallon\": 27.0, \"Cylinders\": 4, \"Displacement\": 151.0, \"Horsepower\": 90.0, \"Weight_in_lbs\": 2950, \"Acceleration\": 17.3, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford mustang gl\", \"Miles_per_Gallon\": 27.0, \"Cylinders\": 4, \"Displacement\": 140.0, \"Horsepower\": 86.0, \"Weight_in_lbs\": 2790, \"Acceleration\": 15.6, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"vw pickup\", \"Miles_per_Gallon\": 44.0, \"Cylinders\": 4, \"Displacement\": 97.0, \"Horsepower\": 52.0, \"Weight_in_lbs\": 2130, \"Acceleration\": 24.6, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"Europe\"}, {\"Name\": \"dodge rampage\", \"Miles_per_Gallon\": 32.0, \"Cylinders\": 4, \"Displacement\": 135.0, \"Horsepower\": 84.0, \"Weight_in_lbs\": 2295, \"Acceleration\": 11.6, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"ford ranger\", \"Miles_per_Gallon\": 28.0, \"Cylinders\": 4, \"Displacement\": 120.0, \"Horsepower\": 79.0, \"Weight_in_lbs\": 2625, \"Acceleration\": 18.6, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}, {\"Name\": \"chevy s-10\", \"Miles_per_Gallon\": 31.0, \"Cylinders\": 4, \"Displacement\": 119.0, \"Horsepower\": 82.0, \"Weight_in_lbs\": 2720, \"Acceleration\": 19.4, \"Year\": \"1982-01-01T00:00:00\", \"Origin\": \"USA\"}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjqkP0J4cdbs",
        "colab_type": "text"
      },
      "source": [
        "##E. OpenCV : Show image file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeZU75kpciJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# support JPG PNG TIFF etc.\n",
        "import cv2\n",
        "img = cv2.imread('D:/image-1.png') #Display image but WON'T display transparency\n",
        "img = cv2.imread('D:/image-1.png', cv2.IMREAD_UNCHANGED) # Display image without any change (may display transparency etc.)\n",
        "img = cv2.imread('D:/image-1.png', cv2.IMREAD_GRAYSCALE) # Display image in grey scale\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yq9YJufAAEnF",
        "colab_type": "text"
      },
      "source": [
        "#**5. DATA CLEANING**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-0SNXd1ARRI",
        "colab_type": "text"
      },
      "source": [
        "##A. NAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9G4vFfEBTRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get True / False if any Nans in each values\n",
        "dataset.isnull().any()\n",
        "\n",
        "#Get count of Nans per features => descending count\n",
        "dataset.isnull().sum().sort_values(ascending=False)\n",
        "\n",
        "# See in %\n",
        "a = dataset.isnull().sum()/dataset.shape[0]*100\n",
        "a.sort_values(ascending=False)\n",
        "\n",
        "# See % of NaN per columns\n",
        "for i in dataset.columns:\n",
        "  print(\"{} count NaN : {}\".format(\n",
        "      i, round(ds[i].isnull().sum()/len(ds),2)\n",
        "  ))\n",
        "\n",
        "# VISUALISATION : To see if nan value per column in HEATMAP\n",
        "fig, ax = plt.subplots(figsize=(18,10))\n",
        "_ = sns.heatmap(dataset.isnull(), cmap=\"YlGnBu\", yticklabels=False, ax=ax)\n",
        "\n",
        "# REPLACE NaN\n",
        "ds.fillna(0) #  replace all NaN by 0\n",
        "\n",
        "# Replace by means / standard error => Example with Age\n",
        "age_avg = data['Age'].mean()\n",
        "age_std = data['Age'].std()\n",
        "age_null_count = data['Age'].isnull().sum()\n",
        "age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
        "data['Age'][np.isnan(data['Age'])] = age_null_random_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_wIK_oG-I_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm5-n8dlEI0o",
        "colab_type": "text"
      },
      "source": [
        "# **6. SUPERVISED MACHINE LEARNING**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FkXL-c_EWXu",
        "colab_type": "text"
      },
      "source": [
        "## **SKLEARN**\n",
        "\n",
        "Got many tidy datasets using the same layout :\n",
        "- **no nan**\n",
        "- DESCR to get all pieces of information about each dataset => IMPORTANT : **print**\n",
        "- data => Explanatory variable => \"x\"\n",
        "- feature_names => every column name for the explanatory variable (sorted properly)\n",
        "- filename => where is stored the dataset file locally\n",
        "- target => Target variable => \"y\"\n",
        "- target_names => Target variable column name or value meaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFyG1ezjEkBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sklearn got many tidy datasets using the same layout (no nan / DESCR )\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "# We recommande to change from array to DataFrame format\n",
        "X = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
        "# Create y data set or add to the end of main dataset\n",
        "y = pd.DataFrame(cancer.target, columns=[\"cancer\"])\n",
        "\n",
        "# or can add to X using pd.Series but eventually longer\n",
        "X[\"cancer\"] = pd.Series(cancer.target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt46g1PzPiuh",
        "colab_type": "text"
      },
      "source": [
        "## A. PREPARATION FOR ML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFCabjm7Aakj",
        "colab_type": "text"
      },
      "source": [
        "> Split X, y in X_train and X_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqIh8UTcF1rB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Train and Test samples\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify = y)\n",
        "# random_state => seed for randomization\n",
        "# stratify => put the value to stratify so that same split in train as in original => so if y = 0 or 1 with 75% 0 in full dataset then in train will get 75% of 0 as well \n",
        "# CANNOT use stratify if only 1 y value\n",
        "\n",
        "# Can split in multiple X 2 by 2\n",
        "X_train_num, X_test_num, X_train_cat, X_test_cat, y_train, y_test = train_test_split(X_num, X_cat, y, test_size=0.3, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSdJH6ZExoV3",
        "colab_type": "text"
      },
      "source": [
        "> Normalisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oJLaIvQNKp8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalization\n",
        "# MANDATORY FOR :\n",
        "# PCA\n",
        "# NOT MANDATORY BUT GOOD PRACTICE :\n",
        "# ALD / LINEAR REGRESSION / LOGISTIC REGRESSION\n",
        "# DO NOT DO IT :\n",
        "# DECISION or RANDOM TREE\n",
        "# we use DataFrame to get user friendly output\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "\n",
        "X_train = pd.DataFrame(sc.fit_transform(X_train), columns = ds.columns, index = ds.index)\n",
        "X_test = pd.DataFrame(sc.transform(X_test), columns = ds.columns, index = ds.index) # NEVER fit the Test  \n",
        "# fit_transfrom will do fit & transform within same action => you fit and transform the X train "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NgyrOc_sPi6",
        "colab_type": "text"
      },
      "source": [
        "> Discretization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF1Yk3YVsSJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Discretization => transform continuous value in discrete ones => usefull for NaivesBayes Bernouilli or Decision Tree or Random Forest\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "\n",
        "kb = KBinsDiscretizer(n_bins=10, strategy='quantile', encode = \"ordinal\") # can change 'strategy=uniform' to get bloc\n",
        "X_train_discrete = pd.DataFrame(kb.fit_transform(X_train), columns=X_train.columns, dtype=str)\n",
        "X_test_discrete = pd.DataFrame(kb.transform(X_test), columns=X_train.columns, dtype=str)\n",
        "\n",
        "X_train_discrete = pd.get_dummies(X_train_discrete) # We want to keep all values => NO 'drop_first'\n",
        "X_test_discrete = pd.get_dummies(X_test_discrete) # We want to keep all values => NO 'drop_first'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YsNXy_gdcxU",
        "colab_type": "text"
      },
      "source": [
        "> Replace missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZQbunYOdfPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Option 1: KNN Imputer + use DataFrame to get nicer display\n",
        "from sklearn.impute import KNNImputer\n",
        "dataset = pd.DataFrame(KNNImputer(missing_values=0, n_neighbors=5).fit_transform(dataset), columns = dataset.columns) \n",
        "# \"missing_values\" is the value to replace (nan, O etc.) / n_neighbors => how many to mean the replace value\n",
        "\n",
        "\n",
        "# Sklearn KNN method to replace missing values\n",
        "from fancyimpute import KNN\n",
        "dataset = pd.DataFrame(KNN(k=3).fit_transform(dataset), columns = dataset.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvFWHWKtLzPJ",
        "colab_type": "text"
      },
      "source": [
        "> Reduce dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sVHy9gwL2l3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PCA => to minimize features\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=0.99, whiten=True, random_state=42) #n_components = 0 to 1 to know info kept or integer to get real components created\n",
        "principalComponents = pca.fit_transform(X)\n",
        "principalDF = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])\n",
        "\n",
        "# LDA => kind of PCA applied to target value\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "lda = LinearDiscriminantAnalysis(n_components=2) #n_components = 0 to 1 to know info kept or integer to get exactd nb components\n",
        "# should split train in train1 fit_transform and train2 just transform to avoid over-fitting\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IrWl7VOBTGJ",
        "colab_type": "text"
      },
      "source": [
        "> META SCRIPT - Split train & test / Normalize / Reduce Dim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz4Q6uoMBbaI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This script allow you to \n",
        "# It assumes you already get your features in 'X' and your target value in 'y'\n",
        "# You may want to play with 'test_size=0.3' (NOT test_size=0.5) and 'random_state'\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=1)\n",
        "\n",
        "X_train_norm = sc.fit_transform(X_train)\n",
        "X_train1, X_train2, y_train1, y_train2 = train_test_split(X_train_norm, y_train, test_size = 0.5, random_state=1)\n",
        "X_test_norm = sc.transform(X_test)\n",
        "\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "lda = LinearDiscriminantAnalysis(n_components=2)\n",
        "lda.fit(X_train1, y_train1)\n",
        "X_train2_lda = lda.transform(X_train2)\n",
        "X_test_lda = lda.transform(X_test_norm)\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_train_pca = pca.fit_transform(X_train_norm)\n",
        "X_test_pca = pca.transform(X_test_norm)\n",
        "\n",
        "# Return :\n",
        "# X_train, X_test, y_train, y_test for basic NONE NORMALIZED set\n",
        "# X_train_norm, X_test_norm, y_train, y_test for basic NORMALIZED set\n",
        "# X_train_pca, X_test_pca, y_train, y_test for PCA set\n",
        "# X_train2_lda, X_test_lda, y_train2, y_test for LDA set \n",
        "# FOR LDA, to minimize over-fitting => split X_train to use X_train2 on models fitting"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hT4RoPHFB8Or",
        "colab_type": "text"
      },
      "source": [
        "## B. COMMON ATTRIBUTES / PIECES OF INFORMATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8zw0N1CCBcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For (almost) all models => clf is your model\n",
        "clf_your_model.fit(X_train, y_train) # Fit (train) your model\n",
        "clf_your_model.score(X_test, y_test) # Accuracy score ALWAYS CALCULATE ON YOUR TEST => can compare test vs. train data score to see overfitting (big gap = less precision)\n",
        "clf_your_model.coef_ # to see your coef => sometimes clf_your_model.coef[0]\n",
        "clf_your_model.intercept_ # to get the B0 value (not relevant for all models)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2ZuC3v7P7bQ",
        "colab_type": "text"
      },
      "source": [
        "## C. LINEAR REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTNnmRVHPdk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run the basic\n",
        "from sklearn.linear_model import LinearRegression\n",
        "reg_lin = LinearRegression()\n",
        "reg_lin.fit(X_train, y_train)\n",
        "\n",
        "#IMPORTANT: FOR COEF\n",
        "reg_lin.coef_[0] # to get the coef\n",
        "\n",
        "# Résumé des paramètres du model\n",
        "reg_lin.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjbnGdfyGx34",
        "colab_type": "text"
      },
      "source": [
        "> Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeiCIe53Gzgs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(X, y, color='black')\n",
        "plt.plot(X, predictions, color='blue', linewidth=3)\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAL-KwgRvP3k",
        "colab_type": "text"
      },
      "source": [
        "## D. LOGISTIC REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cElBqSQgXjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "reg_log = LogisticRegression() # Can use class_weight=\"balanced\" to increase weight on less frequent values\n",
        "reg_log.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcIjCGNEJLLP",
        "colab_type": "text"
      },
      "source": [
        "## E. RIDGE and LASSO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1BeXxNHgfmr",
        "colab_type": "text"
      },
      "source": [
        "Ridge and Lasso allow to \"penalize\" in order to find better balance between Accurancy and Precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViVfge6L9tXd",
        "colab_type": "text"
      },
      "source": [
        "> LINEAR REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtthASQ089n_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ridge\n",
        "from sklearn.linear_model import Ridge\n",
        "reg_lin_ridge = Ridge(alpha = 0.01)  \n",
        "# Alpha = penalty => bigger score (10+) =  Improve Precision vs. decrease accuracy vs. closer 0 improve accuracy vs. precision  \n",
        "reg_lin_ridge.fit(X_train, y_train)\n",
        "\n",
        "#IMPORTANT: FOR COEF\n",
        "reg_lin_ridge.coef_[0] # to get the coef"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFspaDPX-mVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lasso\n",
        "from sklearn.linear_model import Lasso\n",
        "reg_lin_lasso = Lasso(alpha=1) # default 'alpha' = 1 => Big alpha = Improve Precision and decrease accuracy vs. Small Alpha = Improve accuracy et decrease precision\n",
        "reg_lin_lasso.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLyC5Wd9NIfM",
        "colab_type": "text"
      },
      "source": [
        "> Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk8-UixuBbnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualisation to compare ridge coef vs. basic reg lin\n",
        "# 'X' = is your main dataset with every features but NOT the target  \n",
        "perf_reg_lin_ridge = pd.DataFrame({\"params\": clf_reg_lin_ridge.coef_[0], \n",
        "                                       \"model\": \"ridge Alpha = 100\", \n",
        "                                       \"index\": range(0, len(X.columns))})\n",
        "\n",
        "perf_reg_lin = pd.DataFrame({\"params\": clf_reg_lin.coef_[0], \n",
        "                                       \"model\": \"linear\", \n",
        "                                       \"index\": range(0, len(X.columns))})\n",
        "\n",
        "perf_compar = pd.concat([perf_ridge_large_alpha,perf_lin])\n",
        "\n",
        "import seaborn as sns\n",
        "sns.pointplot(x = 'index',y = 'params',hue = 'model', data = perf_compar)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9HCRNt814UY",
        "colab_type": "text"
      },
      "source": [
        "> LOGISTIC REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piOHhP1Uh3Tt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ridge\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "reg_log = LogisticRegression(C=1.0)\n",
        "# By default Logistic regression applies Ridge (penalty 'l2') => play with the C value from 0.0 (high precision & low accuracy) to 10+ (low precission & high accuracy) \n",
        "\n",
        "reg_log.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0cIQFv6JRVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lasso\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "reg_log = LogisticRegression(penalty = \"l1\", solver = \"liblinear\", C=1.0) \n",
        "# penalty 'l1' = Lasso / solver must be 'liblinear' / C (default 1.0)  => 0 = very strong penalty (very precise but less accuracy) => 10+ (more accuracy but less precise)\n",
        "\n",
        "reg_log.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5WJnKstvbr7",
        "colab_type": "text"
      },
      "source": [
        "## F. DECISION TREE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRz5OHKkca4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate the Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier(criterion=\"gini\") # can you criterion = \"gini\" or \"entropy\" with \"entropy\" slightly less heterogeneous than \"gini\"\n",
        "clf.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6UERYSXedxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Accuracy Score\n",
        "clf.score(X_test,y_test) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtOFJil5dgCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check the prediction for specific X value\n",
        "X_new = np.array([[4,4,3,3]]) # IMPORTANT : array 2D => [[\n",
        "clf.predict_proba(X_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYEH5Pajd12R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# See all prediction\n",
        "clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INepqsgXd51k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# How to count difference value between 'gini' and 'entropy' criterion\n",
        "count = 0\n",
        "for i in range(0, len(y_pred_gini)):\n",
        "  \n",
        "  if y_pred_gini[i] != y_pred_entropy[i]:\n",
        "    count+= 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSOWxZ4oeVEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Option 2\n",
        "count = 0\n",
        "for a, b in zip(y_pred_gini,y_pred_entropy):\n",
        "  if a != b:\n",
        "    count+=1\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6c3QqzGdGti",
        "colab_type": "text"
      },
      "source": [
        "> VISUALISATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrjhFJdt0DNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Best visualisation option\n",
        "import graphviz \n",
        "from sklearn.tree import export_graphviz\n",
        "dot_data = export_graphviz(clf_gini,\n",
        "                           feature_names=X_train.columns,\n",
        "                           class_names=[\"0\",\"1\"],\n",
        "                           out_file=None) \n",
        "graph = graphviz.Source(dot_data) \n",
        "graph\n",
        "\n",
        "\n",
        "# or \"DRYer\"\n",
        "graphviz.Source(export_graphviz(clf_gini,\n",
        "                           feature_names=X_train.columns,\n",
        "                           class_names=[\"0\",\"1\"],\n",
        "                           out_file=None))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf_c1f27vkkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualisation using plot_tree\n",
        "from sklearn.tree import plot_tree\n",
        "plt.figure(figsize=(25,10))\n",
        "a = plot_tree(classifier_entropy, \n",
        "              feature_names=X.columns, \n",
        "              class_names=list(set(y)), # WARNING y must be a Series!\n",
        "              filled=True, \n",
        "              rounded=True, \n",
        "              fontsize=14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZc4eXWDdMKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualisation using graphviz to export .png\n",
        "from sklearn import tree\n",
        "tree.export_graphviz(classifier_gini, out_file=\"tree.png\",\n",
        "                filled=True, rounded=True,\n",
        "                special_characters=True,feature_names = X.columns,class_names=['B','R','L'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Waq96MysflwJ",
        "colab_type": "text"
      },
      "source": [
        "##G. RANDOM FOREST "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOJCOsWccQj7",
        "colab_type": "text"
      },
      "source": [
        "> REGRESSOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsTHNPtocUbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate the Decision Tree\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rft_r = RandomForestRegressor(n_estimators=50, max_depth=None) # 'n_estimator' = count of decision trees created  / max_depth = minimize to avoid over-fitting\n",
        "rft_r.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXGDZev9mLlg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get right number of decision trees in the forest using GridSearch\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "rft_r = RandomForestClassifier(n_estimators=50, max_depth=None) # 'n_estimator' = count of decision trees created\n",
        "params = {\"n_estimators\": range(20, 51, 10)}\n",
        "\n",
        "rft_r_grid = GridSearchCV(cv=10, estimator = rft_r, param_grid = params, verbose=2, n_jobs=-1)\n",
        "rft_r_grid.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "186YsCbfcNkn",
        "colab_type": "text"
      },
      "source": [
        "> CLASSIFIER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnvTnBuEfr1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate the Decision Tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rft_c = RandomForestClassifier(n_estimators=50) # 'n_estimator' = count of decision trees created  / max_depth = minimize to avoid over-fitting\n",
        "rft_c.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17734JP6gRhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get right number of decision trees in the forest using GridSearch\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "rft_c = RandomForestClassifier()\n",
        "params = {\"n_estimators\": range(20, 51, 10)}\n",
        "\n",
        "rft_c_grid = GridSearchCV(cv=10, estimator = rft_c, param_grid = params, verbose=2, n_jobs=-1)\n",
        "rft_c_grid.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mSC0Gu7d3dY",
        "colab_type": "text"
      },
      "source": [
        "## H. EXTRA TREE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcWqRNsSGIQD",
        "colab_type": "text"
      },
      "source": [
        "> REGRESSOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNC1h-94GKC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate the Decision Tree\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "reg_ett = ExtraTreesRegressor(n_estimators=100) # 'n_estimator' = count of decision trees created\n",
        "reg_ett.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyPOc9gGd6GJ",
        "colab_type": "text"
      },
      "source": [
        "> CLASSIFIER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rS9PcrTId8Jz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate the Decision Tree\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "clf_ett = ExtraTreesClassifier(n_estimators=100) # 'n_estimator' = count of decision trees created\n",
        "clf_ett.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3j8Gm7Ineal",
        "colab_type": "text"
      },
      "source": [
        "##I. NAIVE BAYES "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKMTQXLwnjvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate Naive Gaussian Base\n",
        "import sklearn.naive_bayes as nb\n",
        "clf_naivebayes = nb.GaussianNB()\n",
        "naivebayes_fit = clf_naivebayes.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "525pqxb1szNC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate Naive Gaussian Base\n",
        "## PLEASE CHECK 'DISCRETIZATION' IN 'PREPARATION' SECTION to modify data first\n",
        "\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "naivebayes = nb.BernoulliNB()\n",
        "naivebayes_fit = naivebayes.fit(X_train_discrete,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GFiQ-NTnkqb",
        "colab_type": "text"
      },
      "source": [
        "##J. SVM / SVC = SUPPORT VECTOR MACHINES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PBj9tKfR5uk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Support Vector Machines\n",
        "from sklearn.svm import SVC\n",
        "svm = SVC() # SOMETIMES need to set 'probability=True' => longer but avoid some error message\n",
        "# you may add 'class_weight=\"balanced\"' | you may change the kernel : 'linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}, default=’rbf’\n",
        "svm.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH4cQMM9qBbS",
        "colab_type": "text"
      },
      "source": [
        "##K. BAGGING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlgfGMHPGmH4",
        "colab_type": "text"
      },
      "source": [
        "> Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYuN-7idHTMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import BaggingRegressor as BR\n",
        "\n",
        "bregr = BR(base_estimator=SVR(), \n",
        "                        n_estimators=10, random_state=0)\n",
        "bregr.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3ZnfeQhGpCh",
        "colab_type": "text"
      },
      "source": [
        "> Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWRo5Qb2qAt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Bagging are meta models that allows to improve other 'real' models by doing multiple sub-section to test and better fit the 'real' model. \n",
        "from sklearn.ensemble import BaggingClassifier as BC\n",
        "\n",
        "bclass = BC(base_estimator = GaussianNB(), \n",
        "            n_estimators = 1000, max_samples=0.9) #max_features=1.0\n",
        "bclass.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5OYG11-pktC",
        "colab_type": "text"
      },
      "source": [
        "## L. BOOSTING - ADABoost XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAoOYAiap7ap",
        "colab_type": "text"
      },
      "source": [
        "> ADABoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTNNRHSDpsL7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PARAMETERS for all ADABoost type \n",
        "# -'learning_ratefloat' by default 1 but closer to 0 learn smaller step but longer to learn\n",
        "# - 'n_estimators' by default 50 = count of iterations\n",
        "# - 'random_state' = to set for same result\n",
        "\n",
        "# For REGRESSION \n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "clf = AdaBoostRegressor() # Can change 'base_estimator=' => by default 'DecisionTreeRegressor(max_depth=3)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Get the score for each model iteration\n",
        "for score in clf.staged_score(X_train, y_train)\n",
        "\n",
        "# CLASSIFICATION\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3)) # Can change 'base_estimator=' => by default 'DecisionTreeRegressor(max_depth=1)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Get the score for each model iteration\n",
        "for score in clf.staged_score(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQDK4hCc9Pim",
        "colab_type": "text"
      },
      "source": [
        "> Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFPt2ZY5fo26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CLASSIFICATION\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gbc = GradientBoostingClassifier(n_estimators=100, max_depth=3) # Can play with n_estimators and max_depth\n",
        "gbc.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aMHvLkHrgyU",
        "colab_type": "text"
      },
      "source": [
        "> XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYC3cQ2bri65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Better Meta Model Booster than AdaBoost\n",
        "\n",
        "# REGRESSOR\n",
        "! pip3 install xgboost\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "clf = XGBRegressor()\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2406Gz29Rsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CLASSIFIER\n",
        "! pip3 install xgboost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "clf = XGBClassifier()\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mofNHfBmvWwy",
        "colab_type": "text"
      },
      "source": [
        "## M. GRID SEARCH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eutJ8cvXg0nB",
        "colab_type": "text"
      },
      "source": [
        "Test multiple parameters and parameter values to compare and get better score  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0HTQWH2cL6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basics\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "clf = your_classifier\n",
        "params = {'param_name1' : [Value1, Value2], 'param_name2' : np.arange(1, 10, 1)}\n",
        "\n",
        "grid = GridSearchCV(estimator=clf, param_grid= params, cv = 10, verbose=0, n_jobs=-1)\n",
        "grid.fit(X_train, y_train)\n",
        "# verbose : 0/1/2 allows to display message to follow Grid work\n",
        "# n_jobs : allow to paralelize work => put -1 to get max paralezisation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJVMQGO8Tr6L",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_NS8dsLcH-0",
        "colab_type": "text"
      },
      "source": [
        "> Grid Search Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBjyuwIswcHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Grid search with Decision Tree\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "rtc = DecisionTreeClassifier()\n",
        "params = {'max_depth' : np.arange(1,10),\n",
        "         'min_samples_split' : [2, 5, 10, 20]}\n",
        "grid =  GridSearchCV(estimator=rtc, param_grid= params, cv = 10)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Grid search with Lasso\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "lasso = Lasso()\n",
        "params = {'alpha' : [10**(-a) for a in range(10)]}\n",
        "grid = GridSearchCV(lasso,param_grid=params, cv = 10)\n",
        "grid.fit(X_train,y_train)\n",
        "\n",
        "# Grid Search Lasso on Logistic Reggresion\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "clf = LogisticRegression(penalty = \"l1\", solver = \"liblinear\")\n",
        "params = {'C' : [.001,.01,.1,1,10,100]}\n",
        "grid = GridSearchCV(clf,param_grid=params, cv = 10)\n",
        "grid.fit(X_train,y_train)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI3gJ0jtcOnV",
        "colab_type": "text"
      },
      "source": [
        "> Apply Grid Search on multiple levels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9V5K4X0CcTwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example to apply max_features and n_estimators on BaggingClassifier \n",
        "# & the var_smoothing to the GaussianNB within the Bagging\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "g = GaussianNB()\n",
        "params = {'max_features': [4,5,6,7,8], \n",
        "          'n_estimators' : [5, 10], \n",
        "          'base_estimator__var_smoothing' : [1,2]\n",
        "          }\n",
        "grid_search = GridSearchCV(BaggingClassifier(base_estimator=g, random_state=0), params)\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(grid_search.best_params_)\n",
        "print(grid_search.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGyrKQNRJ2VO",
        "colab_type": "text"
      },
      "source": [
        "> Global parameters for all grid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_ce9_xoJ06h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid.best_params_# To get an object with the best paramter values\n",
        "grid.best_estimator_.score(X_test, y_test) # To test accuracy on X and y test\n",
        "gsNaive_Bayes.best_score_ # Mean cross-validated score of the best_estimator => done on your X and y used in '.fit' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeCWTosw2dMg",
        "colab_type": "text"
      },
      "source": [
        "## N. VOTING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQIvTIut4Eh5",
        "colab_type": "text"
      },
      "source": [
        "*YOU MUST HAVE CHECKED FOR YOUR ESTIMATOR BEST PARAMETERS USING GRID SEARCH.*\n",
        "\n",
        "*GET OBJECT = estimator.best_estimator_*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7RYdxUX3WgB",
        "colab_type": "text"
      },
      "source": [
        "> Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smuumoQ43YRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################\n",
        "# You must have done your GridSearch to find your 'Best_parameters'\n",
        "########################\n",
        "\n",
        "# GBC_best, garandF_best ... are your best parameters using GridSearch '.best_parameters'\n",
        "# => Exeample\n",
        "Log = LogisticRegression()\n",
        "log_param_grid = {\"solver\":[\"newton-cg\", \"liblinear\", \"sag\", \"saga\"],\n",
        "                 \"class_weight\": [None, \"balanced\"],\n",
        "                 \"C\": [0.5, 0.6,0.7,0.8,0.9,1.0],\n",
        "                 \"tol\": [1e-4, 1e-3]}\n",
        "gsLog = GridSearchCV(Log, log_param_grid, cv =10, scoring ='accuracy', n_jobs=-1, verbose=1)\n",
        "gsLog.fit(X_train, y_train)\n",
        "gsLog_best = gsLog.best_estimator_\n",
        "\n",
        "\n",
        "# Voting Regressor\n",
        "from sklearn.ensemble import VotingRegressor\n",
        "votingR = VotingClassifier(estimators=[(\"GradientBoosting\", GBC_best),(\"Random Forest\",gsrandF_best),(\"LogisticRegression\",gsLog_best),(\"Naive Bayes\",gsNaive_Bayes_best)], \n",
        "                           voting='soft')\n",
        "\n",
        "votingR = votingR.fit(X_train,y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgk0iy5g27-n",
        "colab_type": "text"
      },
      "source": [
        "> Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl9uRLil2t3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################\n",
        "# You should find your 'Best_parameters' through GridSearch before doing Voting\n",
        "########################\n",
        "\n",
        "# GBC_best, garandF_best ... are your best parameters using GridSearch '.best_parameters'\n",
        "# => Exeample\n",
        "GBC = GradientBoostingClassifier()\n",
        "gb_param_grid = {'loss' : [\"deviance\"],\n",
        "              'n_estimators' : [100,200,300],\n",
        "              'learning_rate': [0.1, 0.05, 0.01],\n",
        "              'max_depth': [4, 8],\n",
        "              'min_samples_leaf': [0.05,0.1],\n",
        "              'max_features': [0.3, 0.1] \n",
        "              }\n",
        "\n",
        "gsGBC = GridSearchCV(GBC,gb_param_grid, cv=10, scoring=\"accuracy\", verbose = 1)\n",
        "\n",
        "gsGBC.fit(X_train,np.ravel(y_train))\n",
        "\n",
        "GBC_best = gsGBC.best_estimator_\n",
        "\n",
        "\n",
        "# Voting Classifier\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "votingC = VotingClassifier(estimators=[(\"GradientBoosting\", GBC_best),(\"Random Forest\",gsrandF_best),(\"LogisticRegression\",gsLog_best),(\"Naive Bayes\",gsNaive_Bayes_best)], \n",
        "                           voting='soft')\n",
        "\n",
        "votingC = votingC.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfxp1jwg2l45",
        "colab_type": "text"
      },
      "source": [
        "## O. STACKING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz8gWnF4BqWz",
        "colab_type": "text"
      },
      "source": [
        "> Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyScU0G32vXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import StackingRegressor\n",
        "estimators = [('lr', RidgeCV()), ('svr', LinearSVR(random_state=42))]\n",
        "\n",
        "reg = StackingRegressor(estimators=estimators, \n",
        "                        final_estimator=RandomForestRegressor(n_estimators=10, \n",
        "                                                              random_state=42)\n",
        "                        )\n",
        "\n",
        "reg.fit(X_train, y_train))\n",
        "reg.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4LgOMH3BuNw",
        "colab_type": "text"
      },
      "source": [
        "> Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7KPUCUYBwPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "estimators = [\n",
        "              ('rf', RandomForestClassifier(n_estimators=10, random_state=42)), \n",
        "              ('svr', make_pipeline(StandardScaler(), \n",
        "                                    LinearSVC(random_state=42)))]\n",
        "\n",
        "clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
        "clf.fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAL2NS63qX6h",
        "colab_type": "text"
      },
      "source": [
        "## P. MODEL ANALYSIS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEZ5UxYO-fPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Baseline (calculate the means) \"Dumb model\" to compare against if model < Baseline => very bad !\n",
        "max(y_test.means(), abs(1-y_test.means())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bg4nJgriFGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mean Square Error (=MSE)\n",
        "# This calculate \n",
        "# np.sqrt(np.mean((y_pred)**2))\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mean_squared_error(y_true, y_pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBvvyE-zqmRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Confusion Matrix\n",
        "from sklearn import metrics\n",
        "cm = metrics.confusion_matrix(y, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d') # annot=True to dsplay value / fmt='d' allow to get integer value (do NOT always work) / 'nomralize=\"true\"' to see on 0 to 1\n",
        "\n",
        "# can add the real label value on x and y label\n",
        "sns.heatmap(cm, annot=True, xticklabels=sorted(dataset.quality.unique()), yticklabels=sorted(dataset.quality.unique())) # where 'quality' is your target value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIpCLd3ZvK_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true=y_test, y_pred=classifier.predict(X_test)))\n",
        "# precision = true positive/(true positive + false positive) | recal = true positive/total real positives\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ty5jRz_kGqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ROC\n",
        "# Compare True Positive vs. False positive => 1 = 'perfect' model | 0.5 = random model | 0 = Always wrong !\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "logit_roc_auc = roc_auc_score(y_test, classifier.predict(X_test)) # classifier is the classifier used (e.g. reglog etc.)\n",
        "fpr, tpr, thresholds = roc_curve(y_test, classifier.predict_proba(X_test)[:, 1]) # we use [:,1] to get the 2nd column from predict_proba (positive true / false result)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' %logit_roc_auc)\n",
        "plt.plot([0, 1], [0, 1], 'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig('Log_ROC')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6L8rRUSCaVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# F_score for quantitative regression "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ckQF1ZtCfkj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Chi 2 for quali and quanti variables\n",
        "from sklearn.feature_selection import chi2\n",
        "feature_importance = chi2(X, y)\n",
        "# Display in usefull DataFrame\n",
        "feature_ranking = pd.DataFrame(columns=X.columns, data=feature_importance, index=[\"Chi2 Score\", \"P-value\"]).transpose().sort_values(\"Chi2 Score\", ascending=False)\n",
        "\n",
        "# VISUALISATION\n",
        "ax =sns.catplot(x=\"Chi2 Score\", y=[index for index in feature_ranking.index], data = feature_ranking, kind=\"bar\")\n",
        "ax.set(xlabel=\"Chi2 Score\", ylabel=\"Features\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6nfEVcRQN91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cross Validation => to check score by splitting X_train in sub_Xtrain and X_train_test\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn import metrics\n",
        "cross_val_score(clf, X_train, y_train, cv=10)\n",
        "cross_val_predict(clf, X_train, y_train, cv=10)\n",
        "\n",
        "# Example to get means of various cross val score\n",
        "cross_val_score(classifier, X_train, y_train, scoring = \"accuracy\", cv = 10, n_jobs=4).mean() # 'classifier' is the classifier used to be tested"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzB15-G6Tvh-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Accuracy Score\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFxo8xryWfPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature importance (Decision Tree)\n",
        "feature_importance = pd.DataFrame(\n",
        "    {\"features\": X_train.columns, \"score\": classifier_tree.feature_importances_}).sort_values(by=\"score\", ascending=False)\n",
        "# Can visualize it\n",
        "sns.catplot(x=\"score\", y=\"features\", data=feature_importance, kind=\"bar\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOpyMWZP7V7o",
        "colab_type": "text"
      },
      "source": [
        "> Test multiple classifier and cross_validate_them to see best one in DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngZcMn7i6Imd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CREATE MULTIPLE CLASSIFIERS AND COMPARE THEM THROUGH CROSS VALIDATION\n",
        "# Put all your classifier in an empty classifier => then add each of them using .append()'\n",
        "\n",
        "# 1) put them one at a time.\n",
        "classifiers = []\n",
        "classifiers.append(RandomForestClassifier())\n",
        "classifiers.append(GradientBoostingClassifier())\n",
        "classifiers.append(LogisticRegression())\n",
        "classifiers.append(BernoulliNB())\n",
        "\n",
        "# 2) Get restults in cross_val \n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cv_results = []\n",
        "for classifier in classifiers:\n",
        "  cv_results.append(cross_val_score(classifier, X_train, y_train, cv=10 ,scoring=\"accuracy\"))\n",
        "\n",
        "# 3) Create DataFrame to display result\n",
        "\n",
        "results = pd.DataFrame({\"Algorithm\": [\"Random_Forest\", \"GradientBoosting\", \"LogisticRegression\", \"NaiveBayes\"],\n",
        "             \"Accuracy_mean\": [cv_result.mean() for cv_result in cv_results],\n",
        "             \"Std\": [cv_result.std() for cv_result in cv_results]})\n",
        "\n",
        "results = results.sort_values(by=\"Accuracy_mean\", ascending=False)\n",
        "results\n",
        "\n",
        "# 4) Show in catplot\n",
        "sns.catplot(x='Accuracy_mean', \n",
        "            y=\"Algorithm\", \n",
        "            data=results, \n",
        "            kind=\"bar\", \n",
        "            **{'xerr':[cv_result.std() for cv_result in cv_results]})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlHKE7yJ7d8F",
        "colab_type": "text"
      },
      "source": [
        "> Compare prediction correlation between estimators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3F6B0Vr7rIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1a. Correlation for 0 or 1 prediction\n",
        "test_Survived_NaiveBayes = pd.Series(gsNaive_Bayes_best.predict(X_test), name=\"Naive Bayes\")\n",
        "test_Survived_LogReg = pd.Series(gsLog_best.predict(X_test), name=\"Log\")\n",
        "test_Survived_GBC = pd.Series(GBC_best.predict(X_test), name=\"GBC\")\n",
        "test_Survived_RF = pd.Series(gsrandF_best.predict(X_test), name=\"RF\")\n",
        "\n",
        "# 1b. Correlation for probabilities (P(y=1))\n",
        "test_Survived_NaiveBayes = pd.Series(gsNaive_Bayes_best.predict_proba(X_test)[:,1], name=\"Naive Bayes\")\n",
        "test_Survived_LogReg = pd.Series(gsLog_best.predict_proba(X_test)[:,1], name=\"Log\")\n",
        "test_Survived_GBC = pd.Series(GBC_best.predict_proba(X_test)[:,1], name=\"GBC\")\n",
        "test_Survived_RF = pd.Series(gsrandF_best.predict_proba(X_test)[:,1], name=\"RF\")\n",
        "\n",
        "# 2 Show restult in corr() heatmap\n",
        "ensemble_results = pd.concat([test_Survived_NaiveBayes,\n",
        "                              test_Survived_GBC, \n",
        "                              test_Survived_LogReg,\n",
        "                              test_Survived_RF],axis=1)\n",
        "\n",
        "sns.heatmap(ensemble_results.corr(), annot=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fGLoo_lJ_zq",
        "colab_type": "text"
      },
      "source": [
        "## Q. PIPELINE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkchcVDRKGXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pipeline allow to run various estimators on a seemlessly way to combine them.\n",
        "# It uses a list of (key, value) pairs => key =  name you want to give this step | 'value' is the estimator object\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipe = Pipeline(steps=[('scaler', StandardScaler()), ('svc', SVC())])\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# Can do within GridSearch and cv (=cross-validation) with Standardscaller\n",
        "# Better to use pipeline because it will fit on the train fold within cv and transform both folds\n",
        "params = {'SVM__C':[0.001, 0.1, 10, 100, 10e5], 'SVM__gamma':[0.1, 0.01]} # NOTE : the '__' allow to go \"within\" the pipelne estimator parameters and NOT stay on the GridSearch level\n",
        "grid = GridSearchCV(pipe, param_grid=params, cv=10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw-SbhZTfqJg",
        "colab_type": "text"
      },
      "source": [
        "##R. SAVE & LOAD MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lj5MErnKfspx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save model\n",
        "import joblib\n",
        "joblib.dump(model, 'model.pkl')\n",
        "\n",
        "#Save data_prep\n",
        "import joblib\n",
        "joblib.dump(cv, 'data_prep.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPU6ZnBjgS7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LOAD Model\n",
        "the_model = open('the_model.pkl','rb')\n",
        "clf = joblib.load(the_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJqW19-RgXYV",
        "colab_type": "text"
      },
      "source": [
        "#**7. NONE-SUPERVISED ML**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejIT3UwegcXw",
        "colab_type": "text"
      },
      "source": [
        "##A. PREPARATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyATsjUmgbUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Different from Supervised ML\n",
        "# No target value so no split X_train / X_test\n",
        "# You may want to normalize and dummify data."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pexpS7VhhC7u",
        "colab_type": "text"
      },
      "source": [
        "##B. K-MEANS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIOW-zKpmFBt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# KMEANS\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kms = KMeans(n_clusters=10, init='k-means++', n_init=10, max_iter=300, random_state=rdm_seed)\n",
        "kms.fit(X)\n",
        "y_kmeans = kms.fit_predict(X) # Fit and predict => get array with cluster 'name'\n",
        "\n",
        "distortions = kms.inertia_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szAQAbKm5TTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to apply kmeans and compare predictions done through clustering against real target values\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.stats import mode\n",
        "\n",
        "def kmeans_to_target(data, target, kmeans_instance=None):\n",
        "  if kmeans_instance is None:\n",
        "    kmeans_instance = KMeans()\n",
        "  y_kms = kmeans_instance.fit_predict(data)\n",
        "\n",
        "  labels = pd.DataFrame(np.zeros_like(y_kms), dtype='int')\n",
        "  for i in range (kmeans_instance.n_clusters):\n",
        "    mask = (y_kms ==i)\n",
        "    labels.iloc[mask, :] = mode(target[mask])[0]\n",
        "  results = labels.values.flatten()\n",
        "  return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hS4CX_RFhJNE",
        "colab_type": "text"
      },
      "source": [
        "> ANALYSIS TO FIND RIGHT VALUE OF KMEANS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT2h9ABEhMGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ELBOW\n",
        "max_n = 51\n",
        "rdm_seed = 0\n",
        "\n",
        "# calculate distortion for a range of number of cluster\n",
        "distortions = []\n",
        "for i in range(1, max_n):\n",
        "    kms = KMeans(\n",
        "        n_clusters=i, init='k-means++',\n",
        "        n_init=10, max_iter=300,\n",
        "        tol=1e-04, random_state=rdm_seed\n",
        "    )\n",
        "    kms.fit(X)\n",
        "    distortions.append(kms.inertia_)\n",
        "\n",
        "# plot\n",
        "plt.plot(range(1, max_n), distortions, marker='o')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('Distortion')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI7TnV090wm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# KELBOW\n",
        "# Dans ce cas là, on regarde le point le plus haut\n",
        "# ligne verte =\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "# Generate synthetic dataset with 8 random clusters\n",
        "\n",
        "# Instantiate the clustering model and visualizer\n",
        "model = KMeans() # Can set the random_state=\n",
        "visualizer = KElbowVisualizer(\n",
        "    model, k=(2,12), metric='calinski_harabaz', timings=True\n",
        ") # k to get min and max \n",
        "\n",
        "visualizer.fit(X)        # Fit the data to the visualizer\n",
        "plt.show"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFgTss_qmsLJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SILHOUETE\n",
        "\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "print(__doc__)\n",
        "\n",
        "X2 = X.values\n",
        "\n",
        "range_n_clusters = [2, 3, 4, 5, 6]\n",
        "\n",
        "for n_clusters in range_n_clusters:\n",
        "    # Create a subplot with 1 row and 2 columns\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    fig.set_size_inches(18, 7)\n",
        "\n",
        "    # The 1st subplot is the silhouette plot\n",
        "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
        "    # lie within [-0.1, 1]\n",
        "    ax1.set_xlim([-0.1, 1])\n",
        "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
        "    # plots of individual clusters, to demarcate them clearly.\n",
        "    ax1.set_ylim([0, len(X2) + (n_clusters + 1) * 10])\n",
        "\n",
        "    # Initialize the clusterer with n_clusters value and a random generator\n",
        "    # seed of 10 for reproducibility.\n",
        "    clusterer = KMeans(n_clusters=n_clusters, random_state=rdm_seed)\n",
        "    cluster_labels = clusterer.fit_predict(X2)\n",
        "\n",
        "    # The silhouette_score gives the average value for all the samples.\n",
        "    # This gives a perspective into the density and separation of the formed\n",
        "    # clusters\n",
        "    silhouette_avg = silhouette_score(X2, cluster_labels)\n",
        "    print(\"For n_clusters =\", n_clusters,\n",
        "          \"The average silhouette_score is :\", silhouette_avg)\n",
        "\n",
        "    # Compute the silhouette scores for each sample\n",
        "    sample_silhouette_values = silhouette_samples(X2, cluster_labels)\n",
        "\n",
        "    y_lower = 10\n",
        "    for i in range(n_clusters):\n",
        "        # Aggregate the silhouette scores for samples belonging to\n",
        "        # cluster i, and sort them\n",
        "        ith_cluster_silhouette_values = \\\n",
        "            sample_silhouette_values[cluster_labels == i]\n",
        "\n",
        "        ith_cluster_silhouette_values.sort()\n",
        "\n",
        "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
        "        y_upper = y_lower + size_cluster_i\n",
        "\n",
        "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
        "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
        "                          0, ith_cluster_silhouette_values,\n",
        "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
        "\n",
        "        # Label the silhouette plots with their cluster numbers at the middle\n",
        "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
        "\n",
        "        # Compute the new y_lower for next plot\n",
        "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
        "\n",
        "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
        "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
        "    ax1.set_ylabel(\"Cluster label\")\n",
        "\n",
        "    # The vertical line for average silhouette score of all the values\n",
        "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
        "\n",
        "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
        "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
        "\n",
        "    # 2nd Plot showing the actual clusters formed\n",
        "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
        "    ax2.scatter(X2[:, 0], X2[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n",
        "                c=colors, edgecolor='k')\n",
        "\n",
        "    # Labeling the clusters\n",
        "    centers = clusterer.cluster_centers_\n",
        "    # Draw white circles at cluster centers\n",
        "    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
        "                c=\"white\", alpha=1, s=200, edgecolor='k')\n",
        "\n",
        "    for i, c in enumerate(centers):\n",
        "        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
        "                    s=50, edgecolor='k')\n",
        "\n",
        "    ax2.set_title(\"The visualization of the clustered data.\")\n",
        "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
        "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
        "\n",
        "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
        "                  \"with n_clusters = %d\" % n_clusters),\n",
        "                 fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-vNd2p9dVp5",
        "colab_type": "text"
      },
      "source": [
        "> ANALYSE RESULTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NAZdtfpdYK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Heatmap to show group with key features created by Kmeans\n",
        "sns.heatmap(pd.DataFrame(sc.inverse_transform(kmeans.cluster_centers_[:,:-1]),\n",
        "                         columns=X.columns[:-1]),annot=True) #sc.inverse_transform used to reverse the normalization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mn6fcObreA0T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# See Kmeans per 2 features using scatter plot\n",
        "\n",
        "plt.scatter(X.iloc[:, 1][y_kmeans == 0], X.iloc[:, 2][y_kmeans == 0], s = 100, c = 'red', label = 'Careful')\n",
        "plt.scatter(X.iloc[:, 1][y_kmeans == 1], X.iloc[:, 2][y_kmeans == 1], s = 100, c = 'green', label = 'Standard')\n",
        "plt.scatter(X.iloc[:, 1][y_kmeans == 2], X.iloc[:, 2][y_kmeans == 2], s = 100, c = 'blue', label = 'Vache à lait')\n",
        "plt.scatter(X.iloc[:, 1][y_kmeans == 3], X.iloc[:, 2][y_kmeans == 3], s = 100, c = 'cyan', label = 'Target')\n",
        "plt.scatter(X.iloc[:, 1][y_kmeans == 4], X.iloc[:, 2][y_kmeans == 4], s = 100, c = 'magenta', label = 'Careless')\n",
        "plt.scatter(kmeans.cluster_centers_[:,1], kmeans.cluster_centers_[:,2], s = 300, c = 'yellow', label = 'centroids')\n",
        "plt.title('clusters of clients')\n",
        "plt.xlabel('Annual Income (k$)')\n",
        "plt.ylabel('Spending Score (1-100)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj2ZMi8I4OvG",
        "colab_type": "text"
      },
      "source": [
        "## C. DBSCANS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pHDctRl4TF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unsupervised dedicated for complicated clustering like geographycal etc.\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "dbs = DBSCAN(eps=0.5, min_samples=15) # eps = max distance between 2 samples | min_samples is your min samples to create 'core point'\n",
        "dbscan_predict = dbs.fit_predict(X)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWP5hsZy86Th",
        "colab_type": "text"
      },
      "source": [
        "#**8. DEEP-LEARNING - Tensorflow2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZAVIbVD9HMh",
        "colab_type": "text"
      },
      "source": [
        "##A. LIBRARY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGVVYj5UFIc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basics all system\n",
        "!pip install tensorflow-gpu==2.2 #Any system\n",
        "import tensorflow as tf\n",
        "from pathlib import Path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XC_22RVxC83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basics for Collab\n",
        "%tensorflow_version 2.x # Only for Collab\n",
        "import tensorflow as tf\n",
        "from pathlib import Path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDm7Gv9aFDP2",
        "colab_type": "text"
      },
      "source": [
        "##B. BASICS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBZxZiX-FHx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.__version__ # check TensorFlow version\n",
        "tf_ds.reshape([1, 4]) # reshape\n",
        "tf_ds.reshape(-1) # transform tf_ds in a full vector\n",
        "tf_ds.squeeze() # will check only dimension 1 and remove them => keep other dimensions <> from 1\n",
        "\n",
        "tf.zeros_like(real_outputs) # create vectore filled by 0 size of \"real_outputs\"\n",
        "tf.ones_like(real_outputs) # create vectore filled by 0 size of \"real_outputs\"\n",
        "\n",
        "repeated_ds = ds_train.repeat(10) # repeat dataset 10 times => useful for data augmentation\n",
        "\n",
        "\n",
        "tf_ds = tf.convert_to_tensor(anything) # Transform any object (list, etc.) into tensor\n",
        "\n",
        "tf_ds = tf.keras.preprocessing.sequence.pad_sequences(anything, padding='post') # This padd (add extra value to get the same length within the array / tensor) | padding = 'post' pour effectuer padding après.\n",
        "\n",
        "tf_ds = tf.keras.backend.argmax(x, axis-1) # apply both argmax and transform to tensor => prevent the 'Cannot convert a symbolic Tensor' issue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tg2WHHvn5K3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Random tensor\n",
        "tf.reshape(np.absolute(np.random.randn(x_dim*y_dim*z_dim)), [x_dim, y_dim, y_dim]) # return 3d tensor with random normal distributed value (mean = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PloXfGHnoV0_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# REPEAT Tensor along axis\n",
        "tf.repeat(tf_ds, repeats=x_times, axis=2) # Repeat x_times along axis => IMPORTANT, the Axis must already exist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gayQulS0a5s",
        "colab_type": "text"
      },
      "source": [
        "##C. CALCULATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ1Hztga0Y8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t3 = tf.matmul(t1, t2) # product matrix => same as : t3 = t1 @ t2\n",
        "t1.assign([2, 3]) # Will replace the value within t1\n",
        "t2 = t2.assign_add(t1) # add t1 to t2 and save result in t2 at the same time\n",
        "t2 = t2.assign_sub(t1) # substract t1 to t2 and save result in t2 at the same time\n",
        "\n",
        "tf.math.add(t1, t2) # return tensor with sum from t1 and t2\n",
        "tf.math.reduce_sum(t1, axis=2,  keepdims=True) # calculate the total sum along the 3rd axis (index = 2 because starts from 0) AND can choose to leave 3rd dimension with depth 1\n",
        "tf.math.divide(t1, t2) # return tensor by dividing t1 by t2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2_E9M8en05Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0lYYX3I_2Zp",
        "colab_type": "text"
      },
      "source": [
        "##D. VISUALISATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4QqyklkAJ8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize image\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "\n",
        "random_image = np.random.randint(100) # 100 is to see within the first 100 images\n",
        "plt.imshow(X_train[random_image])\n",
        "plt.title(y_train[random_image])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR7hsBsXvFjh",
        "colab_type": "text"
      },
      "source": [
        "##E. DOWNLOAD DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBokNC0gvIuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from CIFAR10\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "(X_train, y_train),(X_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHy_OzL20b4r",
        "colab_type": "text"
      },
      "source": [
        "> Visualize Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yf17B-f0eGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualisation d'une image aléatoire\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "\n",
        "random_image = np.random.randint(100)\n",
        "plt.imshow(X_train[random_image])\n",
        "plt.title(y_train[random_image])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0hib6aP03i7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize random image for each target\n",
        "def visualize_random_img_for_each_target(X ,y, nrows, ncols):\n",
        "  \n",
        "  fig, axes = plt.subplots(nrows=nrows, ncols=ncols)\n",
        "  for index, ax in enumerate(axes.flat):\n",
        "    mask = y == index\n",
        "    mask = mask.squeeze()\n",
        "    random_image = np.random.randint(mask.sum()) # mask is a boolean so .sum() will make sure we get max value related to the mask\n",
        "    ax.imshow(X[mask][random_image])\n",
        "    ax.set_title(index)\n",
        "    ax.axis('off')\n",
        "\n",
        "visualize_random_img_for_each_target(X_train,y_train, 2, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCDOclAX0llg",
        "colab_type": "text"
      },
      "source": [
        "> System with subfolders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDyPsAgXBTFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download zip file with many images stored in sub folder = their labels\n",
        "\n",
        "zip_file = tf.keras.utils.get_file(\"catsNdogs.zip\", # filename with file extension => Can change the name\n",
        "                                   \"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\", # file path & filename\n",
        "                                   cache_subdir=\"/content\", # to tell where to store the file once downloaded\n",
        "                                   extract=True) # by default = False => True for zip files\n",
        "\n",
        "import pathlib \n",
        "train_set = pathlib.Path(\"/content/cats_and_dogs_filtered/train\")\n",
        "\n",
        "# Convert all paths into string\n",
        "all_image_paths = [str(img_path) for img_path in list(train_set.glob(\"*/*\"))]\n",
        "# or\n",
        "all_image_paths = list(map(str, train_folder.glob(\"*/*\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T5dn1GIqVoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################\n",
        "# NOT MANDATORY\n",
        "# Convert path to binary\n",
        "first_tensors_bytes = [tf.io.read_file(path) for path in all_image_paths[:10]]\n",
        "\n",
        "# Decode binary to jpeg to display the picture\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "first_tensors_images = [tf.io.decode_jpeg(img) for img in first_tensors_bytes]\n",
        "\n",
        "# Display and check if color or black and white to display => otherwise error message because no channel = 3 for B&W \n",
        "random_index = np.random.randint(10)\n",
        "random_image = first_tensors_images[random_index]\n",
        "if random_image.shape[-1] == 3:\n",
        "  plt.imshow(random_image.numpy())\n",
        "else:\n",
        "  plt.imshow(random_image.numpy().squeeze(), cmap='gray')\n",
        "plt.show()\n",
        "#################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOXPlkZ_vs6P",
        "colab_type": "text"
      },
      "source": [
        "##F. DATA PREPARATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0hzfGJovx9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IF ALREADY X and y\n",
        "\n",
        "# Prepare X and y from pd.DataFrame\n",
        "X = ds.iloc[:, 1:].values\n",
        "y = ds.iloc[:, 0:1].values\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
        "dataset = dataset.shuffle(len(y)).batch(8) # Create a batch of 8 images\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWhjdS5MmHsw",
        "colab_type": "text"
      },
      "source": [
        ">> Visualize Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2FB2XLxmKBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for feat, label in dataset.take(1):\n",
        "  print(feat)\n",
        "  print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgjyGJw-mRda",
        "colab_type": "text"
      },
      "source": [
        "> IF STORED IN SUBFOLDERS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C5Fv-LfExrJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#IF STORED IN SUBFOLDERS => NEED TO CREATE LABELS based on SUBFOLDER NAMES\n",
        "\n",
        "#Create function\n",
        "def load_and_preprocess_images(path):\n",
        "  image = tf.io.read_file(path)\n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "  image = tf.image.resize(image, [224, 224])\n",
        "  return image / 255\n",
        "\n",
        "# Apply map\n",
        "ds_paths = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
        "ds_images = ds_paths.map(preprocess_and_load_images)\n",
        "\n",
        "# Prepare the labels / y values\n",
        "  # Get image labels \n",
        "labels = [path.name for path in train_set.iterdir()]\n",
        "  \n",
        "  # Get index for both cats and dogs \n",
        "label_index = {label : i for i, label in enumerate(labels)}\n",
        "\n",
        " # Create lables for each image\n",
        "all_image_labels = [label_index[path.parent.name] for path in list(train_set.glob(\"*/*\"))]\n",
        "\n",
        "  # Insert these  labelss\n",
        "tf_labels = tf.data.Dataset.from_tensor_slices(all_image_labels)\n",
        "\n",
        "# MERGE BOTH X AND y into new dataset\n",
        "full_ds = tf.data.Dataset.zip((ds_images, tf_labels))\n",
        "\n",
        "\n",
        "\n",
        "# Shuffle the dataset & create batchs (16) to avoid getting all the images sorted in the same right\n",
        "full_ds = full_ds.shuffle(len(all_image_paths)).batch(16)\n",
        "\n",
        "# Split Train and Test\n",
        "train_size = int(0.8 * len(all_image_paths))\n",
        "\n",
        "full_ds = full_ds.shuffle(len(all_image_paths))\n",
        "train_set = full_ds.take(train_size)\n",
        "test_set = full_ds.skip(train_size)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DKDZFxgGvND",
        "colab_type": "text"
      },
      "source": [
        ">> Visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS28o861Gx7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize some data \n",
        "for example_x, example_y in full_ds.take(2):\n",
        "  for i in range(len(example_y)):\n",
        "    plt.figure()\n",
        "    plt.title(example_y.numpy()[i])\n",
        "    plt.imshow(example_x.numpy()[i])\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvXDZaOYmFry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xInOpYQszWUq",
        "colab_type": "text"
      },
      "source": [
        "##G. DATA AUGMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov-OlwlxzgX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply some modifications randomly\n",
        "data_aug = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    horizontal_flip=True,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    data_format=\"channels_last\"\n",
        ")\n",
        "\n",
        "# Fit only relevant for \n",
        "data_aug.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJXvR67QFFcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data augmentation using function\n",
        "def load_and_preprocess_images(img):\n",
        "  img = tf.io.read_file(img)\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  img = tf.image.resize(img, [192, 192])\n",
        "  img = tf.image.random_flip_left_right(img)\n",
        "  img = tf.image.random_contrast(img, 0.50, 0.90)\n",
        "  img = tf.image.random_crop(img, size=(192, 192, 3))\n",
        "  img = img / 255.0\n",
        "  \n",
        "  return img\n",
        "\n",
        "# Apply function to train_set\n",
        "tf_train_set = tf_train_set.map(load_and_preprocess_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9y-oTrxlV4mT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Augmentation other function\n",
        "def data_aug (image, label):\n",
        "  image = tf.image.random_flip_left_right(image)\n",
        "  image = tf.image.random_contrast(image, 0, 3.4)\n",
        "  image = tf.image.random_crop(image, [25, 25, 3])\n",
        "  image = image / 255\n",
        "\n",
        "  return image, label\n",
        "\n",
        "repeated_ds = repeated_ds.repeat(10).map(data_aug)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHSGWVxNWsfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IMPORTANT : Always divide by 255 the test data if you did it on train data \n",
        "def valid_aug(image, label):\n",
        "  return image / 255, label\n",
        "\n",
        "ds_test = ds_test.map(valid_aug)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUpKnpXBwyUI",
        "colab_type": "text"
      },
      "source": [
        "##H. CREATE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juPDuy79w2y3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a model\n",
        "# \n",
        "# First row always set the input_shqpe=[height, width, channel]\n",
        "# Layer types : \"Dense\" are main | \"Conv2D\" are for CNN in 2D => filters and kernel_size usual\n",
        "# For last level : count of neurones = 1 if binary classifiation with activation = \"sigmoid\" / otherwise count of available laels with activation = \"softmax\" \n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=[192, 192, 3]),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'),\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'),\n",
        "    tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "#     tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.05),\n",
        "    tf.keras.layers.Dense(units=32, activation =\"relu\"),\n",
        "    tf.keras.layers.Dense(units=16, activation =\"relu\"),\n",
        "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary() # return the summary of the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDQGslXeN598",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For generative models\n",
        "generator = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=7*7*256, use_bias=False, input_shape=(100,)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.3),\n",
        "\n",
        "    tf.keras.layers.Reshape((7, 7, 256)),\n",
        "\n",
        "    tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.3),\n",
        "\n",
        "    tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.3),\n",
        "\n",
        "    tf.keras.layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')\n",
        "\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ0bDkHsd9OE",
        "colab_type": "text"
      },
      "source": [
        "## I. CREATE CUSTOM ACTIVATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2bY4_eJeB4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Swish Activation : \n",
        "# Source : https://www.bignerdranch.com/blog/implementing-swish-activation-function-in-keras/\n",
        "\n",
        "from keras.backend import sigmoid\n",
        "def swish(x, beta = 1):\n",
        "    return (x * sigmoid(beta * x))\n",
        "\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras.layers import Activation\n",
        "get_custom_objects().update({'swish': Activation(swish)})\n",
        "\n",
        "# you can call the swish in you activation within keras.layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAwpOuqaWHY8",
        "colab_type": "text"
      },
      "source": [
        "## I. MODEL TRANSFERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuBI-5SGWLJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Base Model\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=(224,224,3), \n",
        "                                               include_top=False,\n",
        "                                               weights = \"imagenet\"\n",
        "                                               )\n",
        "\n",
        "# Set it none trainable\n",
        "base_model.trainable = False\n",
        "\n",
        "# Example of Base Model\n",
        "# For object detection\n",
        "# InceptionV3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPjtZk7aWQmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create your model (len(labels))\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(len(labels), activation=\"softmax\")\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGjOe18LWmhZ",
        "colab_type": "text"
      },
      "source": [
        "> Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2bBoRGEWoXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we will allow backward propagation to the last 75th layers\n",
        "fine_tune_from = 75\n",
        "for layer in base_model.layers[-fine_tune_from:]:\n",
        "    layer.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeKtFT4p22OI",
        "colab_type": "text"
      },
      "source": [
        "##J. CREATE LOSS FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeDfWerX21m-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Special learning rate decreasing with step furterdown\n",
        "# Decrease by 4% after 10 000 batchs\n",
        "# staircase = True => va changer au bout de la 10 000ème et non PAS linéarisé\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    1e-3,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True)\n",
        "\n",
        "#Compile with:\n",
        "# loss => function used to calculate loss\n",
        "# optimizer => use \"Adam\" better than Sigmoid Gradient => learning late using the \"lr_schedule\"\n",
        "# metrics => to calculate the \"score\"\n",
        "\n",
        "# FOR BINARY CLASS\n",
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(lr_schedule),\n",
        "    loss= tf.keras.losses.binary_crossentropy,\n",
        "    metrics = [tf.keras.metrics.binary_accuracy])\n",
        "\n",
        "# FOR MULTI CLASS\n",
        "model.compile(\n",
        "    optimizer= tf.keras.optimizers.Adam(learning_rate = lr_schedule), \n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"sparse_categorical_accuracy\"])\n",
        "\n",
        "# FOR MULTI LABEL\n",
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(lr_schedule),\n",
        "    loss= tf.keras.losses.binary_crossentropy(login),\n",
        "    metrics = [tf.keras.metrics.binary_accuracy])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7923VklXsav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TEST OTHER OPTION FOR LEARNING RATE FROM TPU\n",
        "EPOCHS = 12\n",
        "\n",
        "start_lr = 0.00001\n",
        "min_lr = 0.00001\n",
        "max_lr = 0.00005 * tpu_strategy.num_replicas_in_sync\n",
        "rampup_epochs = 5\n",
        "sustain_epochs = 0\n",
        "exp_decay = .8\n",
        "\n",
        "def lrfn(epoch):\n",
        "  if epoch < rampup_epochs:\n",
        "    return (max_lr - start_lr)/rampup_epochs * epoch + start_lr\n",
        "  elif epoch < rampup_epochs + sustain_epochs:\n",
        "    return max_lr\n",
        "  else:\n",
        "    return (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n",
        "    \n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=True)\n",
        "\n",
        "rang = np.arange(EPOCHS)\n",
        "y = [lrfn(x) for x in rang]\n",
        "plt.plot(rang, y)\n",
        "print('Learning rate per epoch:')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVcJOHbu3en4",
        "colab_type": "text"
      },
      "source": [
        "##K. MODEL FIT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_dijwot3izf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fit model by applying the data_aug.flow to X and y train\n",
        "# => batch size = // in the steps_per_epoch \n",
        "# epochs => count of times each images should be \"tested\" by neuronal network\n",
        "model.fit(data_aug.flow(X_train, y_train, batch_size=1), \n",
        "                    steps_per_epoch=len(X_train)//1,\n",
        "                    epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9XJCUoCjBOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fit without data aug within each epochs\n",
        "# Store on history variable\n",
        "# validation_data = ds_test allow to calculate metrics on test at the end of each EPOCHS\n",
        "history = model.fit(ds_train, epochs=15, validation_data=ds_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofLFtiW14eUv",
        "colab_type": "text"
      },
      "source": [
        "##L. CHECK RESULTS & PREDICTIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkzRsvao4gmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check result on test\n",
        "loss, accuracy = model.evaluate(data_aug.flow(X_test, y_test, batch_size=1))\n",
        "\n",
        "# or\n",
        "loss, accuracy = model.evaluate(ds_test, batch_size=1)\n",
        "\n",
        "# Print result\n",
        "print(\"valid loss = {}\".format(loss))\n",
        "print(\"Accuracy = {}%\".format(np.round(accuracy*100, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkC7v7qO4kk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check prediction\n",
        "# reshape is 1, 32, 32, 3 because \n",
        "# \"1\" => we check only 1 prediction / \"32, 32\" => heights and width = 32 / \"3\" => channel (=RGB)\n",
        "# argmax allow to take the highest score to know the most likely label \n",
        "pred = np.argmax(model.predict(X_test[0].reshape(1,32,32,3)))\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4R6LCZ77YiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show prediction\n",
        "plt.imshow(X_test[0])\n",
        "plt.title(\"True = {} \\n Pred = {}\".format(y_test[0], pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7No3qWklT2Tx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show graph with accuracy\n",
        "# OPTION 1\n",
        "def display_training_curves(training, validation, title, subplot):\n",
        "  ax = plt.subplot(subplot)\n",
        "  ax.plot(training)\n",
        "  ax.plot(validation)\n",
        "  ax.set_title('model '+ title)\n",
        "  ax.set_ylabel(title)\n",
        "  ax.set_xlabel('epoch')\n",
        "  ax.legend(['training', 'validation'])\n",
        "\n",
        "plt.subplots(figsize=(10,10))\n",
        "plt.tight_layout()\n",
        "display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'accuracy', 211)\n",
        "display_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 212)\n",
        "plt.show()\n",
        "\n",
        "# OPTION 2\n",
        "# Loss\n",
        "plt.plot(history.history[\"loss\"], color=\"b\")\n",
        "plt.plot(history.history[\"val_loss\"], color=\"r\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.title(\"Loss\")\n",
        "plt.legend(['Training', 'Validation'])\n",
        "plt.show()\n",
        "\n",
        "# Accuracy\n",
        "plt.plot(history.history[\"sparse_categorical_accuracy\"], color=\"b\")\n",
        "plt.plot(history.history[\"val_sparse_categorical_accuracy\"], color=\"r\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.title(\"Accuracy\")\n",
        "plt.legend(['Training', 'Validation'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeRHmvcnTMh4",
        "colab_type": "text"
      },
      "source": [
        "##M. SAVE & RELOAD MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLAKx66VTRda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can save our model with:\n",
        "model.save('model.h5')\n",
        "\n",
        "# Save model weight with :\n",
        "model.save_weights('model_weights.h5')\n",
        "\n",
        "# Reload it with:\n",
        "reloaded_model = tf.keras.models.load_model('model.h5')\n",
        "reloaded_model = tf.keras.models.load_model('model.h5', compile = False) # to reload only for production (no need to compile and no training)\n",
        "\n",
        "# Reload weights\n",
        "model.load_weights('model_weights.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxFU_lpz7jDY",
        "colab_type": "text"
      },
      "source": [
        "#**10. DEEP LEARNING - NLP**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ux5NECV7pWx",
        "colab_type": "text"
      },
      "source": [
        "##A. LIBRARY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ljOzkhikdkc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basics\n",
        "import tensorflow as tf \n",
        "import tensorflow_datasets as tfds\n",
        "import pathlib \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8WRbyFI7sOp",
        "colab_type": "text"
      },
      "source": [
        "##B. BASICS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_I5N3aZV3V6",
        "colab_type": "text"
      },
      "source": [
        "## C. DOWNLOAD DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-e4RS64V8jJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OPTION 1 Downlaod csv etc. \n",
        "doc = pd.read_csv(\"https://go.aws/314bBDq\") # Easy one with basic download\n",
        "doc = pd.read_csv(\"https://go.aws/314bBDq\", sep=\"\\t\", encoding=\"utf-8\") # With tabular separator and utf-8 to manage the 'é' or 'ô' etc. \n",
        "doc = pd.read_csv(\"https://go.aws/314bBDq\", sep=\"\\t\", error_bad_lines=False, encoding=\"utf-8\") # Error bad lines \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sX-Q8VMrwFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You may want to sample\n",
        "doc = doc.sample(5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg8rhqberKBP",
        "colab_type": "text"
      },
      "source": [
        "## D. PREPROCESSING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECJoxCCCrNAG",
        "colab_type": "text"
      },
      "source": [
        "> DOWLOAD LANGUAGE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDaSA6iYrI2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ENG & FR\n",
        "!python -m spacy download fr_core_news_md # Can swap md by sd\n",
        "!python -m spacy download en_core_web_md\n",
        "\n",
        "import fr_core_news_md\n",
        "import en_core_web_md\n",
        "nlp_fr = fr_core_news_md.load()\n",
        "nlp_en = en_core_web_md.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2y4l3tdfriws",
        "colab_type": "text"
      },
      "source": [
        "> CREATE CORPUS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dhfsV7ErdnR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Corpus\n",
        "fr_corpus = \" \".join(doc.iloc[:, 1].to_list())\n",
        "en_corpus = \" \".join(doc.iloc[:, 0].to_list())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuQ_9rWysGS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load\n",
        "%%time\n",
        "import time\n",
        "nlp_fr.max_length = len(fr_corpus)\n",
        "nlp_en.max_length = len(en_corpus)\n",
        "\n",
        "fr_doc = nlp_fr(fr_corpus)\n",
        "en_doc = nlp_en(en_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-baBDGtswRs",
        "colab_type": "text"
      },
      "source": [
        "> TOKENISATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQrrOgk2sy-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OPTION 1 : In PANDAS\n",
        "%%time\n",
        "doc[\"fr_tokens\"] = doc.iloc[:, 1].apply(lambda x: nlp_fr.tokenizer(x))\n",
        "doc[\"en_tokens\"] = doc.iloc[:, 0].apply(lambda x: nlp_en.tokenizer(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpH98uqjsbVm",
        "colab_type": "text"
      },
      "source": [
        "#**11. WEB SCRAPPING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "843ASodDsgmN",
        "colab_type": "text"
      },
      "source": [
        "##A. LIBRARY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOaSvhqcsuS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import re\n",
        "import json as js"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6GjlAS3NxGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "from io import BytesIO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZvNr67qs8UN",
        "colab_type": "text"
      },
      "source": [
        "##B. BEAUTIFULSOUP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74meis8NORv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1) SCRAP THE DATA\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "response = request.get(URL) # URL = website link\n",
        "soup = BeautifulSoup(response.text, \"html\") # We use html or lxml parser most of the time => can install other parsers throuhgh PIP install \n",
        "\n",
        "# 2) ACCESS THE DATA\n",
        "soup.prettify() # Display whole doc in \"nice\" HTML formatting\n",
        "soup.head # EX:  <head><title>The Dormouse's story</title></head>\n",
        "soup.title # EX: <title>The Dormouse's story</title>\n",
        "soup.a # EX: <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n",
        "\n",
        "# Access the parent elemant (= element above the 1st selected element)\n",
        "for parent in link.parents:\n",
        "  if parent is None:\n",
        "    print(parent)\n",
        "  else:\n",
        "    print(parent.name)\n",
        "\n",
        "# Access siblings elements (= element within same level within HTML code)\n",
        "for sibling in soup.a.next_siblings:\n",
        "  print(repr(sibling))\n",
        "\n",
        "for sibling in soup.find(id=\"link3\").previous_siblings:\n",
        "  print(repr(sibling))\n",
        "\n",
        "# Search for specific #find specific (or 1st result) and find_all for multiple results\n",
        "soup.find_all(\"title\") # display all with \"title\" => [<title>The Dormouse's story</title>]\n",
        "soup.find_all(\"a\") # [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
        "soup.find_all(\"p\", \"title\") # multiple AND search =>[<p class=\"title\"><b>The Dormouse's story</b></p>]\n",
        "soup.find_all(id=\"link2\") # id is unique => [<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]\n",
        "import re\n",
        "soup.find(string=re.compile(\"sisters\")) # u'Once upon a time there were three little sisters; and their names were\\n\n",
        "\n",
        "#Search within CSS\n",
        "soup.find_all(\"a\", class=\"sister\") # [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]\n",
        "css_soup.select(\"p.strikeout.body\") # [<p class=\"body strikeout\"></p>]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5m96mfBzDJ3",
        "colab_type": "text"
      },
      "source": [
        "> EX : IMD website"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5SG2h4CtCEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1) ACCESS MAIN PAGE\n",
        "url = 'http://www.imdb.com/chart/top'\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, 'lxml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BD4kzVdtV7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2) ACCESS \n",
        "movies = soup.select('td.titleColumn')\n",
        "soup.select('table tr td a')) # will select table => tr => td => a (narrow your selection)\n",
        "\n",
        "links = [a.attrs.get('href') for a in soup.select('td.titleColumn a')] # get the href value attribute\n",
        "crew = [a.attrs.get('title') for a in soup.select('td.titleColumn a')] # get the title attribute value\n",
        "ratings = [b.attrs.get('data-value') for b in soup.select('td.posterColumn span[name=ir]')] # get the data-value attribute for psoterColumn and span name=\"ir\"\n",
        "votes = [b.text for b in soup.select('td.ratingColumn.imdbRating strong')] #Take the text within <tags>\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRJyb2NVwRx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#3) USE DATA\n",
        "imdb = []\n",
        "\n",
        "# Store each item into dictionary (data), then put those into a list (imdb)\n",
        "for index in range(0, len(movies)):\n",
        "    # Separate movie into: 'place', 'title', 'year'\n",
        "    movie_string = movies[index].get_text()\n",
        "    movie = (' '.join(movie_string.split()).replace('.', ''))\n",
        "    movie_title = movie[len(str(index))+1:-7]\n",
        "    year = re.search('\\((.*?)\\)', movie_string).group(1)\n",
        "    place = movie[:len(str(index))-(len(movie))]\n",
        "    data = {\"movie_title\": movie_title,\n",
        "            \"year\": year,\n",
        "            \"place\": place,\n",
        "            \"star_cast\": crew[index],\n",
        "            \"rating\": ratings[index],\n",
        "            \"vote\": votes[index],\n",
        "            \"link\": links[index]}\n",
        "    imdb.append(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXIJx5qSzN3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#4) CONSOLIDATE DATA\n",
        "for item in imdb:\n",
        "    print(item['place'], '-', item['movie_title'], '('+item['year']+') -', 'Starring:', item['star_cast']) #, item[\"vote\"], item[\"rating\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTWI4n8szGxu",
        "colab_type": "text"
      },
      "source": [
        "> EX : Twitter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw7SLZgBzJDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1) SET INPUT  to choose account to scrap\n",
        "handle = input('Input your account name on Twitter: ') #jedhabootcamp\n",
        "ctr = int(input('Input number of tweets to scrape: ')) # to set max tweets to display\n",
        "\n",
        "res=requests.get('https://mobile.twitter.com/'+ handle) ##http://mobile.twitter.com/jedhabootcamp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbNAEPHW0H2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#2) SCRAP all pages\n",
        "bs = BeautifulSoup(res.content,'lxml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aeE8EXy0RGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#3) Scrap specific pieces of information \n",
        "all_tweets = bs.find_all('table',{'class':'tweet'}) # We use find_all to access all tables before selecting specific pieces within it\n",
        "\n",
        "if all_tweets:\n",
        "  for tweet in all_tweets[:ctr]:\n",
        "    content = tweet.find('div',{'class':'tweet-content'})\n",
        "    header = tweet.find('tr',{'class':'tweet-header '})\n",
        "    user = header.find('div',{'class':'username'}).text.replace(\"\\n\",\" \").strip()\n",
        "    time = header.find('td',{'class':'timestamp'}).text.replace(\"\\n\",\" \").strip()\n",
        "    message = tweet.find('div',{'class':'tweet-text'}).text.replace(\"\\n\",\" \").strip()\n",
        "    print(user,time)\n",
        "    print(message)\n",
        "    print()\n",
        "else:\n",
        "    print(\"List is empty/account name not found.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB24Sxv70pMm",
        "colab_type": "text"
      },
      "source": [
        "##C. REQUESTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFQqJ1Nh0vDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GET\n",
        "#  Data\n",
        "URL = \"http://restratpws.azurewebsites.net/api/Lines/metro\"\n",
        "r = requests.get(URL)\n",
        "\n",
        "#Using parameters\n",
        "payload = {'key1': 'value1', 'key2': 'value2'}\n",
        "r = requests.get('https://httpbin.org/get', params=payload)\n",
        "\n",
        "# See GET result\n",
        "r.text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2w9f4xENPcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# POST \n",
        "r = requests.post('https://httpbin.org/post', data = {'key':'value'})\n",
        "# Send file\n",
        "import pandas as pd\n",
        "file = pd.to_csv(\"un_fichier.csv\")\n",
        "r = requests.post('https://httpbin.org/post', files = file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWW9_gq801LW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# JSON\n",
        "r = requests.get('https://api.github.com/events')\n",
        "r.json() # Open the JSON file => It is a dictionnary (key : value)\n",
        "r.json().keys() # Get all the key within JSON File"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Rp0YgFENryY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BINAIRE\n",
        "r = requests.get(\"https://avatars.githubusercontent.com/u/1227972?\")\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "i = Image.open(BytesIO(r.content))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmMtYNjwDBQD",
        "colab_type": "text"
      },
      "source": [
        "#**12. SPARK**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FvCncUrDG0p",
        "colab_type": "text"
      },
      "source": [
        "This is for SPARK in Python / SQL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pylCNT60DFUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcThGCUjd2m0",
        "colab_type": "text"
      },
      "source": [
        "#**97. PYTHON CMD**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXwcNeaK0VQ9",
        "colab_type": "text"
      },
      "source": [
        "##A. ENVIRONNEMENT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU5OV_Ga0RgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CREATE\n",
        "conda create --name myenv\n",
        "conda create -n myenv python=3.7 #to create with specific version of python\n",
        "\n",
        "conda env create -f environment.yml #To create environnement from specific env file\n",
        "\n",
        "#IMPORTANT\n",
        "conda install pip # must do this to get basic packages within newly created virt environnement"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h-KTXfs07B2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SEE List of environnement\n",
        "conda info --envs\n",
        "\n",
        "#See list of package with envs\n",
        "conda list -n myenv\n",
        "conda list # list of package for the active environnement"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQ2AyhVi2NCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ACTIVATE env\n",
        "conda activate myenv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-24t1sW0eeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DELETE\n",
        "conda deactivate #Make sure you are no longer log to the environnement\n",
        "conda remove --name env_name --all # Delete"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVrgG0rsWC-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LINK environnement to Jupyter Notebook\n",
        "# 1st Create your environnement in Conda\n",
        "# 2nd activate virtual environnement\n",
        "# isntall ipykernel\n",
        "pip install ipykernel\n",
        "# link to your environnemnet ('myenv')\n",
        "python -m ipykernel install --name=myenv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVhvjYX3Xsd2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# REMOVE environnement from Jupyter Notebook\n",
        "# 1st Delete environnement in Conda\n",
        "# List all available kernel\n",
        "jupyter kernelspec list\n",
        "# Uninstall kernel ('myenv')\n",
        "jupyter kernelspec uninstall myenv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mc_ZJH1mqNV",
        "colab_type": "text"
      },
      "source": [
        "## C. LIBRARY : INSTALL / UPDATE ETC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDBEIH7Xm7Pi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# INSTALL using Conda\n",
        "conda install packagename\n",
        "\n",
        "# INSTALL using PIP (make sure to get pip library installed first)\n",
        "pip install packagename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBPe--__nIB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# UPDATE\n",
        "conda update --all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_XU6ysJnYpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# REMOVE package in current environnement\n",
        "conda remove packagename\n",
        "\n",
        "# REMOVE multiple packages in current environnement\n",
        "conda remove packagename1 pakcagename2\n",
        "\n",
        "#Remove specific package in another environement\n",
        "conda remove -n myenv packagename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdPcihy50ZBD",
        "colab_type": "text"
      },
      "source": [
        "##B. REQUIREMENTS / PIP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIq9pdP7d8wR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install -r requirements.txt # Install all listed packages\n",
        "\n",
        "pip freeze > requirements.txt # create the requirement file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqLPY13Nt1nB",
        "colab_type": "text"
      },
      "source": [
        "#**98. CODE IDEAS FROM OTHER PEOPLE** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gl3eCR_Nt7lk",
        "colab_type": "text"
      },
      "source": [
        "> These are special python codes written by other people and kept for informational purpose. (We could argue that none of the other scripts within this doc are 100% from me but in this chapter it is truly from someone else)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVkZyy3gvCbd",
        "colab_type": "text"
      },
      "source": [
        ">> CLASS CREATE TO MIMIC THE SKLEARN LINEAR REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OutKcYJcuJcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SAMUEL L.\n",
        "\n",
        "# Create kind of sklearn LINEAR REGRESSION => you can then optimize the learning_rate as it is a hyper_parameters => Do Grid search to get best ones\n",
        "def mse(y_pred, y_true):\n",
        "    return np.mean((y_pred - y_true)**2)\n",
        "def derivative_mse_x(x, y_pred, y_true):\n",
        "    derive_model_w = 2/len(y_pred)*np.sum((np.matrix(x) @ (y_pred - y_true)))\n",
        "    derive_model_b = 2/len(y_pred)*(np.sum(y_pred - y_true))\n",
        "    return (derive_model_w, derive_model_b)\n",
        "class Modelsk(BaseEstimator, RegressorMixin): \n",
        "    def __init__(self, a = np.random.randn(), b = np.random.randn(), learning_rate = None):\n",
        "        self.a = a\n",
        "        self.b = b\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.a * x + self.b\n",
        "\n",
        "    def adjust(self, grads):\n",
        "        grad_a , grad_b = grads\n",
        "        self.a = self.a - self.learning_rate * grad_a\n",
        "        self.b = self.b - self.learning_rate * grad_b\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        for i in range(10001):\n",
        "            self.adjust(derivative_mse_x(X, self(X), y))\n",
        "        print(\"MSE  : {}\\lr = {}\".format(mse(self(X), y), self.learning_rate))\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.__call__(X)\n",
        "\n",
        "    def score(self, X, y):\n",
        "        return 1/mse(self(X), y)\n",
        "\n",
        "# fit et predict example\n",
        "msk = Modelsk(learning_rate=0.1)\n",
        "msk.fit(diabetes_X,y)\n",
        "msk.predict(30)\n",
        "\n",
        "# Do GridSearch\n",
        "#\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = {'learning_rate':[0.1, 0.2, 0.3]}\n",
        "grid = GridSearchCV(Modelsk(), parameters)\n",
        "grid.fit(diabetes_X, y)\n",
        "grid.best_estimator_\n",
        "grid.best_estimator_.predict(diabetes_X)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMpm1x-7nzDM",
        "colab_type": "text"
      },
      "source": [
        "# **99. MISCELENAOUS**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-klSFxDb3rM",
        "colab_type": "text"
      },
      "source": [
        "##A. TIME"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npb3hzmfn1vQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#HOW LONG IT TOOK TO RUN A TASK IN PYTHON\n",
        "# OPTION 1\n",
        "import time\n",
        "t0 = time.time()\n",
        "# your task\n",
        "print(\"done in %0.3fs\" % (time.time() - t0))\n",
        "\n",
        "# OPTION 2\n",
        "%time svm.fit(X_train, y_train) # where svm.fit .... is your taks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOfjmJHXcDxA",
        "colab_type": "text"
      },
      "source": [
        "## B. GOOGLE COLLAB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFz1udXTcIOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MOUNT DRIVE into google\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# you will have to autorize collab \n",
        "\n",
        "!cd /content/drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB2C2qjk5CCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GOOGLE COLLAB HACK !\n",
        "# Special code to simulate activity on google Collab\n",
        "# Press \"CTRL + SHIFT + i\" and copy / paste value the below script within the \"Consol\" and press \"Enter\"\n",
        "\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\"); \n",
        "document.querySelector(\"colab-toolbar-button#connect\").click() \n",
        "}\n",
        "setInterval(ClickConnect,60000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UIKIPotgulY",
        "colab_type": "text"
      },
      "source": [
        "##C. TEST LOCAL GPU Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eECKgUE6grPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU'))) # Should display 1 (Should display))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dO-qZ0HhZGuI",
        "colab_type": "text"
      },
      "source": [
        "## D. VERBOSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gr_spy1Tk8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Minimize verbode tensorflow\n",
        "# IMPORTANT : This only worked if I put the os.environ before tensorflow was imported\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
        "import tensorflow as tf\n",
        "'''\n",
        "0 = all messages are logged (default behavior)\n",
        "1 = INFO messages are not printed\n",
        "2 = INFO and WARNING messages are not printed\n",
        "3 = INFO, WARNING, and ERROR messages are not printed\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}